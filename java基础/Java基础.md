# 必会关键字

**void    byte    int    long    char    short    float    double    String    StringBuffer    StringBuilder    Array    Collection    Collections    List    ArrayList    LinkedList    Vector    Set    Hash    Map    TreeMap    LinkedHashMap    ConcerrentHash    MapSet    TreeMap    HashMap    synchronized    volatile    transient    implements    extends    public    private    protected    this    super    static    final    const    run    start    thread    enmu    stack    queue    list    heap    throw    throws    try    catch    finally    break    continue    instanceof**

# 计算机基础知识数据结构

## 1. 什么是队列、栈、链表

## 2. 什么是树（平衡树,排序树,B树,B+树,R树,红黑树）、堆（大根堆、小根堆）、图（有向图、无向图、拓扑）

**红黑树：（自平衡的二叉搜索树）**

1. 每个节点不是红色就是黑色的；
2. 根节点总是黑色的；
3. 所有的叶节点都是是黑色的（红黑树的叶子节点都是空节点（NIL或者NULL））；
4. 如果节点是红色的，则它的子节点必须是黑色的（反之不一定）；
5. 从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）。

**应用场景**：java中的TreeSet,TreeMap，广泛用在C++的STL中。如map和set都是用红黑树实现的

## 3. 栈和队列的相同和不同之处

栈与队列的**相同点**：

- 都是线性结构。
- 插入操作都是限定在表尾进行。
- 都可以通过顺序结构和链式结构实现。
- 插入与删除的时间复杂度都是O（1），在空间复杂度上两者也一样。
- 多链栈和多链队列的管理模式可以相同。

栈与队列的**不同点**：

- 删除数据元素的位置不同，栈的删除操作在表尾进行，队列的删除操作在表头进行。
- 应用场景不同；常见栈的应用场景包括括号问题的求解，表达式的转换和求值，函数调用和递归实现，深度优先搜索遍历等；常见的队列的应用场景包括计算机系统中各种资源的管理，消息缓冲器的管理和广度优先搜索遍历等。
- 顺序栈能够实现多栈空间共享，而顺序队列不能。

## 4. 栈通常采用的两种存储结构

顺序存储、链式存储

## 5. 两个栈实现队列，和两个队列实现栈

## 6. 散列冲突的几种解决方法

1. 开放定址法（线性探测再散列，二次探测再散列，伪随机探测再散列）
2. 链地址法(Java HashMap就是这么做的)
3. 再哈希法
4. 建立一个公共溢出区

## 7. 为什么使用补码

a) **原码**就是符号位加上真值的绝对值, 即用**第一位表示符号**, 其余位表示值. 比如如果是8位二进制:

[+1]原 = 0000 0001

[-1]原 = 1000 0001

第一位是符号位. 因为第一位是符号位, 所以8位二进制数的取值范围就是:[1111 1111 , 0111 1111]即[-127 , 127]

b) **反码**的表示方法是:**正数**的反码是其本身，**负数**的反码是在其原码的基础上, 符号位不变，其余各个位取反.

[+1] = [00000001]原 = [00000001]反

[-1] = [10000001]原 = [11111110]反

可见如果一个反码表示的是负数, 人脑无法直观的看出来它的数值. 通常要将其转换成原码再计算.

c) **补码**的表示方法是:**正数**的补码就是其本身，**负数**的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1. (即在反码的基础上+1)

[+1] = [00000001]原 = [00000001]反 = [00000001]补

[-1] = [10000001]原 = [11111110]反 = [11111111]补

对于负数, 补码表示方式也是人脑无法直观看出其数值的. 通常也需要转换成原码在计算其数值.

**为何使用**：

现在我们知道了计算机可以有三种编码方式表示一个数. 对于正数因为三种编码方式的结果都相同:

[+1] = [00000001]原 = [00000001]反 = [00000001]补

所以不需要过多解释. 但是对于负数:

[-1] = [10000001]原 = [11111110]反 = [11111111]补

可见原码, 反码和补码是完全不同的. 既然原码才是被人脑直接识别并用于计算表示方式, 为何还会有反码和补码呢?

首先, 因为人脑可以知道第一位是符号位, 在计算的时候我们会根据符号位, 选择对真值区域的加减. (真值的概念在本文最开头). 但是对于计算机, 加减乘数已经是最基础的运算, 要设计的尽量简单. 计算机辨别"符号位"显然会让计算机的基础电路设计变得十分复杂! 于是人们想出了将符号位也参与运算的方法. 我们知道, 根据运算法则减去一个正数等于加上一个负数, 即: 1-1 = 1 + (-1) = 0 , 所以机器可以只有加法而没有减法, 这样计算机运算的设计就更简单了.

于是人们开始探索 将符号位参与运算, 并且只保留加法的方法. 首先来看原码:

计算十进制的表达式: 1-1=0

1 - 1 = 1 + (-1) = [00000001]原 + [10000001]原 = [10000010]原 = -2

如果用原码表示, 让符号位也参与计算, 显然对于减法来说, 结果是不正确的.这也就是为何计算机内部不使用原码表示一个数.

为了解决原码做减法的问题, 出现了反码:

计算十进制的表达式: 1-1=0

1 - 1 = 1 + (-1) = [0000 0001]原 + [1000 0001]原= [0000 0001]反 + [1111 1110]反 = [1111 1111]反 = [1000 0000]原 = -0

发现用反码计算减法, 结果的真值部分是正确的. 而唯一的问题其实就出现在"0"这个特殊的数值上. 虽然人们理解上+0和-0是一样的, 但是0带符号是没有任何意义的. 而且会有[0000 0000]原和[1000 0000]原两个编码表示0.

于是补码的出现, 解决了0的符号以及两个编码的问题:

1-1 = 1 + (-1) =[0000 0001]原 +[1000 0001]原 =[0000 0001]补 +[1111 1111]补 =[00000000]补=[00000000]原

这样0用[0000 0000]表示, 而以前出现问题的-0则不存在了.而且可以用[1000 0000]表示-128:

(-1) + (-127) =[1000 0001]原 +[1111 1111]原 =[1111 1111]补 +[1000 0001]补 =[1000 0000]补

-1-127的结果应该是-128, 在用补码运算的结果中, [1000 0000]补 就是-128. 但是注意因为实际上是使用以前的-0的补码来表示-128, 所以-128并没有原码和反码表示.(对-128的补码表示[1000 0000]补算出来的原码是[0000 0000]原, 这是不正确的)

**使用补码不仅仅修复了0的符号以及存在两个编码的问题, **而且还能够多表示一个最低数.*这就是为什么**8**位二进制**,** **使用原码或反码表示的范围为**[-127, +127],** **而使用补码表示的范围为**[-128, 127].**

因为机器使用补码, 所以对于编程中常用到的32位int类型, 可以表示范围是: [-231, 231-1] 因为第一位表示的是符号位.而使用补码表示时又可以多保存一个最小值。

## 8. C语言中的内存泄漏

有些程序并不需要管理它们的动态内存的使用。当需要内存时，它们简单地通过分配来获得，从来不用担心如何释放它。这类程序包括编译器和其他一些运行一段固定的（或有限的）时间然后终止的程序。当这种类型的程序终止时，所有内存会被自动回收。细心查验每块内存是否需要回收纯属浪费时间，因为它们不会再被使用。

其他程序的生存时间要长一点。有些工具如日历管理器、邮件工具以及操作系统本身经常需要数日及至数周连续运行，并需要管理动态内存的分配和回收。由于C语言通常并不使用垃圾回收器（自动确认并回收不再使用的内存块），这些C程序在使用malloc()和free()时不得不非常慎重。堆经常会出现两种类型的问题：

1. **释放或改写仍在使用的内存(称为：“内存损坏”)。**
2. **未释放不再使用的内存(称为：“内存泄露”)。**

这是最难被调试发现的问题之一。如果每次已分配的内存块不再使用而程序并不释放它们，进程就会一边分配越来越多的内存，一边却并不释放不再使用的那部分内存。

**避免内存泄露**

每当调用malloc分配内存时，注意在以后要调用相应的free来释放它。

如果不知道如何调用free与先前的malloc相对应，那么很可能已经造成了内存泄露！

一种简单的方法就是在可能的时候使用malloc()来分配动态内存，以避免上述情况。当离开调用malloc的函数时，它所分配的内存会被自动释放。

显然，这并不适用于那些比创建它们的函数生命期更长的结构。但如果对象的生命期在该函数结束前便已经终止，这种建立在堆栈上的动态内存分配是一种开销很小的选择。有些人不提倡使用malloc，因为它并不是以后总可移植的方法。如果处理器在硬件上不支持堆栈，malloc ()就很难高效地实现。

我们使用“内存泄露”这个词是因为一种稀有的资源正在被一个进程榨干。内存泄露的主要可见症状就是罪魁进程的速度很减慢。原因是体积大的进程更有可能被系统换出，让别的进程运行，而且大的进程在换进换出时花费的时间也更多。即使泄露的内存本省并不被引用，但它仍用可能存在于页面中（内容自然是垃圾），这样就增加了进程的工作页数量，降低了性能。另外需要注意的一点是，内存泄露往往比忘记释放的的数据结构要大，因为malloc()所分配的内存通常会圆整为下一个大于申请数量的2的整数次方（如申请212B,会圆整为256B）。在资源有限的情况下，即使引起内存泄露的进程并不运行，整个系统运行速度也会被拖慢。从理论上说，进程的大小有一个上限值，这在不同的操作系统中各不相同。在当前的SunOS版本中，进程的最大地址空间可以多达4GB。事实上，在进程所泄露的内存远未达到这个数量时，磁盘的交换区早已消耗殆尽。

**如何检测内存泄露**

观察内存泄露是一个两步骤的过程。首先，使用swap命令观察还有多少可用的交换空间：

/usr/sbin/swap -s

total:17228K bytes allocated + 5396K reserved=22626K used，29548K available.

在一两分钟内键入该命令三到四次，看看可用的交换区是否在减少。还可以使用其他一些/usr/bin/*stat工具如netstat、vmstat等。如发现波段有内存被分配且从不释放，一个可能的解释就是有个进程出现了内存泄露。

# 算法

## 1. 排序都有哪几种方法？

冒泡排序、简单选择排序、直接插入排序、希尔排序、堆排序、归并排序、快速排序

## 2. 会写常用的排序算法，如快排，归并等。

## 3. 各种排序算法的时间复杂度和稳定性，重点快排。

| 排序方法 |       平均时间       |   最好情况   |  最差情形  |    额外空间    | 稳定度 |
| :------: | :------------------: | :----------: | :--------: | :------------: | :----: |
|   冒泡   |       O($n^2$)       |     O(n)     |  O($n^2$)  |      O(1)      |  稳定  |
|   选择   |       O($n^2$)       |   O($n^2$)   |  O($n^2$)  |      O(1)      | 不稳定 |
|   插入   |       O($n^2$)       |     O(n)     |  O($n^2$)  |      O(1)      |  稳定  |
|  Shell   | O($nlogn$)~ O($n^2$) | O($n^{1.3}$​) |  O($n^2$)  |      O(1)      | 不稳定 |
|    堆    |      O($nlogn$)      |  O($nlogn$)  | O($nlogn$) |      O(1)      | 不稳定 |
|   归并   |      O($nlogn$)      |  O($nlogn$)  | O($nlogn$) |      O(n)      |  稳定  |
|   快速   |      O($nlogn$)      |  O($nlogn$)  |  O($n^2$)  | O($logn$)~O(n) | 不稳定 |

**一些结论**：

① 基本有序的情况下，**插入排序**效率最高 

② **冒泡排序**，**插入排序**和**快速排序**的排序趟数与序列的初始状态有关

③ **堆排序**和**选择排序**的排序次数与初始状态无关，即最好情况和最坏情况都一样



## 4. 单链表的遍历和逆序，部分链表的反转

## 5. 深度优先搜索和广度优先搜索

## 6. 前序中序后序非递归遍历，层次遍历（要求5分钟内准确写出来）

## 7. 生成树算法（动态规划/贪心）

## 8. 回溯法，递归的运用

## 9. 最小生成树

## 10. 常见Hash算法，哈希的原理和代价

- MD4、MD5、SHA-1
- 以空间换时间的算法

## 11. 全排列、贪心算法、KMP算法、hash算法、动态规划、最大流、布隆过滤器

## 12. 一致性Hash算法

# 操作系统

## 1. 虚拟内存管理

产生原因：实际内存不够

优点：虚拟内存可以大于物理内存，一般为物理内存的1.5倍到3倍，从而可以运行比物理内存大的程序，进而使得更多的程序可以同时执行，提高了多道程序的程度，增加了CPU的使用率，并且使得进程之间的独立性得到了更好的体现。

## 2. 换页算法

页面置换：在地址映射过程中，若在页面中发现所要访问的页面不在内存中，则产生缺页中断(page fault)。当发生缺页中断时操作系统必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。 

**OPT：最佳替换算法（optional replacement）**。替换下次访问距当前*时间*最长的页。opt算法需要知道操作系统将来的事件，显然不可能实现，只作为一种衡量其他算法的标准。

**LRU:最近最少使用(Least Recently Used)**。替换上次使用距离当前最远的页。根据局部性原理：替换最近最不可能访问到的页。性能最接近OPT，但难以实现。可以维护一个关于访问页的栈或者给每个页添加最后访问的时间标签，但开销都很大。

**FIFO:先进先出(First In First Out)**。将页面看做一个循环缓冲区，按循环方式替换。这是实现最为简单的算法，隐含的逻辑是替换驻留在内存时间最长的页。但由于一部分程序或数据在整个程序的生命周期中使用频率很高，所以会导致反复的换入换出。

**Clock：时钟替换算法（Clock）**。给每个页帧关联一个使用位。当该页第一次装入内存或者被重新访问到时，将使用位置为1。每次需要替换时，查找使用位被置为0的第一个帧进行替换。在扫描过程中，如果碰到使用位为1的帧，将使用位置为0，在继续扫描。如果所谓帧的使用位都为0，则替换第一个帧。

## 3. 进程、线程间通信

**进程与线程的区别是什么？**

线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享同一块内存空间和一组系统资源，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。另外，也正是因为共享资源，所以线程中执行时一般都要进行同步和互斥。总的来说，**进程和线程的主要差别在于它们是不同的操作系统资源管理方式**。

**进程间的几种通信方式说一下？**

- **管道（pipe）**：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有**血缘关系**的进程间使用。进程的血缘关系通常指父子进程关系。管道分为**pipe（无名管道）**和**name pipe（命名管道）**两种，有名管道也是半双工的通信方式，但是它允许**无亲缘关系**进程间通信。
- **信号（signal）**：信号是在**软件层次上对中断机制的一种模拟**，它是比较复杂的通信方式，用于通知进程有某事件发生，一个进程收到一个信号与处理器收到一个中断请求效果上可以说是一致的。
- **消息队列（message queue）**：消息队列是由消息组成的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。**具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息**。
- **共享内存（shared memory）**：可以说这是最有用的进程间通信方式。它使得多个进程可以访问同一块内存空间，**不同进程可以及时看到对方进程中对共享内存中数据得更新**。这种方式需要依靠某种同步操作，如**互斥锁**和**信号量**等。
- **信号量（semophore）****：主要作为进程之间及同一种进程的不同线程之间得同步和互斥手段**。信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它通常作为一种*锁机制*，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
- **套接字（socket）**：socket，即套接字是一种通信机制，凭借这种机制，客户/服务器（即要进行通信的进程）系统的开发工作既可以在本地单机上进行，也可以跨网络进行。也就是说它可以让不在同一台计算机但通过网络连接计算机上的进程进行通信。也因为这样，套接字明确地将客户端和服务器区分开来。

**线程间的几种通信方式知道不？**

1. **锁机制**

- 互斥锁：提供了以排它方式阻止数据结构被并发修改的方法。
- 读写锁：允许多个线程同时读共享数据，而对写操作互斥。
- 条件变量：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。

2. **信号量机制**：包括无名线程信号量与有名线程信号量
3. **信号机制**：类似于进程间的信号处理。

- 线程间通信的**主要目的是用于线程同步**，所以线程没有象进程通信中用于数据交换的通信机制。

## 4. 死锁的四个必要条件，避免方法；银行家算法、哲学家进餐

产生死锁的**原因**主要是：

（1） 因为系统资源不足。

（2） 进程运行推进的顺序不合适。

（3） 资源分配不当等。

如果系统资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则就会因争夺有限的资源而陷入死锁。其次，进程运行推进顺序与速度不同，也可能产生死锁。

产生死锁的四个**必要条件**：

（1） 互斥条件：一个资源每次只能被一个进程使用。

（2） 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。

（3） 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。

（4） 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。 

**死锁的解除与预防**：

理解了死锁的原因，尤其是产生死锁的四个必要条件，就可以最大可能地避免、预防和解除死锁。所以，在系统设计、进程调度等方面注意如何不让这四个必要条件成立，如何确定资源的合理分配算法，避免进程永久占据系统资源。此外，也要防止进程在处于等待状态的情况下占用资源。因此，对资源的分配要给予合理的规划。

## 5. Linux的一些基本命令（内存查看，进程查看之类的），还有ls、tail、chmod、find等

查看cpu的型号命令：dmesg |grep -i xeon

查看内存的命令：free –m

查看硬盘大小：df –h

用top命令也可以查看到cpu和内存的使用率 在输入top命令之后直接按"1" 就能很清楚的查看到cpu和内存的使用情况。

查看进程：ps –A，查看所有；ps aux，详情；

查看端口占用：netstat，lsof

linux中命令cat、more、less均可用来查看文件内容，主要区别有:<https://www.jianshu.com/p/d5c44d392249?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation>

 

## 6. 线程同步的方式和机制

**临界区**（Critical Section）、**互斥对象**（Mutex）：主要用于互斥控制；都具有拥有权的控制方法，只有拥有该对象的线程才能执行任务，所以拥有，执行完任务后一定要释放该对象。

**信号量**（Semaphore）、**事件对象**（Event）：事件对象是以通知的方式进行控制，主要用于同步控制！

1、**临界区**：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。它并不是核心对象，不是属于操作系统维护的，而是属于进程维护的。

总结下关键段：

1）关键段共初始化化、销毁、进入和离开关键区域四个函数。

2）关键段可以解决线程的互斥问题，但因为具有“线程所有权”，所以无法解决同步问题。

3）推荐关键段与旋转锁配合使用。

2、**互斥对象**：互斥对象和临界区很像，采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程同时访问。当前拥有互斥对象的线程处理完任务后必须将线程交出，以便其他线程访问该资源。

总结下互斥量Mutex：

1）互斥量是内核对象，它与关键段都有“线程所有权”所以不能用于线程的同步。

2）互斥量能够用于多个进程之间线程互斥问题，并且能完美的解决某进程意外终止所造成的“遗弃”问题。

3、**信号量**：信号量也是内核对象。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。

在用CreateSemaphore()创建信号量时即要同时指出允许的最大资源计数和当前可用资源计数。一般是将当前可用资源计数设置为最大资源计数，每增加一个线程对共享资源的访问，当前可用资源计数就会减1 ，只要当前可用资源计数是大于0 的，就可以发出信号量信号。但是当前可用计数减小到0 时则说明当前占用资源的线程数已经达到了所允许的最大数目，不能在允许其他线程的进入，此时的信号量信号将无法发出。线程在处理完共享资源后，应在离开的同时通过ReleaseSemaphore（）函数将当前可用资源计数加1。在任何时候当前可用资源计数决不可能大于最大资源计数。

4、**事件对象**：通过通知操作的方式来保持线程的同步，还可以方便实现对多个线程的优先级比较的操作

总结下事件Event

1）事件是内核对象，事件分为手动置位事件和自动置位事件。事件Event内部它包含一个使用计数（所有内核对象都有），一个布尔值表示是手动置位事件还是自动置位事件，另一个布尔值用来表示事件有无触发。

2）事件可以由SetEvent()来触发，由ResetEvent()来设成未触发。还可以由PulseEvent()来发出一个事件脉冲。

3）事件可以解决线程间同步问题，因此也能解决互斥问题。

 

# 计算机网络

## 1. 当你在浏览器地址栏输入www.google.com，敲下回车之后都发生了什么

1. **应用层**：DNS解析域名为目的IP，通过IP找到服务器路径，客户端向服务器发起HTTP会话，然后通过运输层TCP协议封装数据包，在TCP协议基础上进行传输
2. **运输层**：HTTP会话会被分成报文段，添加源、目的端口；TCP协议进行主要工作
3. **网络层**：为数据包选择路由，IP协议进行主要工作
4. **数据链路层**：相邻结点的可靠传输，ARP协议将IP地址转成MAC地址。数据链路的信道主要有两种模式**：点对点信道**：这种信道使用一对一的点对点通信方式；**广播信道**：这种信道使用一对多的广播通信方式，因此过程比较复杂。

 

**各层的传输单位**：

- **应用层**：应用层是报文，报文在发送之前会划分为等长的数据段，在每段前面加上一些必要的控制信息后，就构成了一个分组，叫做包。
- **传输层**：使用TCP的话，单位是报文段，UDP的单位是用户数据报。
- **网络层**：IP数据报
- **数据链路层**：帧
- **物理层**：比特，也就是0和1

## 2. TCP的三次握手，四次关闭

位码即TCP标志位，有6种标示：SYN(synchronous建立联机) 、ACK(acknowledgement 确认)、 PSH(push传送) 、FIN(finish结束) 、RST(reset重置)、 URG(urgent紧急)、Sequence number(顺序号码)、 Acknowledge number(确认号码)

<https://blog.csdn.net/qzcsu/article/details/72861891>

**2.1** **三次握手**

三次握手的**目的**是“**为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误**”。

TCP是主机对主机层的传输控制协议，提供可靠的连接服务，采用三次握手确认建立一个连接:

TCP/IP协议中，TCP协议提供可靠的连接服务，采用三次握手建立一个连接，如图所示。

（1）第一次握手：建立连接时，客户端A发送**SYN报文段**（SYN=j）到服务器B，并进入**SYN_SEND状态**，等待服务器B确认。

（2）第二次握手：服务器B收到SYN包，必须确认客户A的SYN（ACK=j+1），同时自己也发送一个SYN包（SYN=k），即**SYN+ACK报文段**，此时服务器B进入**SYN_RECV**状态。

（3）第三次握手：客户端A收到服务器B的SYN＋ACK包，向服务器B发送确认**ACK报文段（ACK=k+1）**，此包发送完毕，客户端A和服务器B进入**ESTABLISHED状态**，完成三次握手。

完成三次握手，客户端与服务器开始传送数据。

![](E:/Code/JavaLearning/java%E5%9F%BA%E7%A1%80/images/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.jpg)

**1.2** **四次挥手，关闭连接**

由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。这个原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。收到一个 FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。

CP的连接的拆除需要发送四个包，因此称为四次挥手(four-way handshake)。客户端或服务器均可主动发起挥手动作，在socket编程中，任何一方执行close()操作即可产生挥手操作。

（1）客户端A发送一个**FIN**报文段**，用来关闭客户A到服务器B的数据传送，此时客户端进入**FIN_WAIT_1**状态**。

（2）服务器B收到这个FIN报文段后，它发回一个**ACK报文段**，确认序号为收到的序号加1，此时服务端进入**CLOSE_WAIT状态**。和SYN一样，一个FIN将占用一个序号。当客户端收到此ACK后，客户端进入**FIN_WAIT_2状态**。

（3）服务器B关闭与客户端A的连接，发送一个**FIN报文段**给客户端A，此时服务端进入**LAST_ACK状态**。

（4）客户端A发回**ACK报文段**进行确认，并将确认序号设置为收到序号加1,此时客户端进入**TIME_WAIT状态**。假定ACK丢失，TIME_WAIT状态使TCP客户重传最后的确认报文。在TIME_WAIT状态中所消耗的时间是与具体实现有关的，而典型的值是3秒、1分钟或2分钟。经过等待后，连接就正式关闭，客户端所有资源将被释放。

TCP采用四次挥手关闭连接如图所示。 

**状态转移图**：![](E:/Code/JavaLearning/java%E5%9F%BA%E7%A1%80/images/TCP%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.png)

## 3. TCP,UDP区别

- TCP面向连接，UDP面向非连接即发送数据前不需要建立连接
- TCP提供可靠的服务（数据传输），UDP无法保证
- TCP面向字节流，UDP面向报文
- TCP数据传输慢，UDP数据传输快

**TCP对应的协议**：

1. FTP：定义了文件传输协议，使用21端口。
2. Telnet：一种用于远程登陆的端口，使用23端口，用户可以以自己的身份远程连接到计算机上，可提供基于DOS模式下的通信服务。
3. SMTP：邮件传送协议，用于发送邮件。服务器开放的是25号端口。
4. POP3：它是和SMTP对应，POP3用于接收邮件。POP3协议所用的是110端口。
5. HTTP：是从Web服务器传输超文本到本地浏览器的传送协议。

**UDP对应的协议**：

1. DNS：用于域名解析服务，将域名地址转换为IP地址。DNS用的是53号端口。
2. SNMP：简单网络管理协议，使用161号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。
3. TFTP(Trival File Tran敏感词er Protocal)，简单文件传输协议，该协议在熟知端口69上使用UDP服务。

## 4. TCP协议如何来保证传输的可靠性

1. 应用数据被分割成TCP认为最适合发送的数据块。这和UDP完全不同，应用程序产生的数据报长度将保持不变。(**将数据截断为合理的长度**)
2. 当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。(**超时重发**)
3. 当TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒。(**对于收到的请求，给出确认响应**) (之所以推迟，可能是要对包做**完整校验**)
4. TCP将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段。(**校验出包有错，丢弃报文段，不给出响应，TCP发送数据端，超时时会重发数据**)
5. 既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。如果必要，TCP将对收到的数据进行重新排序，将收到的数据以正确的顺序交给应用层。(**对失序数据进行重新排序，然后才交给应用层**)
6. 既然IP数据报会发生重复，TCP的接收端必须丢弃重复的数据。(**对于重复数据，能够丢弃重复数据**)
7. TCP还能提供**流量控制**。TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据。这将防止较快主机致使较慢主机的缓冲区溢出。(**TCP可以进行流量控制，防止较快主机致使较慢主机的缓冲区溢出**)TCP使用的流量控制协议是可变大小的**滑动窗口协议**。

## 5. 流量控制、拥塞控制

**流量控制**以消除发送方使的接收方缓存区溢出的可能性，因此可以说流量控制是一个速度匹配服务（匹配发送方的发送速率与接收方的读取速率）。在通信过程中，接收方根据自己接收缓存的大小，动态地调整发送方的发送窗口大小，这就是接收窗口rwnd，即调整TCP报文段首部中的**窗口**字段值，来限制发送方向网络注入报文的速率。

**拥塞控制**就是防止过多的数据注入到网络中，这样可以防止网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。

TCP的拥塞控制由4个核心的算法组成**：慢启动**（slow start）、**拥塞避免**（Congestion voidance）、**快重传**（Fast Retransmit）和**快恢复**（Fast Recovery）。![](E:/Code/JavaLearning/java%E5%9F%BA%E7%A1%80/images/%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6.png)

**快重传**：当发送方连续收到三个重复的ACK报文时，直接重传对方尚未收到的报文段，而不必等待那个报文段设置的重传计时器超时。

**快恢复**：当发送端连续收到三个冗余ACK时，就把慢开始门限设置为出现拥塞发送方cwnd的一半。与慢开始不同的是它把cwnd的值设置为慢开始门限改变后的数值 ，然后开始执行拥塞避免算法，使拥塞窗口缓慢线性增大。

慢开始、拥塞避免算法、快重传和快恢复几种算法应该是同时应用在拥塞控制机制中的，当发送方检测到超时的时候就采用慢开始和拥塞避免，当发送方接收到冗余ACK的时候就采用快重传和快恢复。

## 6. 滑动窗口、拥塞窗口

窗口分为**滑动窗口**和**拥塞窗口**。

**滑动窗口**是接受数据端使用的窗口大小，用来告知发送端接收端的缓存大小，以此可以控制发送端发送数据的大小，从而达到流量控制的目的。滑动窗口协议是传输层进行流控的一种措施，接收方通过通告发送方自己的窗口大小，从而控制发送方的发送速度，从而达到防止发送方发送速度过快而导致自己被淹没的目的。

那么对于数据的发送端就是**拥塞窗口**了，拥塞窗口不代表缓存，拥塞窗口指某一源端数据流在一个RTT内可以最多发送的数据包数。

 

## 7. HTTP各个版本的区别

HTTP（Hypertext transfer protocol）超文本传输协议，是一个应用层的通信协议。

**HTTP协议版本介绍**：

**HTTP/0.9:**只接受GET一种请求方法，没有在通信中指定版本号，且不支持请求头。由于该版本不支持POST方法，因此客户端无法向服务器传递太多信息。

**HTTP/1.0:**第一个在通信中指定的版本号，至今被广泛采用，特别是在代理服务器中。

**HTTP/1.1:**当前版本号，**持久连接被默认采用**，并能很好地配合代理服务器工作。还支持以管道方式在同时发送多个请求，以便降低线路负载，提高传输速度。

**HTTP/2.0:**正在开发中······

 

**HTTP/1.1与HTTP/1.0的区别**：

**①** **persistent connection**（持久连接）

HTTP/1.0中，每对请求/ 响应都使用一个新的连接。

HTTP/1.1则支持持久连接（默认）。

**②** **Host域**

HTTP/1.1在请求消息头多一个Host域；HTTP/1.0则没有这个域，建立TCP连接的时候已经指定了IP地址，而且默认一个IP地址只对应一个主机名，IP地址上只有一个host。

**③** **带宽优化**

HTTP/1.1中在请求消息中引入了range头域，它允许只请求资源的某个部分。在响应消息中Content-Range头域声明了返回的这部分对象的偏移值和长度。如果服务器相应地返回了对象所请求范围的内容，则响应码为206（Partial Content），它可以防止Cache将响应误以为是完整的一个对象。请求消息中如果包含比较大的实体内容，但不确定服务器是否能够接收该请求（如是否有权限），此时若贸然发出带实体的请求，如果被拒绝也会浪费带宽。HTTP/1.1加入了一个新的状态码100（Continue）。客户端事先发送一个只带头域的请求，如果服务器因为权限拒绝了请求，就回送响应码 401（Unauthorized）；如果服务器接收此请求就回送响应码100，客户端就可以继续发送带实体的完整请求了。注意，HTTP/1.0的客户端不支持100响应码。

节省带宽资源的一个非常有效的做法就是压缩要传送的数据。Content-Encoding是对消息进行端到端（end-to-end）的编码，它可能是资源在服务器上保存的固有格式（如jpeg图片格式）；在请求消息中加入Accept-Encoding头域，它可以告诉服务器客户端能够解码的编码方式。而Transfer-Encoding是逐段式（hop-by-hop）的编码，如Chunked编码。在请求消息中加入TE头域用来告诉服务器能够接收的transfer-coding方式。

**④** **请求方法和状态码**

HTTP1.1增加了OPTIONS, PUT, DELETE, TRACE, CONNECT这些Request方法

HTTP/1.0中只定义了16个状态响应码，对错误或警告的提示不够具体。HTTP/1.1引入了一个Warning头域，增加对错误或警告信息的描述。

在HTTP/1.1中新增了24个状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。

**⑤** **内容协商**

为了满足互联网使用不同母语和字符集的用户，一些网络资源有不同的语言版本（如中文版、英文版）。HTTP/1.0定义了内容协商（content negotiation）的概念，也就是说客户端可以告诉服务器自己可以接收以何种语言（或字符集）表示的资源。例如如果服务器不能明确 客户端需要何种类型的资源，会返回300（Multiple Choices），并包含一个列表，用来声明该资源的不同可用版本，然后客户端在请求消息中包含Accept-Language和Accept- Charset头域指定需要的版本。

**⑥** **状态码**

100～199：信息状态码，表示成功接收请求，要求客户端继续提交下一次请求才能完成整个处理过程

100（continue）**继续发送**

200～299**：成功状态码**，表示成功接收请求并已完成整个处理过程，常用200（OK）成功接收

300～399**：重定向状态码**，例如，请求的资源已经移动一个新地址，常用302、307和304

400～499**：客户端的请求有错误**，常用404（Not Found），403（Fobidden）

500～599**：服务器端出现错误**，常用 500

## 8. HTTP请求和响应的全过程

## 9. HTTP有没有状态？

无状态，怎么解决HTTP无状态，怎么解决HTTP无状态其实就是怎么进行**会话跟踪**，有四种方法**：URL重写**、**隐藏表单域**、**Cookie**、**Session**。

## 10. HTTP常见响应码：200、301、302、404、500

**一、1开头**

**1xx(临时响应)**表示临时响应并需要请求者继续执行操作的状态代码。**代码 说明

**二、2开头**

**2xx (成功)**表示成功处理了请求的状态代码。

**200 (成功)** 服务器已成功处理了请求。通常，这表示服务器提供了请求的网页。

**三、3开头**

3xx (重定向) 表示要完成请求，需要进一步操作。通常，这些状态代码用来重定向。

**301(永久移动)** 请求的网页已永久移动到新位置。服务器返回此响应(对 GET 或 HEAD 请求的响应)时，会自动将请求者转到新位置。

**302 (临时移动)** 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。

**四、4开头**

4xx(请求错误) 这些状态代码表示请求可能出错，妨碍了服务器的处理。

- **403 (禁止)** 服务器拒绝请求。资源不可用。服务器理解客户的请求，但拒绝处理它。通常由于服务器上文件或目录的权限设置导致，比如IIS或者apache设置了访问权限不当。或者可能是客户端IP被列入黑名单等。
- **404 (未找到)** 服务器找不到请求的网页。
- **405 (方法禁用)** 禁用请求中指定的方法。

**五、5开头**

5xx(服务器错误)这些状态代码表示服务器在尝试处理请求时发生内部错误。 这些错误可能是服务器本身的错误，而不是请求出错。

- 500 (服务器内部错误) 服务器遇到错误，无法完成请求。
- 501 服务器不具备完成请求的功能 
- **502 错误网关、无效网关**
- 503 服务器不可用（超载或者停机维护，暂停的状态） 
- **504 网关超时**
- 505 http版本不受支持（请求使用的http协议版本服务器不支持）

## 11. get和post的区别

- GET在浏览器回退时是无害的，而POST会再次提交请求。
- GET产生的URL地址可以被Bookmark，而POST不可以。
- GET请求会被浏览器主动cache，而POST不会，除非手动设置。
- GET请求只能进行url编码，而POST支持多种编码方式。
- GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。
- GET请求在URL中传送的参数是有长度限制的，而POST没有。
- 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。
- GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。
- GET参数通过URL传递，POST放在Request body中。

## 12. forward和redirect的区别

**转发是服务器行为，重定向是客户端行为**。

**转发（Forword）** 通过RequestDispatcher对象的forward（HttpServletRequest request,HttpServletResponse response）方法实现的。RequestDispatcher 可以通过HttpServletRequest 的 getRequestDispatcher()方法获得。例如下面的代码就是跳转到 login_success.jsp 页面。

request.getRequestDispatcher("login_success.jsp").forward(request, response);

**重定向（Redirect）是利用服务器返回的状态吗来实现的**。客户端浏览器请求服务器的时候，服务器会返回一个状态码。服务器通过HttpServletRequestResponse的setStatus(int status)方法设置状态码。如果服务器返回301或者302，则浏览器会到新的网址重新请求该资源。

1. 从地址栏显示来说: forward是服务器请求资源,服务器直接访问目标地址的URL,把那个URL的响应内容读取过来,然后把这些内容再发给浏览器.浏览器根本不知道服务器发送的内容从哪里来的,所以它的地址栏还是原来的地址. redirect是服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址.所以地址栏显示的是新的URL.
2. 从数据共享来说: forward:转发页面和转发到的页面可以共享request里面的数据. redirect:不能共享数据.
3. 从运用地方来说: forward:一般用于用户登陆的时候,根据角色转发到相应的模块. redirect:一般用于用户注销登陆时返回主页面和跳转到其它的网站等
4. 从效率来说: forward:高. redirect:低.

## 13. osi七层模型

  ![](E:/Code/JavaLearning/java%E5%9F%BA%E7%A1%80/images/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B.gif)

## 14. TCP/IP四层模型及原理

  

## 15. 粘包、丢包

**粘包出现的原因**：在流传输中会出现（如TCP），UDP不会出现粘包（数据报传输）

- 发送端需要等缓冲区满才发送出去，造成粘包（nalge算法也可能造成粘包现象）
- 接收方不及时接收缓冲区的包，造成多个包接收



**粘包解决的办法**

- 一是对于发送方引起的粘包现象，用户可通过编程设置来避免，TCP提供了强制数据立即传送的操作指令push，TCP软件收到该操作指令后，就立即将本段数据发送出去，而不必等待发送缓冲区满；
- 二是对于接收方引起的粘包，则可通过优化程序设计、精简接收进程工作量、提高接收进程优先级等措施，使其及时接收数据，从而尽量避免出现粘包现象；
- 三是由接收方控制，将一包数据按结构字段，人为控制分多次接收，然后合并，通过这种手段来避免粘包

还有的笨方法是在两次send函数之间添加 sleep函数，显然会降低数据传输效率

以上提到的三种措施，都有其不足之处。

- 第一种编程设置方法虽然可以避免发送方引起的粘包，但它关闭了优化算法，降低了网络发送效率，影响应用程序的性能，一般不建议使用。
- 第二种方法只能减少出现粘包的可能性，但并不能完全避免粘包，当发送频率较高时，或由于网络突发可能使某个时间段数据包到达接收方较快，接收方还是有可能来不及接收，从而导致粘包。
- 第三种方法虽然避免了粘包，但应用程序的效率较低，对实时应用的场合不适合。 

**丢包的主要原因**

1. 接收端处理时间过长导致丢包：调用recv方法接收端收到数据后，处理数据花了一些时间，处理完后再次调用recv方法，在这二次调用间隔里，发过来的包可能丢失。对于这种情况可以修改接收端，将包接收后存入一个缓冲区，然后迅速返回继续recv.
2. 发送的包较大，超过接受者缓存导致丢包：包超过mtu size数倍，几个大的udp包可能会超过接收者的缓冲，导致丢包
3. 发送的包频率太快：虽然每个包的大小都小于mtu size 但是频率太快

**解决方案**

1. 模拟tcp三次握手协议，通过使用Timer定时器监视发送请求后接受数据的时间，如果一段时间内没有接受到数据包则判定丢包，并重新发送本次请求
2. 换TCP

## 16. 编写socket套接字的流程

**服务器端程序的编写步骤**：

第一步：调用socket()函数创建一个用于通信的套接字。

第二步：给已经创建的套接字绑定一个端口号，这一般通过设置网络套接口地址和调用bind()函数来实现。

第三步：调用listen()函数使套接字成为一个监听套接字。

第四步：调用accept()函数来接受客户端的连接，这是就可以和客户端通信了。

第五步：处理客户端的连接请求。

第六步：终止连接。

**客户端程序编写步骤**：

第一步：调用socket()函数创建一个用于通信的套接字。

第二步：通过设置套接字地址结构，说明客户端与之通信的服务器的IP地址和端口号。

第三步：调用connect()函数来建立与服务器的连接。

第四步：调用读写函数发送或者接收数据。

第五步：终止连接。

 

## 17. 子网划分

## 18. IPV4和IPV6

## 19. HTTPS和HTTP/2

## 20. Hibernate的session和http的session的区别

## 21. ServerSocketChannel和SocketChannel与ServerSoket和Socket的区别

**1.ServerSocket类**

创建一个ServerSocket类，同时在运行该语句的计算机的指定端口处建立一个监听服务，如：

ServerSocket MyListener=new ServerSocket(600)；

这里指定提供监听服务的端口是600，一台计算机可以同时提供多个服务，这些不同的服务之间通过端口号来区别，不同的端口号上提供不同的服务。为了随时监听可能的Client请求，执行如下的语句：

Socket LinkSocket=MyListener.accept()；

该语句调用了ServerSocket对象的accept()方法，这个方法的执行将使Server端的程序处于等待状态，程序将一直阻塞直到捕捉到一个来自Client端的请求，并返回一个用于与该Client通信的Socket对象Link-Socket。此后Server程序只要向这个Socket对象读写数据，就可以实现向远端的Client读写数据。结束监听时，关闭ServerSocket对象：Mylistener.close()；

**2.Socket类**

当Client程序需要从Server端获取信息及其他服务时，应创建一个Socket对象：

Socket mySocket=new Socket(“ServerComputerName”，600)；

Socket类的构造函数有两个参数，第一个参数是欲连接到的Server计算机的主机地址，第二个参数是该Server机上提供服务的端口号。

Socket对象建立成功之后，就可以在Client和Server之间建立一个连接，并通过这个连接在两个端点之间传递数据。利用Socket类的方法getOutputStream()和getInputStream()分别获得向Socket读写数据的输入／输出流，最后将从Server端读取的数据重新返还到Server端。

当Server和Client端的通信结束时，可以调用Socket类的close()方法关闭Socket，拆除连接。

**ServerSocket** **一般仅用于设置端口号和监听，真正进行通信的是服务器端的Socket与客户端的Socket，在ServerSocket进行accept之后，就将主动权转让了。**

 

Socket、SocketChannel二者的实质都是一样的，都是为了实现客户端与服务器端的连接而存在的，但是在使用上，却有很大的区别。具体如下：

**所属包不同**：Socket在java.net包中，而SocketChannel在java.nio包中。

**异步方式不同**：从包的不同，我们大体可以推断出他们主要的区别：Socket是阻塞连接（当然我们可以自己实现非阻塞），SocketChannel可以设置非阻塞连接。 使用ServerSocket、Socket类时，服务端Socket往往要为每一个客户端Socket分配一个线程，而每一个线程都有可能处于长时间的阻塞状态中。过多的线程也会影响服务器的性能（可以使用线程池优化，具体看这里：如何编写多线程Socket程序）。而使用SocketChannel、ServerSocketChannel类可以非阻塞通信，这样使得服务器端只需要一个线程就能处理所有客户端socket的请求。

**性能不同**：一般来说使用SocketChannel会有更好的性能。其实，Socket实际应该比SocketChannel更高效，不过由于使用者设计等原因，效率反而比直接使用SocketChannel低。

**使用方式不同**：Socket、ServerSocket类可以传入不同参数直接实例化对象并绑定ip和端口。

# 数据库与高并发

## 1. 范式

范式：英文名称是 Normal Form，它是英国人 E.F.Codd（关系数据库的老祖宗）在上个世纪70年代提出关系数据库模型后总结出来的，范式是关系数据库理论的基础，也是我们在设计数据库结构过程中所要遵循的规则和指导方法。目前有迹可寻的共有8种范式，依次是：1NF，2NF，3NF，BCNF，4NF，5NF，DKNF，6NF。通常所用到的只是前三个范式，即**：第一范式（1NF）**，**第二范式（2NF）**，**第三范式（3NF）**。

设计关系数据库时，遵从不同的规范要求，设计出合理的关系型数据库，这些不同的规范要求被称为不同的范式，各种范式呈递次规范，越高的范式数据库冗余越小。

目前关系数据库有六种范式：第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴斯-科德范式（BCNF）、第四范式(4NF）和第五范式（5NF，又称完美范式）。满足最低要求的范式是第一范式（1NF）。在第一范式的基础上进一步满足更多规范要求的称为第二范式（2NF），其余范式以次类推。一般说来，数据库只需满足第三范式(3NF）就行了。

下面就简单介绍下这三个范式。

1) **第一范式（1NF**）

强调的是列的**原子性**，即列不能够再分成其他几列。 

考虑这样一个表：【联系人】（姓名，性别，电话） 

如果在实际场景中，一个联系人有家庭电话和公司电话，那么这种表结构设计就没有达到 1NF。要符合 1NF 我们只需把列（电话）拆分，即：【联系人】（姓名，性别，家庭电话，公司电话）。1NF 很好辨别，但是 2NF 和 3NF 就容易搞混淆。 

说明：在任何一个关系数据库中，第一范式（1NF）是对关系模式的设计基本要求，一般设计中都必须满足第一范式（1NF）。不过有些关系模型中突破了1NF的限制，这种称为非1NF的关系模型。换句话说，是否必须满足1NF的最低要求，主要依赖于所使用的关系模型。

2) **第二范式（2NF**）

首先是 1NF，另外包含两部分内容，一是表必须有一个主键；二是没有包含在主键中的列必须完全依赖于主键，而不能只依赖于主键的一部分。 

考虑一个订单明细表：【OrderDetail】（OrderID，ProductID，UnitPrice，Discount，Quantity，ProductName）。 

因为我们知道在一个订单中可以订购多种产品，所以单单一个 OrderID 是不足以成为主键的，主键应该是（OrderID，ProductID）。显而易见 Discount（折扣），Quantity（数量）完全依赖（取决）于主键（OderID，ProductID），而 UnitPrice，ProductName 只依赖于 ProductID。所以 OrderDetail 表不符合 2NF。不符合 2NF 的设计容易产生冗余数据。 

可以把【OrderDetail】表拆分为【OrderDetail】（OrderID，ProductID，Discount，Quantity）和【Product】（ProductID，UnitPrice，ProductName）来消除原订单表中UnitPrice，ProductName多次重复的情况。

第二范式（2NF）要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性，如果存在，那么这个属性和主关键字的这一部分应该分离出来形成一个新的实体，新实体与原实体之间是一对多的关系。为实现区分通常需要为表加上一个列，以存储各个实例的唯一标识。简而言之，第二范式就是在第一范式的基础上属性完全依赖于主键。

3) **第三范式（3NF）**

在1NF基础上，任何非主属性不依赖于其它非主属性[在2NF基础上消除传递依赖。

第三范式（3NF）是第二范式（2NF）的一个子集，即满足第三范式（3NF）必须满足第二范式（2NF）。

首先是 2NF，另外非主键列必须直接依赖于主键，不能存在传递依赖。即不能存在：非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况。 考虑一个订单表【Order】（OrderID，OrderDate，CustomerID，CustomerName，CustomerAddr，CustomerCity）主键是（OrderID）。 

其中 OrderDate，CustomerID，CustomerName，CustomerAddr，CustomerCity 等非主键列都完全依赖于主键（OrderID），所以符合 2NF。不过问题是 CustomerName，CustomerAddr，CustomerCity 直接依赖的是 CustomerID（非主键列），而不是直接依赖于主键，它是通过传递才依赖于主键，所以不符合 3NF。 

通过拆分【Order】为【Order】（OrderID，OrderDate，CustomerID）和【Customer】（CustomerID，CustomerName，CustomerAddr，CustomerCity）从而达到 3NF。 

第二范式（2NF）和第三范式（3NF）的概念很容易混淆，区分它们的关键点在于，2NF**：非主键列是否完全依赖于主键，还是依赖于主键的一部分**；3NF**：非主键列是直接依赖于主键，还是直接依赖于非主键列**。

 

## 2. 数据库事务和隔离级别

如果一个数据库声称支持事务的操作，那么该数据库必须要具备以下四个特性：

**⑴** **原子性（Atomicity）**

原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。

**⑵** **一致性（Consistency）**

一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。

拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。

**⑶** **隔离性（Isolation）**

隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。

即要达到这么一种效果：对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。

关于事务的隔离性数据库提供了多种隔离级别，稍后会介绍到。

**⑷** **持久性（Durability）**

持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。

例如我们在使用JDBC操作数据库时，在提交事务方法后，提示用户事务操作完成，当我们程序执行完成直到看到提示后，就可以认定事务以及正确提交，即使这时候数据库出现了问题，也必须要将我们的事务完全执行完成，否则就会造成我们看到提示事务处理完毕，但是数据库因为故障而没有执行事务的重大错误。

以上介绍完事务的四大特性(简称ACID)，现在重点来说明下事务的**隔离性**，当多个线程都开启事务操作数据库中的数据时，数据库系统要能进行隔离操作，以保证各个线程获取数据的准确性，在介绍数据库提供的各种隔离级别之前，我们先看看如果不考虑事务的隔离性，会发生的几种问题：

**1，脏读**

脏读是指在一个事务处理过程里读取了另一个**未提交的事务**中的数据。

当一个事务正在多次修改某个数据，而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致。

1.Mary的原工资为1000, 财务人员将Mary的工资改为了8000(但未提交事务) ；

2.Mary读取自己的工资 ,发现自己的工资变为了8000，欢天喜地！

3.而财务发现操作有误，回滚了事务,Mary的工资又变为了1000。

像这样,Mary记取的工资数8000是一个脏数据。

**2，不可重复读**

不可重复读是指在对于数据库中的某个数据，**一个事务范围内**多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。

例如事务T1在读取某一数据，而事务T2立马修改了这个数据并且提交事务给数据库，事务T1再次读取该数据就得到了不同的结果，发送了不可重复读。

不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了前一事务提交的数据。

在某些情况下，不可重复读并不是问题，比如我们多次查询某个数据当然以最后查询得到的结果为主。但在另一些情况下就有可能发生问题，例如对于同一个数据A和B依次查询就可能不同，A和B就可能打起来了……

**3，虚读(幻读)**

幻读是**事务非独立执行**时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。

幻读和不可重复读都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。

现在来看看MySQL数据库为我们提供的四种隔离级别：

1. Read uncommitted (读未提交)：最低级别，任何情况都无法保证。
2. Read committed (读已提交)：可避免脏读的发生。
3. Repeatable read (可重复读)：可避免脏读、不可重复读的发生。
4. Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。



## 3. 为什么需要锁，锁定分类，锁粒度

**为什么需要锁**：

数据库是一个多用户使用的共享资源。当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。加锁是实现数据库并发控制的一个非常重要的技术。当事务在对某个数据对象进行操作前，先向系统发出请求，对其加锁。加锁后事务就对该数据对象有了一定的控制，在该事务释放锁之前，其他的事务不能对此数据对象进行更新操作。

**锁的分类**：

**共享（S）锁**：多个事务可封锁一个共享页；任何事务都不能修改该页；通常是该页被读取完毕，S锁立即被释放。 

**排它（X）锁**：仅允许一个事务封锁此页；其他任何事务必须等到X锁被释放才能对该页进行访问；X锁一直到事务结束才能被释放。 

**更新（U）锁**：更新锁在修改操作的初始化阶段用来锁定可能要被修改的资源，这样可以避免使用共享锁造成的死锁现象。因为使用共享锁时，修改数据的操作分为两步，首先获得一个共享锁，读取数据，然后将共享锁升级为排它锁，然后再执行修改操作。这样如果同时有两个或多个事务同时对一个事务申请了共享锁，在修改数据的时候，这些事务都要将共享锁升级为排它锁。这时，这些事务都不会释放共享锁而是一直等待对方释放，这样就造成了死锁。如果一个数据在修改前直接申请更新锁，在数据修改的时候再升级为排它锁，就可以避免死锁。



**锁的粒度**：

1) **行级锁定（row-level）**

行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

缺陷：由于锁定资源的颗粒度很小，所以每次获取锁和释放锁需要做的事情也更多，带来的消耗自然也就更大了。此外，行级锁定也最容易发生死锁。

2) **表级锁定（table-level）**

表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。

缺陷：锁定颗粒度大所带来最大的负面影响就是出现锁定资源争用的概率也会最高，致使并发度大打折扣。

3) **页级锁定（page-level）**：（MySQL特有）

页级锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。

缺陷：页级锁定和行级锁定一样，会发生死锁。

## 4. 乐观锁，悲观锁的概念及实现方式

**悲观锁（Pessimistic Lock）**，顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。

悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。

Java synchronized 就属于悲观锁的一种实现，每次线程要修改数据时都先获得锁，保证同一时刻只有一个线程能操作数据，其他线程则会被block。

**乐观锁（Optimistic Lock**）**，顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在提交更新的时候会判断一下在此期间别人有没有去更新这个数据。乐观锁适用于**读多写少**的应用场景，这样可以提高吞吐量。

乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。

乐观锁一般来说有以下2种方式：

- 使用**数据版本（Version）**记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。
- 使用**时间戳（timestamp）**。乐观锁定的第二种实现方式和第一种差不多，同样是在需要乐观锁控制的table中增加一个字段，名称无所谓，字段类型使用时间戳（timestamp）, 和上面的version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。

Java JUC中的atomic包就是乐观锁的一种实现，AtomicInteger 通过CAS（Compare And Set）操作实现线程安全的自增。

**乐观锁与悲观锁的区别**

乐观锁的思路一般是表中增加版本字段，更新时where语句中增加版本的判断，算是一种CAS（Compare And Swep）操作，商品库存场景中number起到了版本控制（相当于version）的作用（ AND number=#{number}）。

悲观锁之所以是悲观，在于他认为本次操作会发生并发冲突，所以一开始就对商品加上锁（SELECT ... FOR UPDATE），然后就可以安心的做判断和更新，因为这时候不会有别人更新这条商品库存。

## 5. 分页如何实现（Oracle，MySql）

一般对MySQL数据库分页，我们都会使用到其自带的limit函数。

语法：select * from users limit 10,5;（limit offset,rowsmys）

## 6. Mysql引擎

InnoDB和MyIsam

[参考链接](https://blog.csdn.net/Jack__Frost/article/details/72904318)

MyISAM是MySQL的默认数据库引擎（5.5版之前），由早期的ISAM（Indexed Sequential Access Method：有索引的顺序访问方法）所改良。虽然性能极佳，但却有一个缺点**：不支持事务处理（**transaction**）**。不过，在这几年的发展下，MySQL也导入了InnoDB（另一种数据库引擎），以强化参考完整性与并发违规处理机制，后来就逐渐取代MyISAM。

InnoDB，是MySQL的数据库引擎之一，为MySQL AB发布binary的标准之一。InnoDB由Innobase Oy公司所开发，2006年五月时由甲骨文公司并购。与传统的ISAM与MyISAM相比，InnoDB的最大特色就是支持了ACID兼容的事务（Transaction）功能，类似于PostgreSQL。目前InnoDB采用双轨制授权，一是GPL授权，另一是专有软件授权。

MyISAM与InnoDB的区别是什么？

**1、存储结构**

MyISAM：每个MyISAM在磁盘上存储成三个文件。第一个文件的名字以表的名字开始，扩展名指出文件类型。.frm文件存储表定义。数据文件的扩展名为.MYD (MYData)。索引文件的扩展名是.MYI (MYIndex)。

InnoDB：所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB。

**2、存储空间**

MyISAM：可被压缩，存储空间较小。支持三种不同的存储格式：静态表(默认，但是注意数据末尾不能有空格，会被去掉)、动态表、压缩表。

InnoDB：需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引。

**3、可移植性、备份及恢复**

MyISAM：数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作。

InnoDB：免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了。

**4、事务支持**

MyISAM：强调的是性能，每次查询具有原子性,其执行数度比InnoDB类型更快，但是不提供事务支持。

InnoDB：提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。

**5、AUTO_INCREMENT**

MyISAM：可以和其他字段一起建立联合索引。引擎的自动增长列必须是索引，如果是组合索引，自动增长可以不是第一列，他可以根据前面几列进行排序后递增。

InnoDB：InnoDB中必须包含只有该字段的索引。引擎的自动增长列必须是索引，如果是组合索引也必须是组合索引的第一列。

**6、表锁差异**

MyISAM：只支持表级锁，用户在操作myisam表时，select，update，delete，insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。

InnoDB**：支持事务和行级锁，是innodb的最大特色**。行锁大幅度提高了多用户并发操作的新能。但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。

**7、全文索引**

MyISAM：支持 FULLTEXT类型的全文索引

InnoDB：不支持FULLTEXT类型的全文索引，但是innodb可以使用sphinx插件支持全文索引，并且效果更好。

**8、表主键**

MyISAM：允许没有任何索引和主键的表存在，索引都是保存行的地址。

InnoDB：如果没有设定主键或者非空唯一索引，就会自动生成一个6字节的主键(用户不可见)，数据是主索引的一部分，附加索引保存的是主索引的值的数据列。

**9、表的具体行数**

MyISAM：保存有表的总行数，如果select count() from table;会直接取出出该值。

InnoDB：没有保存表的总行数，如果使用select count() from table；就会遍历整个表，消耗相当大，但是在加了wehre条件后，myisam和innodb处理的方式都一样。

**10、CURD操作**

MyISAM：如果执行大量的SELECT，MyISAM是更好的选择。

InnoDB：如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表。DELETE 从性能上InnoDB更优，但DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除，在innodb上如果要清空保存有大量数据的表，最好使用truncate table这个命令。

**11、外键**

MyISAM：不支持

InnoDB：支持

通过上述的分析，基本上可以考虑使用InnoDB来替代MyISAM引擎了，原因是InnoDB自身很多良好的特点，比如事务支持、存储 过程、视图、行级锁定等等，在并发很多的情况下，相信InnoDB的表现肯定要比MyISAM强很多。另外，任何一种表都不是万能的，只用恰当的针对业务类型来选择合适的表类型，才能最大的发挥MySQL的性能优势。如果不是很复杂的Web应用，非关键应用，还是可以继续考虑MyISAM的，这个具体情况可以自己斟酌。 

**存储引擎选择的基本原则**：

**采用MyISAM引擎**：

- R/W > 100:1 且update相对较少
- 并发不高
- 表数据量小
- 硬件资源有限

**采用InnoDB引擎**

- R/W比较小，频繁更新大字段
- 表数据量超过1000万，并发高
- 安全性和可用性要求高

**采用Memory引擎**

- 有足够的内存
- 对数据一致性要求不高，如在线人数和session等应用
- 需要定期归档数据

## 7. MYSQL语句优化

## 8. 索引以及索引的实现(B+树介绍、和B树、R树区别)

### 索引

> 按照**存储类型**分为：B树、B+树、Hash
>
> > **B+ Tree索引和Hash索引区别**: 哈希索引适合等值查询，但是不无法进行范围查询，哈希索引没办法利用索引完成排序，哈希索引不支持多列联合索引的最左匹配规则，如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题。
>
> 按照**索引类别**分为：聚集索引、非聚集索引

- **聚集索引**： 按照每张表的主键构造一棵B+树，同时**叶子节点中存放的即为整张表的行记录数据**，也将聚集索引的叶子节点称为数据页。每张表只能拥有**一个**聚集索引。在多数情况下，查询优化器倾向于采用聚集索引，因为聚集索引能够在B+树索引的叶子节点上直接找到数据。**注意**：聚集索引并不是在物理存储上是连续的，其只是在逻辑上连续。这有两点：1、数据页是按照**主键的顺序**并通过双向链表链接的，因此物理存储上可以不按主键顺序存储。2、数据页中的记录也是通过**双向链表**进行维护的，物理存储上同样可以不按主键顺序存储。
- **辅助索引**(也称**非聚集索引**)：叶子节点并不包含行记录的全部数据。
- **联合索引**：联合索引是指同时对表上的多个列进行索引。
- **覆盖索引**：从辅助索引中就可以得到查询记录，而不需要查询聚集索引中的记录。使用覆盖索引的一个好处是辅助索引不包含整行记录的所有信息也不需要回表查询，故其大小要远小于聚集索引，因此可以减少大量的IO操作。
- **全文检索**：全文检索是将存储于数据库中的整本书或整篇文章中的任意内容信息查找出来的技术。它可以根据需要获得全文中有关章、节、段、句、词等信息，也可以进行各种统计和分析。

​    [参考链接1]( https://zhuanlan.zhihu.com/p/23624390)

​    [参考链接2](https://zhuanlan.zhihu.com/p/27700617)

### 联合索引、最左前缀匹配

在创建多列索引时，我们根据业务需求，where子句中使用最频繁的一列放在最左边，因为MySQL索引查询会遵循最左前缀匹配的原则，即最左优先，在检索数据时**从联合索引的最左边开始匹配**。所以当我们创建一个联合索引的时候，如(key1,key2,key3)，相当于创建了（key1）、(key1,key2)和(key1,key2,key3)三个索引，这就是最左匹配原则。

### 索引下推、查询优化

**Index Condition Pushdown（索引下推）**：MySQL 5.6引入了索引下推优化，默认开启，使用SET optimizer_switch = ‘index_condition_pushdown=off’;可以将其关闭。官方文档中给的例子和解释如下： people表中（zipcode，lastname，firstname）构成一个索引：`SELECT * FROM people WHERE zipcode=‘95054’ AND lastname LIKE ‘%etrunia%’ AND address LIKE ‘%Main Street%’;`

如果没有使用索引下推技术，则MySQL会通过zipcode='95054’从存储引擎中查询对应的数据，返回到MySQL服务端，然后MySQL服务端基于lastname LIKE '%etrunia%'和address LIKE '%Main Street%'来判断数据是否符合条件。 如果使用了索引下推技术，则MYSQL首先会返回符合zipcode='95054’的索引，然后根据lastname LIKE '%etrunia%'和address LIKE '%Main Street%'来判断索引是否符合条件。如果符合条件，则根据该索引来定位对应的数据，如果不符合，则直接reject掉。 有了索引下推优化，可以在有like条件查询的情况下，减少回表次数。

## 9. 从一张大表读取数据，如何解决性能问题

第一**优化SQL语句和索引**；

第二加**缓存**，memcached，redis；

第三以上都做了后，还是慢，就做主从复制或主主复制，**读写分离**，可以在应用层做，效率高，也可以用三方工具，第三方工具推荐360的atlas,其它的要么效率不高，要么没人维护；

第四如果以上都做了还是慢，不要想着去做切分，**mysql自带分区表**，先试试这个，对你的应用是透明的，无需更改代码，但是sql语句是需要针对分区表做优化的，sql条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区，另外分区表还有一些坑，在这里就不多说了；

第五如果以上都做了，那就先做**垂直拆分**，其实就是根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；

第六才是**水平切分**，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key，为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；

------

### 读写分离

**1. what 读写分离**
读写分离，基本的原理是让**主数据库处理事务性增、改、删操作**（INSERT、UPDATE、DELETE），而**从数据库处理SELECT查询**操作。数据库复制被用来把事务性操作导致的变更同步到集群中的从数据库。

**2. why 那么为什么要读写分离呢？** 
因为数据库的“写”（写10000条数据到oracle可能要3分钟）操作是比较耗时的。 
但是数据库的“读”（从oracle读10000条数据可能只要5秒钟）。 
所以读写分离，解决的是，**数据库的写入，影响了查询的效率**。

**3. when 什么时候要读写分离？**
数据库不一定要读写分离，如果程序使用数据库较多时，而更新少，查询多的情况下会考虑使用，利用数据库**主从同步**。可以减少数据库压力，提高性能。当然，数据库也有其它优化方案。memcache 或是 表折分，或是搜索引擎。都是解决方法。

**4. 主从复制与读写分离**
在实际的生产环境中，对数据库的读和写都在同一个数据库服务器中，是不能满足实际需求的。无论是在安全性、高可用性还是高并发等各个方面都是完全不能满足实际需求的。因此，通过**主从复制**的方式来同步数据，再通过**读写分离**来提升数据库的并发负载能力。

![](E:/Code/JavaLearning/java%E5%9F%BA%E7%A1%80/images/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.png)

**4.1. MySQL支持的复制类型**

1. **基于语句的复制**。在服务器上执行sql语句，在从服务器上执行同样的语句，mysql**默认采用基于语句的复制，执行效率高**。
   **存在的问题**：时间上可能不完全同步造成偏差，执行语句的用户也可能是不同的用户。

2. **基于于行的复制**。把改变的内容复制过去，而不是把命令在从服务器上执行一遍。
   **存在的问题**：比如一个工资表中有一万个用户，我们把每个用户的工资+1000，那么基于行的复制则要复制一万行的内容，由此造成的开销比较大，而基于语句的复制仅仅一条语句就可以了。

3. **混合类型的复制**。默认采用基于语句的复制，一旦发现基于语句无法精确复制时，就会采用基于行的复制。

   以上两种方式都是通过**在主库上记录二进制日志，在备库重放日志的方式来实现异步的数据复制**。这意味着，同一时间点上备库中的数据可能与主库不一致。复制通常不会增加主库的开销，主要是启用二进制日志带来的开销，但出于备份或及时从崩溃中恢复的目的，这点开销是必要的。

**如何复制**

1. 在主库上把数据更改记录到**二进制日志（Binary Log）**中（这些记录被称为二进制日志事件）
2. 备库将主库上的日志复制到自己的**中继日志（Relay Log）** 中。
3. 备库读取中继日志中的事件，将其重放到备库数据之上。
   ![](E:/Code/JavaLearning/java%E5%9F%BA%E7%A1%80/images/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B62.png)下面

  

**主从复制常见问题**

1. 从库数据比主库数据慢，有**延时**
2. 如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了

  **解决方案**：一个是**半同步复制**，用来解决主库数据丢失问题；一个是**并行复制**，用来解决主从同步延时问题。

  **半同步复制**，也叫 `semi-sync` 复制，指的就是主库写入 binlog 日志之后，就会将**强制**此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到**至少一个从库**的 ack 之后才会认为写操作完成了。

  **并行复制**，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后**并行重放不同库的日志**，这是库级别的并行。

  一般来说，如果主从延迟较为严重，有以下解决方案：

- 分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。
- 打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。
- 重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。
- 如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询**设置直连主库**。**不推荐**这种方法，你要是这么搞，读写分离的意义就丧失了。

  **针对MySQL主从复制原理的重点小结**

  - 主从复制是异步的逻辑的SQL语句级的复制

  - 复制时，主库有一个I/O线程，从库有两个线程，I/O和SQL线程。
  - 作为复制的所有MySQL节点的server-id都不能相同。
  - binlog文件只记录对数据库有更改的SQL语句（来自数据库内容的变更），不记录任何查询（select，slow）语句。

----


### 分区表

[参考链接](http://mysql.taobao.org/monthly/2017/11/09/)

**概述**
随着MySQL越来越流行，MySQL里面的保存的数据也越来越大。在日常的工作中，我们经常遇到一张表里面保存了上亿甚至过十亿的记录。这些表里面保存了大量的历史记录。 对于这些历史数据的清理是一个非常头疼事情，由于所有的数据都在一个普通的表里。所以只能是启用一个或多个带where条件的delete语句去删除（一般where条件是时间）。 这对数据库的造成了很大压力。即使我们把这些删除了，但底层的数据文件并没有变小。面对这类问题，最有效的方法就是在使用分区表。最常见的分区方法就是按照时间进行分区。 分区一个最大的优点就是可以**非常高效的进行历史数据的清理**


**分区类型**
目前MySQL支持**范围分区（RANGE）**，**列表分区（LIST）**，**哈希分区（HASH）**以及**KEY分区**四种。


**总结**
1. MySQL分区中如果存在主键或唯一键，则分区列必须包含在其中。
2. 对于原生的RANGE分区，LIST分区，HASH分区，分区对象返回的只能是整数值。
3. 分区字段不能为NULL，要不然怎么确定分区范围呢，所以尽量NOT NULL

**优点**

1. 大表数据分区，查询时优化器根据分区定义，无须扫描所有分区，只查找需要数据的分区
2. 批量删除整个分区十分方便

**缺点**
1. 一个表最多只能有1024个分区
2. 在分区表上，用于分区表达式里的每一个字段都必须是唯一性索引的一部分(包括主键)
3. 分区表中无法使用外键
4. 分区键不可以为NULL
5. 分区列和索引列不匹配导致无法进行分区过滤

----
### 分库分表

[参考链接](https://juejin.im/entry/5b5eb7f2e51d4519700f7d3c)

分库分表的方式方法
一般就是**垂直切分**和**水平切分**，这是一种结果集描述的切分方式，是物理空间上的切分。 我们从面临的问题，开始解决，阐述： 首先是用户请求量太大，我们就堆机器搞定。

---
#### 垂直拆分

1. **垂直分库**

   垂直分库针对的是一个系统中的不同业务进行拆分，比如用户User一个库，商品Producet一个库，订单Order一个库。 切分后，要放在多个服务器上，而不是一个服务器上。为什么？ 我们想象一下，一个购物网站对外提供服务，会有用户，商品，订单等的CRUD。没拆分之前， 全部都是落到单一的库上的，这会让数据库的单库处理能力成为瓶颈。按垂直分库后，如果还是放在一个数据库服务器上， 随着用户量增大，这会让单个数据库的处理能力成为瓶颈，还有单个服务器的磁盘空间，内存，tps等非常吃紧。 所以我们要拆分到多个服务器上，这样上面的问题都解决了，以后也不会面对单机资源问题。

   数据库业务层面的拆分，和服务的“治理”，“降级”机制类似，也能对不同业务的数据分别的进行管理，维护，监控，扩展等。 数据库往往最容易成为应用系统的瓶颈，而数据库本身属于“有状态”的，相对于Web和应用服务器来讲，是比较难实现“横向扩展”的。 数据库的连接资源比较宝贵且单机处理能力也有限，在高并发场景下，垂直分库一定程度上能够突破IO、连接数及单机硬件资源的瓶颈。

2. **垂直分表**

   也就是“大表拆小表”，基于**列字段**进行的。一般是表中的字段较多，将不常用的， 数据较大，长度较长（比如text类型字段）的拆分到“扩展表“。 一般是针对那种几百列的大表，也避免查询时，数据量太大造成的“跨页”问题。

   **优点**：
   - 便于开发与维护
   - 避免跨页问题
   - 行字段少的时候，内存能加载更多数据，命中率更高，减少磁盘IO，提高数据库性能。

   **垂直切分的优点**：
   * 解决业务系统层面的耦合，业务清晰
   * 与微服务的治理类似，也能对不同业务的数据进行分级管理、维护、监控、扩展等
   * 高并发场景下，垂直切分一定程度的提升IO、数据库连接数、单机硬件资源的瓶颈

   **缺点**：
   * 部分表无法join，只能通过接口聚合方式解决，提升了开发的复杂度
   
   * 分布式事务处理复杂
   
   * 依然存在单表数据量过大的问题（需要水平切分）

----
#### 水平拆分

1. **水平分表**

   针对数据量巨大的单张表（比如订单表），按照某种规则（RANGE,HASH取模等），切分到多张表里面去。 但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。不建议采用。

2. **水平分库分表**

   将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。 水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。

   **水平切分的优点**：

   - 不存在单库数据量过大、高并发的性能瓶颈，提升系统稳定性和负载能力
   - 应用端改造较小，不需要拆分业务模块

   **缺点**：

   - 跨分片的事务一致性难以保证
   - 跨库的join关联查询性能较差
   - 数据多次扩展难度和维护量极大

3. **水平分库分表切分规则**

	- **Range（时间、ID）**：从0到10000一个表，10001到20000一个表；或者按照时间分到不同的表中。
     **优点**：
     * 单表大小可控
     * 天然便于水平扩展，后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片的数据进行迁移
     * 使用分片字段进行范围查找时，连续分片可快速定位分片进行快速查询，有效避免跨分片查询的问题。
     
     **缺点**：

	  * 热点数据成为性能瓶颈。连续分片可能存在数据热点，例如按时间字段分片，有些分片存储最近时间段内的数据，可能会被频繁的读写，而有些分片存储的历史数据，则很少被查询。
   
	- **Hash取模**：一个商场系统，一般都是将用户，订单作为主表，然后将和它们相关的作为附表，这样不会造成跨库事务之类的问题。 取用户id，然后hash取模，分配到不同的数据库上。
	  **优点**：
   
   - 数据分片相对比较均匀，不容易出现热点和并发访问的瓶颈
     
     **缺点**：
      - 后期分片集群扩容时，需要迁移旧的数据（使用一致性hash算法能较好的避免这个问题）
      - 容易面临跨分片查询的复杂问题。比如上例中，如果频繁用到的查询条件中不带cusno时，将会导致无法定位数据库，从而需要同时向4个库发起查询，再在内存中合并数据，取最小集返回给应用，分库反而成为拖累。

---
### 分库分表带来的问题

[参考链接](https://zhuanlan.zhihu.com/p/70025377)

- **事务一致性问题**

  分布式事务：跨分片事务也就是分布式事务，没有简单的方案，一般可使用“XA协议”和“两阶段提交”处理。

  最终一致性：对于那些性能要求很高，但对一致性要求不高的系统，往往不苛求系统的实时一致性，只要在允许的时间段内达到最终一致性即可，可采用事务补偿的方式。

- **跨节点关联查询join问题**

  切分之前，系统中很多列表和详情页所需的数据可以通过sql join来完成。而切分之后，数据可能分布在不同的节点上，此时join带来的问题就比较麻烦了，考虑到性能，尽量避免使用join查询。

  解决这个问题的一些方法：

  **1）全局表**

  全局表，也可看做是"数据字典表"，就是系统中所有模块都可能依赖的一些表，为了避免跨库join查询，可以将这类表在每个数据库中都保存一份。这些数据通常很少会进行修改，所以也不担心一致性的问题。

  **2）字段冗余**

  一种典型的反范式设计，利用空间换时间，为了性能而避免join查询。例如：订单表保存userId时候，也将userName冗余保存一份，这样查询订单详情时就不需要再去查询"买家user表"了。

  但这种方法适用场景也有限，比较适用于依赖字段比较少的情况。而冗余字段的数据一致性也较难保证，就像上面订单表的例子，买家修改了userName后，是否需要在历史订单中同步更新呢？这也要结合实际业务场景进行考虑。

  **3）数据组装**

  在系统层面，分两次查询，第一次查询的结果集中找出关联数据id，然后根据id发起第二次请求得到关联数据。最后将获得到的数据进行字段拼装。

  **4）ER分片**

  关系型数据库中，如果可以先确定表之间的关联关系，并将那些存在关联关系的表记录存放在同一个分片上，那么就能较好的避免跨分片join问题。在1:1或1:n的情况下，通常按照主表的ID主键切分。如下图所示：![](E:\Code\JavaLearning\java基础\images\ER分片.jpg)

  这样一来，Data Node1上面的order订单表与orderdetail订单详情表就可以通过orderId进行局部的关联查询了，Data Node2上也一样。 

- **跨节点分页、排序、函数问题**

  跨节点多库进行查询时，会出现limit分页、order by排序等问题。分页需要按照指定字段进行排序，**当排序字段就是分片字段时，通过分片规则就比较容易定位到指定的分片**；当排序字段非分片字段时，就变得比较复杂了。

  需要**先在不同的分片节点中将数据进行排序并返回，然后将不同分片返回的结果集进行汇总和再次排序**，最终返回给用户。如图所示：![](.\images\分片排序.jpg)

  在使用Max、Min、Sum、Count之类的函数进行计算的时候，也需要先在每个分片上执行相应的函数，然后将各个分片的结果集进行汇总和再次计算，最终将结果返回。

- **全局主键避重问题**

  在分库分表环境中，由于表中数据同时存在不同数据库中，主键值平时使用的自增长将无用武之地，某个分区数据库自生成的ID无法保证全局唯一。因此需要单独设计全局主键，以避免跨库主键重复问题。有一些常见的主键生成策略：

  **1）UUID**

  + UUID标准形式包含32个16进制数字，分为5段，形式为8-4-4-4-12的36个字符，例如：550e8400-e29b-41d4-a716-446655440000

  + UUID是主键是最简单的方案，本地生成，性能高，没有网络耗时。但缺点也很明显，由于UUID非常长，会占用大量的存储空间；另外，作为主键建立索引和基于索引进行查询时都会存在性能问题，在InnoDB下，UUID的无序性会引起数据位置频繁变动，导致分页。

  **2）Snowflake分布式自增ID算法**

  Twitter的snowflake算法解决了分布式系统生成全局ID的需求，生成64位的Long型数字，组成部分：

  - 第一位未使用

  - 接下来41位是毫秒级时间，41位的长度可以表示69年的时间

  - 5位datacenterId，5位workerId。10位的长度最多支持部署1024个节点

  - 最后12位是毫秒内的计数，12位的计数顺序号支持每个节点每毫秒产生4096个ID序列

    ![](.\images\snowflake.jpg)

    **优点**：毫秒数在高位，生成的ID整体上按时间趋势递增；不依赖第三方系统，稳定性和效率较高，理论上QPS约为409.6w/s（$1000*2^{12}$），并且整个分布式系统内不会产生ID碰撞；可根据自身业务灵活分配bit位。

    **缺点**：强依赖机器时钟，如果时钟回拨，则可能导致生成ID重复。  

- **数据迁移、扩容问题**

  当业务高速发展，面临性能和存储的瓶颈时，才会考虑分片设计，此时就不可避免的需要考虑历史数据迁移的问题。一般做法是先读出历史数据，然后按指定的分片规则再将数据写入到各个分片节点中。

  此外还需要根据当前的数据量和QPS，以及业务发展的速度，进行容量规划，推算出大概需要多少分片（一般建议单个分片上的单表数据量不超过1000W）

  如果采用数值范围分片，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。如果采用的是数值取模分片，则考虑后期的扩容问题就相对比较麻烦。




然后是单个库太大，这时我们要看是因为表多而导致数据多，还是因为单张表里面的数据多。 如果是因为**表多而数据多，使用垂直切分**，根据业务切分成不同的库。

如果是因为**单张表的数据量太大，这时要用水平切分**，即把表的数据按某种规则切分成多张表，甚至多个库上的多张表。 分库分表的顺序应该是先垂直分，后水平分。 因为垂直分更简单，更符合我们处理现实世界问题的方式。



## 10. 内连接，左连接，右连接作用及区别

**A.**  **内连接**

1.1.等值连接：在连接条件中使用等于号(=)运算符比较被连接列的列值，其查询结果中列出被连接表中的所有列，包括其中的重复列。

1.2.不等值连接：在连接条件使用除等于运算符以外的其它比较运算符比较被连接的列的列值。这些运算符包括>、>=、<=、<、!>、!<和<>。

1.3.自然连接：在连接条件中使用等于(=)运算符比较被连接列的列值，但它使用选择列表指出查询结果集合中所包括的列，并删除连接表中的重复列。

**B.**  **外连接**

2.1.左联接：是以左表为基准，将a.stuid = b.stuid的数据进行连接，然后将左表没有的对应项显示，右表的列为NULL

2.2.右连接：是以右表为基准，将a.stuid = b.stuid的数据进行连接，然以将右表没有的对应项显示，左表的列为NULL

2.3.全连接：完整外部联接返回左表和右表中的所有行。当某行在另一个表中没有匹配行时，则另一个表的选择列表列包含空值。如果表之间有匹配行，则整个结果集行包含基表的数据值。

内连接和外连接两种类型的**主要区别**在于，即使是在连接条件不满足的情况下，外部连接也会在结果集内返回行，而内部连接不会在结果集类返回行。

**C.**  **交叉连接**

交叉连接：交叉联接返回左表中的所有行，左表中的每一行与右表中的所有行组合。交叉联接也称作笛卡尔积。

## 11. Statement和PreparedStatement之间的区别

1) PreparedStatement是预编译的,对于批量处理可以大大提高效率.也叫JDBC存储过程；

2) 使用 Statement 对象。在对数据库只执行一次性存取的时侯，用 Statement 对象进行处理。PreparedStatement对象的开销比Statement大，对于一次性操作并不会带来额外的好处；

3) statement每次执行sql语句，相关数据库都要执行sql语句的编译，preparedstatement是预编译得,preparedstatement支持批处理。

## 12. 什么是数据库连接池

## 1. 使用mysql索引都有哪些原则？索引什么数据结构？ B+树和B树什么区别？
1. 尽量减少like，但不是绝对不可用，”xxxx%” 是可以用到索引的
2. 表的主键、外键必须有索引
3. 谁的区分度更高（同值的最少），谁建索引，区分度的公式是count(distinct（字段）)/count(*)
4. 单表数据太少，不适合建索引
5. where，order by ,group by 等过滤时，后面的字段最好加上索引
6. 如果既有单字段索引，又有这几个字段上的联合索引，一般可以删除联合索引；
7. 联合索引的建立需要进行仔细分析；尽量考虑用单字段索引代替：
8. 联合索引: mysql 从左到右的使用索引中的字段，一个查询可以只使用索引中的一部份，但只能是最左侧部分。例如索引是key index(a,b,c). 可以支持 a|a,b|a,b,c 3种组合进行查找，但不支持 b,c 进行查找.当最左侧字段是常量引用时，索引就十分有效。
9. 前缀索引: 有时候需要索引很长的字符列，这会让索引变得大且慢。通常可以索引开始的部分字符，这样可以大大节约索引空间，从而提高索引效率。其缺点是不能用于ORDER BY和GROUP BY操作，也不能用于覆盖索引 Covering index（即当索引本身包含查询所需全部数据时，不再访问数据文件本身）。
10. NULL会导致索引形同虚设

## 2. mysql有哪些存储引擎？都有啥区别？要详细!

## 3. 设计高并发系统数据库层面该怎么设计？数据库锁有哪些类型？如何实现呀？

## 4. 数据库事务有哪些？

**事务特性**：ACID

**隔离级别**：读未提交，读已提交，可重复读，串行化

## 1. 如何设计可以动态扩容缩容的分库分表方案？

1. 停机迁移方案（不推荐）
2. 升级从库
3. 双写迁移

## 2. 用过哪些分库分表中间件，有啥优点和缺点，讲一下你了解的分库分表中间件的底层实现原理？

## 3. 我现在有一个未分库分表的系统，以后系统需分库分表,如何设计,让未分库分表的系统动态切换到分库分表的系统上？

[参考链接](https://github.com/doocs/advanced-java)

1. 停机迁移方案（不推荐）
2. 升级从库
3. 双写迁移

## 4. 分布式事务知道吗？你们怎么解决的？TCC？那若出现网络原因,网络连不通怎么办？

## 5. 为什么要分库分表？

分库：减少并发问题

分表：其实降低了分布式事务

## 6. 分布式寻址方式都有哪些算法？知道一致性hash吗？手写一下java实现代码？

## 7.分库分表中若对userId取摸分片，那我要查一段连续时间里的数据怎么办？

建立userId与时间得一个映射关系

## 8. 如何解决分库分表主键问题？有什么实现方案？

UUID、Snowflakes

## 9.如何设计一个高并发系统

可以从以下几点考虑：

- 系统拆分：可采用微服务或者Dubbo，将系统划分成多个小系统
- 缓存：大部分系统都是多读少写，采用Redis等缓存
- MQ
- 分库分表
- 读写分离
- ElasticSearch



# 设计模式

## 1. 谈一下自己了解或者熟悉的设计模式

**创建型模式**：单例模式、抽象工厂模式、建造者模式、工厂模式、原型模式。

**结构型模式**：适配器模式、桥接模式、装饰模式、组合模式、外观模式、享元模式、代理模式。

**行为型模式**：模版方法模式、命令模式、迭代器模式、观察者模式、中介者模式、备忘录模式、解释器模式（Interpreter 模式）、状态模式、策略模式、职责链模式(责任链模式)、访问者模式。

## 2. 单例的五种写法：饿汉、懒汉、静态内部类、枚举、双重校验锁

单例模式的三个要求：延迟加载（懒汉）、线程安全、效率高

```java
//饿汉式**
public class Singleton1 {
    public static Singleton1 singleton=new Singleton1();
    private Singleton1(){}
    public static Singleton1 getInstance(){
        return singleton;
    }
}


//**懒汉式**
public class Singleton2 {
    public static Singleton2 singleton;
    private Singleton2(){}
    public static synchronized Singleton2 getInstance(){
        if(singleton==null){
            singleton=new Singleton2();
        }
        return singleton;
    }
}


//**静态内部类**
public class Singleton3 {
    public static class SingletonInstance{

        public static Singleton3 singleton=new Singleton3();
    }
    private Singleton3(){}
    public static Singleton3 getInstance(){
        return SingletonInstance.singleton;
    }
}


//**枚举**
public enum Singleton4 {

    INSTANCE;
    public void whateverMethod(){}
}


//**双重检查**
public class Singleton5 {
    public static volatile Singleton5 singleton;
    private Singleton5(){}
    public static Singleton5 getInstance(){
        if(singleton==null){
            synchronized (Singleton5.class){
                if(singleton==null){
                    singleton=new Singleton5();
                }
            }
        }
        return singleton;
    }
}
```

## 3. 简单工厂模式、工厂模式、抽象工厂模式

[参考链接](https://juejin.im/entry/58f5e080b123db2fa2b3c4c6)

工厂模式主要有三种：**简单工厂模式**、**工厂方法模式**、**抽象工厂模式**

### 简单工厂模式
简单工厂模式算不上一种设计模式，更多的是一种编程习惯。

定义一个工厂类，根据传入的参数不同返回不同的实例，被创建的实例具有共同的父类或接口。

**适用场景**：

（1）需要创建的对象较少。　　
（2）客户端不关心对象的创建过程。

### 工厂方法模式

工厂方法模式是简单工厂的仅一步深化， 在工厂方法模式中，我们不再提供一个统一的工厂类来创建所有的对象，而是**针对不同的对象提供不同的工厂**。也就是说**每个对象都有一个与之对应的工厂**。

**定义：** 定义一个用于创建对象的接口，让子类决定将哪一个类实例化。工厂方法模式让一个类的实例化延迟到其子类。


和简单工厂对比一下，最根本的区别在于，简单工厂只有一个统一的工厂类，而工厂方法是**针对每个要创建的对象都会提供一个工厂类**，这些工厂类都实现了一个工厂基类（本例中的ReaderFactory ）。

**适用场景：**
（1）客户端不需要知道它所创建的对象的类。例子中我们不知道每个图片加载器具体叫什么名，只知道创建它的工厂名就完成了创建过程。
（2）客户端可以通过子类来指定创建对应的对象。

### 抽象工厂模式
这个模式并不符合开闭原则。实际开发还需要做好权衡。

抽象工厂模式是工厂方法的仅一步深化，在这个模式中的工厂类不单单可以创建一个对象，而是可以创建一组对象。这是和工厂方法最大的不同点。

**定义：** 提供一个创建一系列相关或相互依赖对象的接口，而无须指定它们具体的类。（ 在抽象工厂模式中，每一个具体工厂都提供了多个工厂方法用于产生多种不同类型的对象）
　　
抽象工厂和工厂方法一样可以划分为4大部分：
* AbstractFactory（抽象工厂）：声明了一组用于创建对象的方法，注意是一组。
* ConcreteFactory（具体工厂）：它实现了在抽象工厂中声明的创建对象的方法，生成一组具体对象。
* AbstractProduct（抽象产品）：它为每种对象声明接口，在其中声明了对象所具有的业务方法。
* ConcreteProduct（具体产品）：它定义具体工厂生产的具体对象。

**适用场景：**
（1）和工厂方法一样客户端不需要知道它所创建的对象的类。
（2）需要一组对象共同完成某种功能时。并且可能存在多组对象完成不同功能的情况。
（3）系统结构稳定，不会频繁的增加对象。（因为一旦增加就需要修改原有代码，不符合开闭原则）

----

**工厂模式要点:**
     **简单工厂模式(静态工厂模式)** 
     虽然某种程度不符合设计原则,但实际使用最多。 
     **工厂方法模式**
     不修改已有类的前提下,通过增加新的工厂类实现扩展。
     **抽象工厂模式**
     不可以增加产品，可以增加产品族! 

应用场景
    * JDK中Calendar的getInstance方法
        * JDBC中Connection对象的获取
        * Hibernate中SessionFactory创建Session
        * spring中IOC容器创建管理bean对象
        * XML解析时的DocumentBuilderFactory创建解析器对象
        * 反射中Class对象的newInstance()

# Java高级多线程

## 1. 进程和线程的区别

进程和线程的主要差别在于**它们是不同的操作系统资源管理方式**。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。

1) 简而言之,一个程序至少有一个进程,一个进程至少有一个线程。

2) 线程的划分尺度小于进程，使得多线程程序的并发性高。

3) 另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。

4) 线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。

5) 从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。

从**四个角度**来剖析二者之间的区别

Ø 调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位。

Ø 并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可以并发执行。

Ø 拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源。

Ø 系统开销：

## 2. 线程状态转换

![](.\images\线程状态.png)

![](.\images\线程状态说明.png)

## 3. 线程间通信

- volatile和synchronized关键字

- 等待/通知机制

- Thread.join()的使用

- ThreadLocal的使用

- 通过管道进行线程间通信：字节流


## 4. 并行和并发的区别和联系

**并发**:一个处理器能够处理多个任务。

**并行**:多个处理器或者是多核的处理器同时处理多个不同的任务。

前者是*逻辑上*的同时发生（simultaneous），而后者是*物理*上的同时发生．

**并发性(concurrency)**，**又称共行性，是指能处理多个同时性活动的能力，并发事件之间不一定要同一时刻发生。

**并行(parallelism)**是指同时发生的两个并发事件，具有并发的含义，而并*发则不一定并行*。

例子：

Ø 你吃饭吃到一半，电话来了，你一直到吃完了以后才去接，这就说明你不支持并发也不支持并行。

Ø 你吃饭吃到一半，电话来了，你停了下来接了电话，接完后继续吃饭，这说明你支持**并发**。

Ø 你吃饭吃到一半，电话来了，你一边打电话一边吃饭，这说明你支持**并行**。

并发的关键是你有处理多个任务的能力，不一定要同时。并行的关键是你有同时处理多个任务的能力。所以我认为它们最关键的点就是：是否是**同时**。

 

## 5. 同步与异步、阻塞与非阻塞

同步和异步关注的是**消息通信机制**；

所谓同步，就是在发出一个调用时，在没有得到结果之前，该调用就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由调用者主动等待这个调用的结果。

而异步则是相反，**调用在发出之后，这个调用就直接返回了，所以没有返回结果**。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在调用发出后，被调用者通过状态、通知来通知调用者，或通过回调函数处理这个调用。

阻塞和非阻塞关注的是**程序在等待调用结果（消息，返回值）时的状态。**

阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。

非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。

## 6. 多线程的实现方式，有什么区别

**1、继承Thread类实现多线程**

继承Thread类的方法尽管被我列为一种多线程实现方式，但Thread本质上也是实现了Runnable接口的一个实例，它代表一个线程的实例，并且，启动线程的唯一方法就是通过Thread类的start()实例方法。start()方法是一个native方法，它将启动一个新线程，并执行run()方法。这种方式实现多线程很简单，通过自己的类直接extend Thread，并复写run()方法，就可以启动新线程并执行自己定义的run()方法。缺点：不能继承其他类。

**2、实现Runnable接口方式实现多线程**

如果自己的类已经extends另一个类，就无法直接extends Thread，此时，必须实现一个Runnable接口，如下：

```java
public class MyThread extends OtherClass implements Runnable {
    public void run() {
        System.out.println("MyThread.run()");
    }
}

//为了启动MyThread，需要首先实例化一个Thread，并传入自己的MyThread实例：
MyThread myThread = new MyThread();
Thread thread = new Thread(myThread);
thread.start();
```

**3、实现 Callable 接口**

可以返回结果（通过Future），也可以抛出异常

需要实现的是call() 方法

以上两点也是Callable接口 与 Runnable 接口的区别

```java
public class MultiThread_Test {
    public static void main(String[] args) throws Exception {
        ExecutorService es = Executors.newSingleThreadExecutor();
        // 自动在一个新的线程上启动 MyCallable，执行 call 方法
        Future<Integer> f = es.submit(new MyCallable());
        // 当前 main 线程阻塞，直至 future 得到值
        System.out.println(f.get());
        es.shutdown();
    }
}

class MyCallable implements Callable<Integer> {
    public Integer call() {
        System.out.println(Thread.currentThread().getName());
        try {
            Thread.sleep(2000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        return 123;
    }
}
```

## 7. 什么叫守护线程

**用户线程***：*我们平常创建的普通线程。

**守护线程***：*用来服务于用户线程；不需要上层逻辑介入。

通过一个例子来区分一下它们与JVM的关系。

class DaemonRunner implements Runnable {

  @Override

  public void run() {

  while (true) {

 for (int i = 1; i <= 100; i++) {

 System.out.println("daemon thread:"+i);

 try {

 Thread.sleep(1000);

 } catch (InterruptedException e) {

 e.printStackTrace();

 }

 }

  }

  }

}

Thread daemonThread = new Thread(new DaemonRunner());

daemonThread.setDaemon(true);

daemonThread.start();

System.out.println("isDaemon? = " + daemonThread.isDaemon());

Scanner scanner = new Scanner(System.in);

scanner.next();

Runtime.getRuntime().addShutdownHook(new Thread() {

  @Override

  public void run() {

  System.out.println("JVM Exit!");

  }

});

我们分析结果，可以得出结论**：当线程只剩下守护线程的时候**,JVM**就会退出**；补充一点如果还有其他的任意一个用户线程还在，JVM就不会退出。

 

**使用它需要注意些什么？**

thread.setDaemon(true)必须在thread.start()之前设置，否则会跑出一个IllegalThreadStateException异常。**你不能把正在运行的常规线程设置为守护线程**。

在Daemon线程中产生的新线程也是Daemon的。

守护线程不能用于去访问固有资源，比如读写操作或者计算逻辑。因为它会在任何时候甚至在一个操作的中间发生中断。

Java自带的多线程框架，比如ExecutorService，会将守护线程转换为用户线程，所以如果要使用后台线程就不能用Java的线程池。

**意义及应用场景**

当主线程结束时，结束其余的子线程（守护线程）自动关闭，就免去了还要继续关闭子线程的麻烦。如：Java垃圾回收线程就是一个典型的守护线程；内存资源或者线程的管理，但是非守护线程也可以。

## 8. 什么是线程安全？

当多个线程访问同一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替运行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获取正确的结果，那这个对象是线程安全的。

## 9. synchronized和lock的区别
① **两者都是可重入锁**

两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。

② **synchronized** **依赖于 JVM** **而 ReenTrantLock** **依赖于 API**

synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReenTrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。

③ **ReenTrantLock** **比 synchronized** **增加了一些高级功能**

相比synchronized，ReenTrantLock增加了一些高级功能。主要来说主要有三点：①**等待可中断**；②**可实现公平锁**；③**可实现选择性通知**（锁可以绑定多个条件）

l ReenTrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。

l ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 ReenTrantLock默认情况是非公平的，可以通过 ReenTrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。

l synchronized关键字与wait()和notify/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。在使用notify/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知”，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法只会唤醒注册在该Condition实例中的所有等待线程。

如果你想使用上述功能，那么选择ReenTrantLock是一个不错的选择。

**④** **性能已不是选择标准**

在JDK1.6之前，synchronized 的性能是比 ReenTrantLock 差很多。具体表示为：synchronized 关键字吞吐量随线程数的增加，下降得非常严重。而ReenTrantLock 基本保持一个比较稳定的水平。我觉得这也侧面反映了， synchronized 关键字还有非常大的优化余地。后续的技术发展也证明了这一点，我们上面也讲了在 JDK1.6 之后 JVM 团队对 synchronized 关键字做了很多优化。JDK1.6 之后，synchronized 和 ReenTrantLock 的性能基本是持平了。所以网上那些说因为性能才选择 ReenTrantLock 的文章都是错的！JDK1.6之后，性能已经不是选择synchronized和ReenTrantLock的影响因素了！而且虚拟机在未来的性能改进中会更偏向于原生的synchronized，所以还是提倡在synchronized能满足你的需求的情况下，优先考虑使用synchronized关键字来进行同步！优化后的synchronized和ReenTrantLock一样，在很多地方都是用到了CAS操作。

## 10. 当一个线程进入一个对象的一个synchronized方法后，其它线程是否可进入此对象的其它方法？

分几种情况：

 1.其他方法前是否加了synchronized关键字，如果没加，则能。

 2.如果这个方法内部调用了wait，则可以进入其他synchronized方法。

 3.如果其他个方法都加了synchronized关键字，并且内部没有调用wait，则不能。

 4.如果其他方法是static，它用的同步锁是当前类的字节码，与非静态的方法不能同步，因为非静态的方法用的是this。

## 11. 启动一个线程是用run()还是start()？

用start()方法。当用start()开始一个线程后，线程就进入就绪状态，使线程所代表的虚拟处理机处于可运行状态，这意味着它可以由JVM调度并执行。这并不意味着线程就会立即运行。当cpu分配给它时间时，才开始执行run()方法(如果有的话)。start()是方法,它调用run()方法。而run()方法是你必须重写的。run()方法中包含的是线程的主体。

## 12. Wait、sleep、yield、join的区别

1、每个对象都有一个锁来控制同步访问，Synchronized关键字可以和对象的锁交互，来实现同步方法或同步块。sleep()方法正在执行的线程主动让出CPU（然后CPU就可以去执行其他任务），在sleep指定时间后CPU再回到该线程继续往下执行(**注意****：sleep**方法只让出了CPU**，而并不会释放同步资源锁**！！！)；wait()方法则是指当前线程让自己暂时退让出同步资源锁，以便其他正在等待该资源的线程得到该资源进而运行，只有调用了notify()方法，之前调用wait()的线程才会解除wait状态，可以去参与竞争同步资源锁，进而得到执行。（注意：notify的作用相当于叫醒睡着的人，而并不会给他分配任务，就是说notify只是让之前调用wait的线程有权利重新参与线程的调度）；

2、sleep()方法可以在任何地方使用；wait()方法则只能在同步方法或同步块中使用；

3、sleep()是线程线程类（Thread）的方法，调用会暂停此线程指定的时间，但监控依然保持，不会释放对象锁，到时间自动恢复；wait()是Object的方法，调用会放弃对象锁，进入等待队列，待调用notify()/notifyAll()唤醒指定的线程或者所有线程，才会进入锁池，不再次获得对象锁才会进入运行状态；

**yield()**方法和sleep()方法类似，也不会释放“锁标志”，区别在于，它没有参数，即**yield()**方法只是让出CPU**使当前线程重新回到可执行状态(**没有运行)**，所以执行yield()的线程有可能在进入到可执行状态后马上又被执行，另外yield()方法只能使**同优先级或者高优先级的线程得到执行机会**，这也和sleep()方法不同。

**join()**方法会使当前线程等待调用join()方法的线程结束后才能继续执行

<https://juejin.im/post/5ae6cf7a518825670960fcc2>

## 13. ThreadLocal是什么？底层如何实现？写一个例子？

**ThreadLocal**归纳下来就2**类用途**：

\1. 保存线程上下文信息，在任意需要的地方可以获取！

\2. 线程安全的，避免某些情况需要考虑线程安全必须同步带来的性能损失！

 

## 14. notify和notifyAll的区别

先说两个概念：锁池和等待池

**锁池:**假设线程A已经拥有了某个对象(注意:不是类)的锁，而其它的线程想要调用这个对象的某个synchronized方法(或者synchronized块)，由于这些线程在进入对象的synchronized方法之前必须先获得该对象的锁的拥有权，但是该对象的锁目前正被线程A拥有，所以这些线程就进入了该对象的锁池中。

**等待池:**假设一个线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁后，进入到了该对象的等待池中

然后再来说notify和notifyAll的**区别**：

1) 如果线程调用了对象的wait()方法，那么线程便会处于该对象的等待池中，等待池中的线程不会去竞争该对象的锁。

2) 当有线程调用了对象的 notifyAll()方法（唤醒所有 wait 线程）或 notify()方法（只随机唤醒一个 wait 线程），被唤醒的的线程便会进入该对象的锁池中，锁池中的线程会去竞争该对象锁。也就是说，调用了notify后只要一个线程会由等待池进入锁池，而notifyAll会将该对象等待池内的所有线程移动到锁池中，等待锁竞争。

3) 优先级高的线程竞争到对象锁的概率大，假若某线程没有竞争到该对象锁，它还会留在锁池中，唯有线程再次调用wait()方法，它才会重新回到等待池中。而竞争到对象锁的线程则继续往下执行，直到执行完了 synchronized 代码块，它会释放掉该对象锁，这时锁池中的线程会继续竞争该对象锁。

综上，所谓唤醒线程，另一种解释可以说是**将线程由等待池移动到锁池**，notifyAll调用后，会将全部线程由等待池移到锁池，然后参与锁的竞争，竞争成功则继续执行，如果不成功则留在锁池等待锁被释放后再次参与竞争。而notify只会唤醒一个线程。

## 15. 线程池的作用

Ø 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。

Ø 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。

Ø 提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。

## 16. 为什么suspend()、resume()、stop()这些方法废弃了？

不建议使用的原因主要有：以suspend()方法为例，在调用后，线程不会释放已经占有的资源（比如锁），而是占有着资源进入睡眠状态，这样容易引发死锁问题。同样，stop()方法在终结一个线程时不会保证线程的资源正常释放，通常是没有给予线程完成资源释放工作的机会，因此会导致程序可能工作在不确定状态下。

## 17. 如何停止一个线程？

Ø 使用stop方法强行终止，但是不推荐这个方法，因为stop和suspend及resume一样都是过期作废的方法。

Ø 使用boolean类型的变量，来终止线程。

Ø 使用interrupt方法中断线程，使用此方法分两种情况：

\1.  **线程处于阻塞状态**，如使用了sleep,同步锁的wait,socket中的receiver,accept等方法时，会使线程处于阻塞状态。当调用线程的interrupt()方法时，会抛出InterruptException异常。阻塞中的那个方法抛出这个异常，通过代码捕获该异常，然后break跳出循环状态，从而让我们有机会结束这个线程的执行。通常很多人认为只要调用interrupt方法线程就会结束，实际上是错的，一定要先捕获InterruptedException异常之后通过break来跳出循环，才能正常结束run方法。

\2.  **线程未处于阻塞状态**，使用isInterrupted()判断线程的中断标志来退出循环。当使用interrupt()方法时，中断标志就会置true，和使用自定义的标志来控制循环是一样的道理。

## 18. 等待/通知的经典范式

等待方遵循如下原则。

1）获取对象的锁。

2）如果条件不满足，那么调用对象的wait()方法，被通知后仍要检查条件。

3）条件满足则执行对应的逻辑。

对应的伪代码如下。

synchronized(对象) {

while(条件不满足) {

对象.wait();

} 

对应的处理逻辑

}

通知方遵循如下原则。

1）获得对象的锁。

2）改变条件。

3）通知所有等待在对象上的线程。

对应的伪代码如下。

synchronized(对象) {

改变条件；

对象.notifyAll();

}

## 19. Java中线程池相关的类

public ThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue)

corePoolSize 指的是保留的线程池大小。

maximumPoolSize 指的是线程池的最大大小。

keepAliveTime 指的是空闲线程结束的超时时间。

unit 是一个枚举，表示 keepAliveTime 的单位。

workQueue 表示存放任务的队列。

我们可以从线程池的工作过程中了解这些参数的意义。线程池的工作过程如下：

1、线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面有任务，线程池也不会马上执行它们。

2、当调用 execute() 方法添加一个任务时，线程池会做如下判断：

 a. 如果正在运行的线程数量小于corePoolSize，那么马上创建线程运行这个任务；

 b. 如果正在运行的线程数量大于或等于corePoolSize，那么将这个任务放入队列。

 c. 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建线程运行这个任务；

 d. 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会抛出异常，告诉调用者“我不能再接受任务了”。

3、当一个线程完成任务时，它会从队列中取下一个任务来执行。

4、当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运行的线程数大于corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到corePoolSize 的大小。

## 20. Java并发容器，为什么要使用ConcurrentHashMap?

 **JDK1.5**中的实现**：ConcurrentHashMap使用的是**分段锁**技术,将ConcurrentHashMap将锁一段一段的存储，然后给每一段数据配一把锁（segment），当一个线程占用一把锁（segment）访问其中一段数据的时候，其他段的数据也能被其它的线程访问，默认分配16个segment。默认比Hashtable效率提高16倍。JDK1.5的ConcurrentHashMap的结构图如右图所示。

 **JDK1.8**中的实现**：ConcurrentHashMap取消了segment分段锁，而采用**CAS**和synchronized**来保证并发安全。数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。

synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生并发，效率又提升N倍。JDK1.8的ConcurrentHashMap的结构图如右图所示。

**总结**：JDK8中的实现也是锁分离的思想，它把锁分的比segment（JDK1.5）更细一些，只要hash不冲突，就不会出现并发获得锁的情况。它首先使用无锁操作CAS插入头结点，如果插入失败，说明已经有别的线程插入头结点了，再次循环进行操作。如果头结点已经存在，则通过synchronized获得头结点锁，进行后续的操作。性能比segment分段锁又再次提升。

## 21. CAS问题

具体思想：CAS包含三个参数（V,expect,update），我认为这三个参数分别是**：V**表示当前内存中的值**，而**expect**表示当前读取到的值**，只有当当前读取到的值和内存中的值一致时，我们会把内存中的时更新为最新的值，即update;若不等，则说明该值被其他线程修改了。每次CAS操作时，一定有一个线程会成功更新变量，而其他失败的线程不会挂起，而是允许继续重试，直到成功为止。

CAS虽然很高效的解决原子操作，但是CAS仍然存在三大问题。**ABA**问题**，**循环时间长开销大**和**只能保证一个共享变量的原子操作**

**ABA**问题**。因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是**使用版本号**。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A－2B－3A。从Java1.5开始JDK的atomic包里提供了一个类*AtomicStampedReference*来解决ABA问题。这个类的*compareAndSet*方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

**循环时间长开销大**。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。

**只能保证一个共享变量的原子操作**。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij。从Java1.5开始JDK提供了**AtomicReference**类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS**操作。**

## 22. 

# Spring

## 1. 对与IoC和AOP的理解

**IoC（控制反转）**，将类的创建和依赖关系写在配置文件里，由配置文件注入，实现了松耦合。

**AOP**将安全，事务等于程序逻辑相对独立的功能抽取出来，利用spring的配置文件将这些功能插进去，实现了按照切面编程，提高了复用性。

## 2. spring都有哪些机制？AOP底层如何实现的？IOC呢？

 

## 3. cgLib知道吗？他和jdk动态代理什么区别？手写一个jdk动态代理？

JDK动态代理必须提供接口才能使用，在一些不能提供接口的环境中，只能采用其它第三方技术，比如CGLIB动态代理。它的优势在于不需要提供接口，只要一个非抽象类就能实现动态代理。CGLIB是利用ASM开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理

## 4. spring bean的生命周期

![](.\images\spring生命周期.png)

1. 实例化（当我们的程序加载beans.xml文件），把我们的bean（前提是scope=singleton）实例化(反射机制)到内存。
2. 调用set方法设置属性。

3. 如果实现了bean名字关注接口（BeanNameAware），则可以通过setBeanName获取id号。

4. 如果实现了bean工厂关注接口（BeanFactoryAware），则可以获取BeanFactory。

5. 如果实现了ApplicationContextAware接口，则调用方法setApplicationContext，该方法传递了ApplicationContext。
6. 如果bean和一个后置处理器关联，则会自动去调用postProcessBeforeInitialization方法。
7. 如果实现了InitializingBean接口，则会调用afterPropertiesSet()方法
8. 如果自己在<bean init-method="init" />则可以在bean定义自己的初始化方法

9. 如果bean和一个后置处理器关联，则会自动去调用BeanPostProcessor的后初始化方法(after)

10. Bean可以使用了

11. 容器关闭

12. 可以通过调用DisposableBean的destory()方法

13. 可以在<bean destroy-method="fun1" />调用定制的销毁方法

## 3. 什么是控制反转(IOC)？什么是依赖注入？

控制反转是应用于软件工程领域中的，在运行时被装配器对象来绑定耦合对象的一种编程技巧，对象之间耦合关系在编译时通常是未知的。在传统的编程方式中，业务逻辑的流程是由应用程序中的早已被设定好关联关系的对象来决定的。在使用控制反转的情况下，业务逻辑的流程是由对象关系图来决定的，该对象关系图由装配器负责实例化，这种实现方式还可以将对象之间的关联关系的定义抽象化。而绑定的过程是通过“依赖注入”实现的。

控制反转是一种以给予应用程序中目标组件更多控制为目的设计范式，并在我们的实际工作中起到了有效的作用。

依赖注入是在编译阶段尚未知所需的功能是来自哪个的类的情况下，将其他对象所依赖的功能对象实例化的模式。这就需要一种机制用来激活相应的组件以提供特定的功能，所以依赖注入是控制反转的基础。否则如果在组件不受框架控制的情况下，框架又怎么知道要创建哪个组件？

在Java中依赖注入有以下三种实现方式：

- 构造器注入

- Setter方法注入

- 接口注入


## 4. 请解释下Spring框架中的IOC？

Spring中的 org.springframework.beans 包和 org.springframework.context包构成了Spring框架IOC容器的基础。

BeanFactory 接口提供了一个先进的配置机制，使得任何类型的对象的配置成为可能。ApplicationContex接口对BeanFactory（是一个子接口）进行了扩展，在BeanFactory的基础上添加了其他功能，比如与Spring的AOP更容易集成，也提供了处理message resource的机制（用于国际化）、事件传播以及应用层的特别配置，比如针对Web应用的WebApplicationContext。

org.springframework.beans.factory.BeanFactory 是Spring IOC容器的具体实现，用来包装和管理前面提到的各种bean。BeanFactory接口是Spring IOC 容器的核心接口。

## 5. BeanFactory和ApplicationContext有什么区别？

BeanFactory 可以理解为含有bean集合的工厂类。BeanFactory 包含了种bean的定义，以便在接收到客户端请求时将对应的bean实例化。

BeanFactory还能在实例化对象的时生成协作类之间的关系。此举将bean自身与bean客户端的配置中解放出来。BeanFactory还包含了bean生命周期的控制，调用客户端的初始化方法（initialization methods）和销毁方法（destruction methods）。

从表面上看，application context如同bean factory一样具有bean定义、bean关联关系的设置，根据请求分发bean的功能。但application context在此基础上还提供了其他的功能。

+ 提供了支持国际化的文本消息

+ 统一的资源文件读取方式

+ 已在监听器中注册的bean的事件

以下是三种较常见的 ApplicationContext 实现方式：

1、ClassPathXmlApplicationContext：从classpath的XML配置文件中读取上下文，并生成上下文定义。应用程序上下文从程序环境变量中取得。

ApplicationContext context = new ClassPathXmlApplicationContext(“bean.xml”);

2、FileSystemXmlApplicationContext：由文件系统中的XML配置文件读取上下文。

ApplicationContext context = new FileSystemXmlApplicationContext(“bean.xml”);

3、XmlWebApplicationContext：由Web应用的XML文件读取上下文。

## 6. Spring有几种配置方式？

将Spring配置到应用开发中有以下三种方式：

Ø 基于XML的配置

Ø 基于注解的配置

Ø 基于Java的配置

## 7. 构造方法注入和设值注入有什么区别？

## 8. Spring 框架中都用到了哪些设计模式？

[参考链接](https://juejin.im/post/5ce69379e51d455d877e0ca0)

工厂模式：

单例模式：

代理模式：

模板方法：

适配器模式：

观察者模式：

装饰者模式：

# 海量数据处理

## 1. 海量日志数据，如何提取出某日访问淘宝次数最多的IP？

分而治之+Hash

1) IP地址最多有$2^{32}$=4G种取值情况，所以不能完全加载到内存中处理； 

2) 可以考虑采用“分而治之”的思想，按照IP地址的Hash(IP)%1024值，把海量IP日志分别存储到1024个小文件中。这样，每个小文件最多包含4MB个IP地址； 

3) 对于每一个小文件，可以构建一个IP为key，出现次数为value的Hash map，同时记录当前出现次数最多的那个IP地址；

4) 可以得到1024个小文件中的出现次数最多的IP，再依据常规的排序算法得到总体上出现次数最多的IP；

## 2. 上亿数据，统计其中出现次数最多的前N个数据

## 3. 100亿个int，找出他们的中位数（分桶）

假设100亿个数字保存在一个大文件中，依次读一部分文件到内存(不超过内存的限制)，将每个数字用二进制表示，比较二进制的最高位(第32位，符号位，0是正，1是负)，如果数字的最高位为0，则将这个数字写入 file_0文件中；如果最高位为 1，则将该数字写入file_1文件中。 

从而将100亿个数字分成了两个文件，假设 file_0文件中有 60亿个数字，file_1文件中有40亿个数字。那么中位数就在file_0文件中，并且是 file_0文件中所有数字排序之后的第10亿个数字。（file_1中的数都是负数，file_0中的数都是正数，也即这里一共只有40亿个负数，那么排序之后的第50亿个数一定位于file_0中） 

现在，我们只需要处理 file_0 文件了（不需要再考虑file_1文件）。对于 file_0 文件，同样采取上面的措施处理：将file_0文件依次读一部分到内存(不超内存限制)，将每个数字用二进制表示，比较二进制的 次高位（第31位），如果数字的次高位为0，写入file_0_0文件中；如果次高位为1，写入file_0_1文件中。

## 4. 两个文件，各存放50亿条URL，每个URL占64字节。内存限制是4G，找出两个文件中相同的URL

## 5. 有40亿个不重复的unsigned int的整数，没排过序，现在给一个数，如何快速判断这个数是否在这40亿个数当中。

可以用位图/Bitmap的方法，申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。

## 6. 在2.5亿个整数中找出不重复的整数，注：内存不足以容纳这2.5亿个整数

**解法一**：采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存$2^{32}$ * 2 bit=1 GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。

**解法二**：也可采用与第1题类似的方法，进行划分小文件的方法。然后在小文件中找出不重复的整数，并排序。然后再进行归并，注意去除重复的元素。”

## 7. 提示：分治、Hash映射、堆排序、双层桶划分、Bloom filter、bitmap、数据库索引、mapreduce

**BitMap**就是用一个bit位来标记某个元素对应的Value，而Key即是该元素。由于采用了Bit为单位来存储数据，因此在存储空间方面，可以大大节省。

# Java基础

## 1. Java中实现多态的机制是什么，动态多态和静态多态的区别

**多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定**，即**一个引用变量到底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定**。因为在程序运行时才确定具体的类，这样，不用修改源程序代码，就可以让引用变量绑定到各种不同的类实现上，从而导致该引用调用的具体方法随之改变，即不修改程序代码就可以改变程序运行时所绑定的具体代码，让程序可以选择多个运行状态，这就是多态性。

但是向上转型存在一些缺憾，那就是它必定会导致一些方法和属性的丢失，而导致我们不能够获取它们。所以父类类型的引用可以调用父类中定义的所有属性和方法，对于只存在与子类中的方法和属性它就望尘莫及了。

指向子类的父类引用由于向上转型了，它只能访问父类中拥有的方法和属性，而对于子类中存在而父类中不存在的方法，该引用是不能使用的，尽管是重载该方法。若子类重写了父类中的某些方法，在调用该些方法的时候，必定是使用子类中定义的这些方法（动态连接、动态调用）。

多态分为**编译时多态**和**运行时多态**。其中编译时多态是静态的，主要是指方法的**重载**，它是根据参数列表的不同来区分不同的函数，通过编译之后会变成两个不同的函数，在运行时谈不上多态。而运行时多态是动态的，它是通过动态绑定来实现的，也就是我们所说的多态性。

**Java实现多态有三个必要条件：继承、重写、向上转型。**

- **继承**：在多态中必须存在有继承关系的子类和父类。
- **重写**：子类对父类中某些方法进行重新定义，在调用这些方法时就会调用子类的方法。

- **向上转型**：在多态中需要将子类的引用赋给父类对象，只有这样该引用才能够具备技能调用父类的方法和子类的方法。

只有满足了上述三个条件，我们才能够在同一个继承结构中使用统一的逻辑实现代码处理不同的对象，从而达到执行不同的行为。

对于Java而言，它多态的实现机制遵循一个**原则**：当超类对象引用变量引用子类对象时，被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法，但是**这个被调用的方法必须是在超类中定义过的，也就是说被子类覆盖的方法**。

实现形式:

在Java中有两种形式可以实现多态。继承和接口。

```java
class A{

    public String show(D obj){

        return ("A and D");

    }

    public String show(A obj){

        return ("A and A");

    }

}



class B extends A{

    public String show(B obj){

        return("B and B");

    }

    public String show(A obj){

        return("B and A");

    }

}

class C extends B{}

class D extends B{}

public class test25 {

    public static void main(String[] args) {

        A a1=new A();

        A a2=new B();

        B b=new B();

        C c=new C();

        D d=new D();



        System.out.println("1--"+a1.show(b));

        System.out.println("2--"+a1.show(c));

        System.out.println("3--"+a1.show(d));

        System.out.println("4--"+a2.show(b));

        System.out.println("5--"+a2.show(c));

        System.out.println("6--"+a2.show(d));

        System.out.println("7--"+b.show(b));

        System.out.println("8--"+b.show(c));

        System.out.println("9--"+b.show(d));

    }

}
```

结果为:

1--A and A

2--A and A

3--A and D

4--B and A

5--B and A

6--A and D

7--B and B

8--B and B

9--A and D

当超类对象引用变量引用子类对象时，被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法，但是这个被调用的方法必须是在超类中定义过的，也就是说被子类覆盖的方法。这句话对多态进行了一个概括。**其实在继承链中对象方法的调用存在一个优先级**：this.show(O)**、super.show(O)**、this.show((super)O)**、super.show((super)O)**。**

首先我们分析5，a2.show(c)，a2是A类型的引用变量，所以this就代表了A，a2.show(c),它在A类中找发现没有找到，于是到A的超类中找(super)，由于A没有超类（Object除外），所以跳到第三级，也就是this.show((super)O)，C的超类有B、A，所以(super)O为B、A，this同样是A，这里在A中找到了show(A obj)，同时由于a2是B类的一个引用且B类重写了show(A obj)，因此最终会调用子类B类的show(A obj)方法，结果也就是B and A。

方法已经找到了但是我们这里还是存在一点疑问，我们还是来看这句话：当超类对象引用变量引用子类对象时，被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法，但是这个被调用的方法必须是在超类中定义过的，也就是说被子类覆盖的方法。这我们用一个例子来说明这句话所代表的含义：a2.show(b)；

这里a2是引用变量，为A类型，它引用的是B对象，因此按照上面那句话的意思是说有B来决定调用谁的方法,所以a2.show(b)应该要调用B中的show(B obj)，产生的结果应该是“B and B”，但是为什么会与前面的运行结果产生差异呢？这里我们忽略了后面那句话“但是这儿被调用的方法必须是在超类中定义过的”，那么show(B obj)在A类中存在吗？根本就不存在！所以这句话在这里不适用？那么难道是这句话错误了？非也！其实这句话还隐含这这句话：它仍然要按照继承链中调用方法的优先级来确认。所以它才会在A类中找到show(A obj)，同时由于B重写了该方法所以才会调用B类中的方法，否则就会调用A类中的方法。

所以多态机制遵循的**原则**概括为**：当超类对象引用变量引用子类对象时，被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法，但是这个被调用的方法必须是在超类中定义过的，也就是说被子类覆盖的方法，但是它仍然要根据继承链中方法调用的优先级来确认方法，该**优先级**为：this.show(O)**、super.show(O)**、this.show((super)O)**、super.show((super)O)**。**

 

## 2. 接口和抽象类的区别，如何选择

抽象类是用来捕捉子类的通用特性的。它不能被实例化，只能被用作子类的超类。抽象类是被用来创建继承层级里子类的模板。

接口是抽象方法的集合。如果一个类实现了某个接口，那么它就继承了这个接口的抽象方法。这就像契约模式，如果实现了这个接口，那么就必须确保使用这些方法。接口只是一种形式，接口自身不能做任何事情。

 

| **参数** | **抽象类**  | **接口**   |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 默认的方法实现 | 它可以有默认的方法实现   | 接口完全是抽象的。它根本不存在方法的实现  |
| 实现 | 子类使用**extends**关键字来继承抽象类。如果子类不是抽象类的话，它需要提供抽象类中所有声明的方法的实现。 | 子类使用关键字**implements**来实现接口。它需要提供接口中所有声明的方法的实现 |
| 构造器  | 抽象类可以有构造器 | 接口不能有构造器  |
| 与正常Java类的区别 | 除了你不能实例化抽象类之外，它和普通Java类没有任何区别  | 接口是完全不同的类型  |
| 访问修饰符 | 抽象方法可以有**public**、**protected**和**default**这些修饰符 | 接口方法默认修饰符是**public**。你不可以使用其它修饰符。 |
| main方法 | 抽象方法可以有main方法并且我们可以运行它  | 接口没有main方法，因此我们不能运行它。  |
| 多继承  | 抽象方法可以继承一个类和实现多个接口 | 接口只可以继承一个或多个其它接口 |
| 速度 | 它比接口速度要快  | 接口是稍微有点慢的，因为它需要时间去寻找在类中实现的方法。  |
| 添加新方法 | 如果你往抽象类中添加新的方法，你可以给它提供默认的实现。因此你不需要改变你现在的代码。 | 如果你往接口中添加方法，那么你必须改变实现该接口的类。  |

 

**什么时候使用抽象类和接口**

· 如果你拥有一些方法并且想让它们中的一些有默认实现，那么使用抽象类吧。

· 如果你想实现多重继承，那么你必须使用接口。由于**Java**不支持多继承**，子类不能够继承多个类，但可以实现多个接口。因此你就可以使用接口来解决它。

· 如果基本功能在不断改变，那么就需要使用抽象类。如果不断改变基本功能并且使用接口，那么就需要改变所有实现了该接口的类。

 

## 3. Java能不能多继承，可不可以多实现

Java为了保证数据安全，它只允许单继承。同时也提供了两种方式让我们曲折来实现多重继承**：接口**和**内部类**。

 

## 4. Static Nested Class和Inner Class的不同？

**内部类就是在一个类的内部定义的类，内部类中不能定义静态成员**（静态成员不是对象的特性，只是为了找一个容身之处，所以需要放到一个类中而已，这么一点小事，你还要把它放到类内部的一个类中，过分了！提供内部类，不是为让你干这种事情，无聊，不让你干。我想可能是既然静态成员类似c语言的全局变量，而内部类通常是用于创建内部对象用的，所以，把“全局变量”放在内部类中就是毫无意义的事情，既然是毫无意义的事情，就应该被禁止），内部类可以直接访问外部类中的成员变量，内部类可以定义在外部类的方法外面，也可以定义在外部类的方法体中，如下所示：

public class Outer

{

 int out_x = 0;

 public void method(){

 Inner1 inner1 = new Inner1();

 class Inner2 //在方法体内部定义的内部类

 {

 public void method()

 {

 out_x = 3;

 }

 }

 Inner2 inner2 = new Inner2();

 }

 

 public class Inner1 //在方法体外面定义的内部类

 {

 }

}

**在方法体外面定义的内部类的访问类型可以是**public**、**protecte**、默认的、**private**等**4**种类型**，这就好像类中定义的成员变量有4种访问类型一样，它们决定这个内部类的定义对其他类是否可见；对于这种情况，我们也可以在外面创建内部类的实例对象，创建内部类的实例对象时，一定要先创建外部类的实例对象，然后用这个外部类的实例对象去创建内部类的实例对象，代码如下：

Outer outer = new Outer();

Outer.Inner1 inner1 = outer.new Innner1();

**在方法内部定义的内部类前面不能有访问类型修饰符**，就好像方法中定义的局部变量一样，但这种内部类的前面可以使用final或abstract修饰符。这种内部类对其他类是不可见的其他类无法引用这种内部类，但是这种内部类创建的实例对象可以传递给其他类访问。这种内部类必须是先定义，后使用，即内部类的定义代码必须出现在使用该类之前，这与方法中的局部变量必须先定义后使用的道理也是一样的。这种内部类可以访问方法体中的局部变量，但是，该局部变量前必须加final修饰符。

对于这些细节，只要在eclipse写代码试试，根据开发工具提示的各类错误信息就可以马上了解到。

在方法体内部还可以采用如下语法来创建一种**匿名内部类**，即定义某一接口或类的子类的同时，还创建了该子类的实例对象，无需为该子类定义名称：

public class Outer

{

 public void start()

 {

 new Thread(new Runable(){

  public void run(){};

}).start();}

}


如果不需要内部类对象与其外围类对象之间有联系，那么可以将内部类声明为static。这通常称为嵌套类。想要理解static应用与内部类时的含义，就必须记住，普通的内部类对象隐式地保存了一个引用，指向创建它的外围类对象。当内部类是static时候，嵌套类意味着：

1) 要创建嵌套类的对象，并不需要其外围类的对象。

2) 不能从嵌套类的对象中访问非静态的外围类对象。

嵌套类与普通的内部类还有一个区别。普通内部类的字段与方法，只能放在类的外部层次上，所以普通的内部类不能有static数据和static字段，也不能包含嵌套类，但是嵌套类可以包含所有这些东西。

正常情况下，不能在接口内部放置任何代码，但是嵌套类可以作为接口的一部分，放置在接口中。

一个内部类被嵌套多少层并不重要---它能透明地访问所有它所嵌入的外围类的所有成员.

在静态方法中定义的内部类也是Static Nested Class，这时候不能在类前面加static关键字，静态方法中的Static Nested Class与普通方法中的内部类的应用方式很相似，它除了可以直接访问外部类中的static的成员变量，还可以访问静态方法中的局部变量，但是，该局部变量前必须加final修饰符。

## 5. 重载和重写的区别。

**重载(Overloading)**

（1）方法重载是让类以统一的方式处理不同类型数据的一种手段。多个同名函数同时存在，具有不同的参数个数/类型。重载Overloading是一个类中多态性的一种表现。

（2）Java的方法重载，就是在类中可以创建多个方法，它们具有相同的名字，但具有**不同的参数**和**不同的定义**。调用方法时通过传递给它们的**不同参数个数**和**参数类型**来决定具体使用哪个方法, 这就是多态性。

（3）重载的时候，方法名要一样，但是参数类型和个数不一样，返回值类型可以相同也可以不相同。无法以返回型别作为重载函数的区分标准。

**重载的规则**：

1、必须具有不同的参数列表；

2、可以有不同的返回类型，只要参数列表不同就可以了；

3、可以有不同的访问修饰符；

4、可以抛出不同的异常；

 

**重写（Overriding**）**

（1）父类与子类之间的多态性，对父类的函数进行**重新定义**。如果在子类中定义某方法与其父类有相同的名称和参数，我们说该方法被重写 (Overriding)。在Java中，子类可继承父类中的方法，而不需要重新编写相同的方法。但有时子类并不想原封不动地继承父类的方法，而是想作一定的修改，这就需要采用方法的重写。方法重写又称方法覆盖。

（2）若子类中的方法与父类中的某一方法具有相同的方法名、返回类型和参数表，则新方法将覆盖原有的方法。如需父类中原有的方法，可使用super关键字，该关键字引用了当前类的父类。

（3）子类函数的访问修饰权限不能少于父类的；

**重写方法的规则**：

1、 参数列表必须完全与被重写的方法相同，否则不能称其为重写而是重载。

2、返回的类型必须一直与被重写的方法的返回类型相同，否则不能称其为重写而是重载。

3、访问修饰符的限制一定要**大于**被重写方法的访问修饰符（public>protected>default>private）

4、重写方法一定不能抛出新的检查异常或者比被重写方法申明更加宽泛的检查型异常。例如：父类的一个方法申明了一个检查异常IOException，在重写这个方法是就不能抛出Exception,只能抛出IOException的子类异常，可以抛出非检查异常。

 

**重写与重载的区别在于**：

重写多态性起作用，对调用被重载过的方法可以大大减少代码的输入量，同一个方法名只要往里面传递不同的参数就可以拥有不同的功能或返回值。

用好重写和重载可以设计一个结构清晰而简洁的类，可以说重写和重载在编写代码过程中的作用非同一般。

## 6. 是否可以继承String类

不能

## 7. 构造器是否可被override？

构造器不能被继承，所以不存在override（重写）的问题，但是可以被重载。

## 8. public,protected,private的区别？

|  | private | default | protect | public |
| ------------ | ------- | ------- | ------- | ------ |
| 当前类  | √  | √  | √  | √  |
| 同一个包 | ×  | √  | √  | √  |
| 其他包的子类 | ×  | ×  | √  | √  |
| 其他包  | ×  | ×  | ×  | √  |

 

## 9. 一个接口可以继承多个接口吗？

可以，接口是常量值和方法定义的集合。接口是一种特殊的抽象类。

java类是单继承的。classB Extends classA

java接口可以多继承。Interface3 Extends Interface0, Interface1, interface……

不允许类多重继承的**主要原因**是，如果A同时继承B和C，而b和c同时有一个D方法，A如何决定该继承那一个呢？

但接口不存在这样的问题，接口全都是抽象方法继承谁都无所谓，所以接口可以继承多个接口。

## 10. 值传递、引用传递；为什么说 Java 中只有值传递

**值传递**（pass by value）是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。

**引用传递**（pass by reference）是指在调用函数时将实际参数的地址直接传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。

java在参数传递的时候并不是把实参传递给了形参，而是建立了实参的**副本**，然后将副本传递给形参(这是值传递的精髓)。

理解java中只有值传递只需要理解两点。

1.参数传递的时候是**拷贝实参的副本传递给形参**。(再看下上面值传递与引用传递的定义就知道为什么说java中只有值传递了)

2.在方法内只有修改了实参所指向的对象的内容，对实参才有影响。

<https://www.jianshu.com/p/f1a075af1669>

 

## 11. 什么是浮点型？什么是单精度和双精度？为什么不能用浮点型表示金额？

浮点数就是**带有小数的数值**。

单精度和双精度实际上是说明浮点数的存储位数。单精度是32位；双精度是64位。

另外因为**浮点数在计算过程中会丢失精度**，所以并不能使用浮点数来表示金额。在Java中用来表示金额可以使用**BigDecimal**。

## 12. 反射机制

是实例化对象的操作，即**通过一个给定的字符串来实例化一个类的对象**。

Java 反射机制在程序**运行时**，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性。这种**动态的获取信息以及动态调用对象的方法的功能称为**java**的反射机制**。

反射机制很重要的一点就是“**运行时**”，其使得我们可以在程序运行时加载、探索以及使用编译期间完全未知的.class文件。换句话说，Java程序可以加载一个运行时才得知名称的 .class文件，然后获悉其完整构造，并生成其对象实体、或对其fields（变量）设值、或调用其 methods（方法）。

可以调用私有方法、可以修改私有变量。

## 13. Java中范型的概念

## 14. JVM启动参数，-Xms和-Xmx

## 15. 代理机制的实现

## 16. String s = new String("s")，创建了几个对象。

首先在String池内找，找到则不创建String对象，否则创建，这样就一个String对象。遇到new运算符号了，在内存上创建String对象，并将其返回给s，又一个对象。所以创建了2个对象。

## 17. String和StringBuilder、StringBuffer的区别

String对象是不可改变的

StringBuilder对象是可改变的，是线程不安全的

StringBuffer对象是可改变的，是线程安全的

## 18. replaceFirst、replaceAll、replace 区别

## 19. String 对“+”的重载、字符串拼接的几种方式和区别

## 20. String.valueOf 和 Integer.toString 的区别

在Java开发中，我们经常用到将对象转换成String类型这一功能，常用的有如下三种方式：

Ø (String)[对象]

Ø [对象].toString

Ø String.valueOf([对象])

调用toString()方法的对象不能是null，但是String.valueOf()方法却不管这些，这个方法就是在调用 toString() 之前判断一下这个对象是不是null，如果不是null，则正常调用其toString()方法，如果是null 的话，则返回字符串形式的null。

## 21. switch 对 String 的支持

jdk7+支持。其实switch中只能使用整型，字符串的switch是通过equals()和hashCode()方法来实现的。swich只支持一种数据类型，那就是整型，其他数据类型都是转换成整型之后在使用switch的。

## 22. ==和equals的区别

==：等于；

equals：相同；

\1. ==是判断两个变量或实例是不是指向同一个内存空间；equals是判断两个变量或实例所指向的内存空间的值是不是相同 

\2. ==是指对内存地址进行比较；equals()是对字符串的内容进行比较

\3. ==指引用是否相同；equals()指的是值是否相同

## 23. hashCode的作用，和equals方法的关系

Java对象的eqauls方法和hashCode方法是这样规定的：

1、相等（相同）的对象必须具有相等的哈希码（或者散列码）；

2、如果两个对象的hashCode相同，它们并不一定相同。

## 24. Input/OutputStream和Reader/Writer有什么区别  

## 25. 如何在字符流和字节流之间转换？

**将字节流转换成字符流的桥梁**——**InputStreamReader**；

InputStreamReader(InputStream in) ：创建一个使用默认字符集的 InputStreamReader。传入的对象是InputStream类型，而自己本身是Reader的子类。

**将字符流转换成字节流的桥梁**——**OutputStreamWriter**。

OutputStreamWriter(OutputStream out) ：创建使用默认字符编码的 OutputStreamWriter。传入的对象是OutputStream类型，而自己本身是Writer的子类。

从名字就可以看出，他们分别属于（从属关系看名字的后半部分）字符流Reader和Writer，他们的功能（功能看名字的前半部分）和字节流InputStream、OutputStream相关。

## 26. switch可以使用那些数据类型

在switch(exp)中,exp只能是一个**整数表达式**或者**枚举常量**,整数表达式可以是int基本类型或Integer包装类型,其中byte、short、char都可以隐式转换为int。jdk1.7开始支持String类型,但实际上String类型有一个hashCode算法,结果也是int类型。

## 27. Java的四种引用

**a)** **强引用(StrongReference)**

 强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。

**b)**  **软引用(SoftReference)**

如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。

软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。

**c)** **弱引用(WeakReference)**

弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。

弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 

**d)**  **虚引用(PhantomReference)**

"虚引用"顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。

虚引用主要用来跟踪对象被垃圾回收器回收的活动。虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之 关联的引用队列中。 

**e)** **总结**：

WeakReference与SoftReference都可以用来保存对象的实例引用，这两个类与垃圾回收有关。WeakReference是弱引用，其中保存的对象实例可以被GC回收掉。这个类通常用于在某处保存对象引用，而又不干扰该对象被GC回收，通常用于Debug、内存监视工具等程序中。因为这类程序一般要求即要观察到对象，又不能影响该对象正常的GC过程。最近在JDK的Proxy类的实现代码中也发现了Weakrefrence的应用，Proxy会把动态生成的Class实例暂存于一个由Weakrefrence构成的Map中作为Cache。

SoftReference是强引用，它保存的对象实例，除非JVM即将OutOfMemory，否则不会被GC回收。这个特性使得它特别适合设计对象Cache。对于Cache，我们希望被缓存的对象最好始终常驻内存，但是如果JVM内存吃紧，为了不发生OutOfMemoryError导致系统崩溃，必要的时候也允许JVM回收Cache的内存，待后续合适的时机再把数据重新Load到Cache中。这样可以系统设计得更具弹性。

 

## 28. 序列化与反序列化

 

## 29. 正则表达式

 

## 30. int和Integer的区别，什么是自动装箱和自动拆箱

int是基本数据类型，Integer是类。

**自动装箱**：将基本数据类型自动转换为类的对象，例如：Integer i = 100;相当于编译器自动为您作以下的语法编译：Integer i = Integer.valueOf(100);

**自动拆箱(unboxing)**：也就是将对象中的基本数据从对象中自动取出。

Integer i = 10; //装箱 

int t = i; //拆箱，实际上执行了 int t = i.intValue();

## 31. 枚举

## 32. Integer a=100；Integer b= 100；a==b是true or false, 如果是300呢？

如果变量值在-127和128之间，他会直接从事先实例化好的数组里面取，==我们知道，比较的是堆里面的对象，从数组里取，肯定是一样的实例，所以为true； 但是如果不在这个范围内，他会重新 new Integer()对象，那对于Integer a = 300, Integer b = 300;实际是哪个等于 new了两个对象，这时候 == 比较，肯定是false。（具体实现看Integer源码）

 

# 异常相关

## 1. Error和Exception的区别

**a)** **Error**和Exception**的联系**

Ø 继承结构：Error和Exception都是继承于**Throwable**，RuntimeException继承自Exception。

Ø Error和RuntimeException及其子类称为未检查异常（Unchecked exception），其它异常成为受检查异常（Checked Exception）。

**b)**  **Error**和Exception**的区别**

Ø Error类一般是指与虚拟机相关的问题，如系统崩溃，虚拟机错误，内存空间不足，方法调用栈溢出等。如java.lang.StackOverFlowError和Java.lang.OutOfMemoryError。对于这类错误，Java编译器不去检查他们。对于这类错误的导致的应用程序中断，仅靠程序本身无法恢复和预防，遇到这样的错误，建议让程序终止。

Ø Exception类表示程序可以处理的异常，可以捕获且可能恢复。遇到这类异常，应该尽可能处理异常，使程序恢复运行，而不应该随意终止异常。

Ø **注意**：异常和错误的区别：异常能被程序本身可以处理，错误是无法处理。

**c)** **运行时异常和受检查的异常**

Exception又分为运行时异常（Runtime Exception）和受检查的异常(Checked Exception )。

Ø RuntimeException：其特点是Java编译器不去检查它，也就是说，当程序中可能出现这类异常时，即使没有用try……catch捕获，也没有用throws抛出，还是会编译通过，如除数为零的ArithmeticException、错误的类型转换、数组越界访问和试图访问空指针等。处理RuntimeException的原则是：如果出现RuntimeException，那么一定是程序员的错误。

Ø 受检查的异常（IOException等）：这类异常如果没有try……catch也没有throws抛出，编译是通不过的。这类异常一般是外部错误，例如文件找不到、试图从文件尾后读取数据等，这并不是程序本身的错误，而是在应用环境中出现的外部错误。

## 2. 异常的类型，什么是运行时异常和检查时异常

Java 提供了两种Exception 的模式，一种是执行的时候所产生的Exception (Runtime Exception)，另外一种则是受控制的Exception (Checked Exception)。所有方法都可以在不声明throws的情况下抛出RuntimeException及其子类。不可以在不声明的情况下抛出非RuntimeException

**简单的说，非RuntimeException**要自己写catch**块处理掉。**

## 3. final、finally和finalize的区别

## 4. try-catch-finally中，如果在catch中return了，finally中的代码还会执行么，原理是什么？

finally中的代码还会执行。

## 5. 列举3个以上的RuntimeException

最常见到的5个RuntimeException：ClassCastException类转换异常，IllegalArgumentException非法参数异常，IndexOutOfBoundsException数组越界异常，NullPointerException空指针异常，ArrayStoreException数据存储异常。

## 6. Java中的异常处理机制的简单原理和应用 

 

# 集合相关

  

  

## 1. 列举几个Java中Collection类库中的常用类 

继承Collection的主要接口有List与Set，其中实现List的接口的有ArrayList、LinkList、Vector；实现Set接口的主要有HashSet、TreeSet 、LinkedHashSet。 

## 2. List、Set、Map是否都继承自Collection接口？存储特点分别是什么？

List与Set是；Map不是。

List：存储单列元素，元素有放入顺序，元素可重复。List用来处理序列。

Set：存储单列元素，元素无放入顺序，元素不可重复。Set用来处理集合。

Map：元素按键值对存储，键不可重复，无放入顺序。Map用来存储键值对。

## 3. ArrayList、LinkedList和Vector之间的区别与联系

**共同**：都实现了List接口，都存储单列可重复元素，元素有放入顺序。

**区别**：

ArrayList 本质上是一个可改变大小的数组。当元素加入时,其大小将会动态地增长。内部的元素可以直接通过get与set方法进行访问。元素顺序存储,随机访问很快，删除非头尾元素慢，新增元素慢而且费资源，较适用于无频繁增删的情况，比数组效率低，如果不是需要可变数组，可考虑使用数组，非线程安全。

LinkedList 是一个双链表,在添加和删除元素时具有比ArrayList更好的性能.但在get与set方面弱于ArrayList。适用于：没有大规模的随机读取，有大量的增加/删除操作。随机访问很慢，增删操作很快，不耗费多余资源 ,允许null元素,非线程安全。

Vector （类似于ArrayList）但其是同步的，开销就比ArrayList要大。如果你的程序本身是线程安全的，那么使用ArrayList是更好的选择。 Vector和ArrayList在更多元素添加进来时会请求更大的空间。Vector每次请求其大小的双倍空间，而ArrayList每次对size增长50%.

## 4. HashMap和Hashtable、TreeMap以及ConcurrentHashMap的区别

HashMap是基于散列表(数组+链表/红黑树)实现的，时间复杂度平均能达到O(1)；是线程非安全的。

HashTable是线程安全的。

TreeMap基于红黑树（一种自平衡二叉查找树）实现的，时间复杂度平均能达到O(log n)。

## 5. HashMap的实现原理

HashMap中解决hash冲突采用的是**链地址法**，所以其底层实现采用的**数组**+**链表**，HashMap存储的是键值对，其根据key的hashcode选择到对应的数组，将其值存入数组中。

HashMap的主干是一个**Entry**数组**。Entry是HashMap的基本组成单元，每一个Entry包含一个key-value键值对。简单来说，HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的，如果定位到的数组位置不含链表（当前entry的next指向null）,那么对于查找，添加等操作很快，仅需一次寻址即可；如果定位到的数组包含链表，对于添加操作，其时间复杂度为O(n)，首先遍历链表，存在即覆盖，否则新增；对于查找操作来讲，仍需遍历链表，然后通过key对象的equals方法逐一比对查找。所以，性能考虑，HashMap中的链表出现越少，性能才会越好。

  

**扩容**：当发生哈希冲突并且size大于阈值的时候，需要进行数组扩容，扩容时，需要新建一个长度为之前数组2倍的新的数组，然后将当前的Entry数组中的元素全部传输过去，扩容后的新数组长度为之前的2倍，所以扩容相对来说是个耗资源的操作。

## 6. Collection和Collections的区别 

Collection是集合类的上级接口，继承它的主要接口有List与Set。

Collections是针对集合类的一个帮助类，它提供一系列静态方法实现对各种集合的搜索、排序、线程安全化等操作。

## 7. 其他的集合类：TreeSet、LinkedHashMap等。

## 8. ArrayList、HashMap的扩容

<https://www.jianshu.com/p/397d8637f8bc>

# JVM底层技术

## 1. 请介绍一下JVM内存结构？

Java代码是要运行在虚拟机上的，而虚拟机在执行Java程序的过程中会把所管理的内存划分为若干个不同的数据区域，这些区域都有各自的用途。其中有些区域随着虚拟机进程的启动而存在，而有些区域则依赖用户线程的启动和结束而建立和销毁。

**程序计数器**：可看作是当前线程所执行字节码得行号指示器，是线程私有的。唯一一个没有规定任何OOM错误情况的区域。

**虚拟机栈**：Java虚拟机栈也是**线程私有的**，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧用于存放**局部变量、操作数栈、动态链接、方法出口**等信息。一个方法的调用至到完成，对应着一个栈帧在虚拟机栈中入栈与出栈的过程。

**本地方法栈**：本地方法栈与虚拟机栈发挥的作用相似，而本地方法栈是为虚拟机使用到的Native方法服务。

**Java堆**：Java堆是被所有线程共享的一块最大的内存区域。基本上所有的对象实例与数组都在Java堆上分配。Java堆可以处于物理上不连续的内存空间中，其大小可拓展（通过-Xmx和-Xms控制）。

**方法区**：方法区与Java堆一样，是所有线程共享的区域，用于存储已被虚拟机加载的**类信息**、**常量**、**静态变量**、**即时编译器编译后的代码**等数据。这区域的内存回收目标**主要是针对常量池的回收和对类型的卸载**。

**运行时常量池**：运行时常量池是方法区的一部分，其用于存放编译期生成的各种**字面量**和**符号引用**。

## 2. 用过什么垃圾回收器？

**CMS（Concurrent Mark Sweep）**收集器是一种以**获取最短回收停顿时间**为目标的收集器，它非常符合那些集中在互联网站或者B/S系统的服务端上的Java应用，这些应用都非常重视服务的响应速度。从名字上（“Mark Sweep”）就可以看出它是基于**“标记-清除”**算法实现的。

CMS收集器工作的整个流程分为以下4个步骤：

- **初始标记（CMS initial mark）**：仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，需要“Stop The World”。

- **并发标记（CMS concurrent mark）**：进行**GC Roots Tracing**的过程，在整个过程中耗时最长。

- **重新标记（CMS remark）**：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。此阶段也需要“Stop The World”。

- **并发清除（CMS concurrent sweep）**

  ![](.\images\CMS.png)

  **优点**

  ​		CMS是一款优秀的收集器，它的主要**优点**在名字上已经体现出来了：**并发收集**、**低停顿**，因此CMS收集器也被称为**并发低停顿收集器（Concurrent Low Pause Collector）**。

  **缺点**

  - **对CPU资源非常敏感** 其实，面向并发设计的程序都对CPU资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。**CMS默认启动的回收线程数是（CPU数量+3）/4**，也就是当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且随着CPU数量的增加而下降。但是**当CPU不足4个时（比如2个），CMS对用户程序的影响就可能变得很大**，如果本来CPU负载就比较大，还要分出一半的运算能力去执行收集器线程，就可能导致用户程序的执行速度忽然降低了50%，其实也让人无法接受。
  - **无法处理浮动垃圾（Floating Garbage）** 可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。**由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生。**这一部分垃圾出现在标记过程之后，CMS无法再当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就被称为**“浮动垃圾”**。也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。
  - **标记-清除算法导致的空间碎片** CMS是一款基于“标记-清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象。

## 3. 介绍一下Java内存模型(JMM)

Java程序是需要运行在Java虚拟机上面的，**Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。**

**共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范。**

Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。

而**JMM就作用于工作内存和主存之间数据同步过程。他规定了如何做数据同步以及什么时候做数据同步**。![](./images/jmm.png)

**总结下，JMM是一种规范，目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。**

## 4. 内存分配策略

- **对象优先在Eden分配**，当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。
- **大对象直接进入老年代**。大对象是指需要大量连续内存空间的Java对象，最典型的大对象就是那种**很长的字符串**以及**数组**，虚拟机提供一个-XX:PretenureSizeThreshold参数，令大于这个设置值的对象直接在老年代分配，这样做避免在Eden区及两个Survivor区之间发生大量的内存复制。
- **长期存活的对象将进入老年代**，年龄计数器，每经过一次Minor GC，年龄就增加1岁。
- **动态对象年龄判断**：并不是所有对象的年龄达到阈值才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。
- **空间分配担保**

## 5. 线上发送频繁full gc如何处理？

**查看GC日志，定位问题**

可能原因：使用了大对象，如很长的字符串与数组；在程序中长期持有了对象的引用

## 6. CPU使用率过高怎么办？如何定位问题？如何解决？说一下解决思路和处理方法。

[参考链接](https://www.cnblogs.com/myseries/p/11230839.html)

1. ​	定位进程：top命令
2. ​	定位线程：top -Hp 1893 （查看1893进程中的线程）
3. ​	定位代码：printf %x 4519 （把有问题的4519线程转成16进制）
4. ​	通过jstack命令，查看栈信息：`sudo -u admin  jstack 1893 |grep -A 200 11a7`

## 3. 知道字节码吗？字节码都有哪些？Integer X = 5,int y =5，比较x== y都经过哪些步骤？

​	这两个数据的相互比较，无论是谁和谁比，都**最终比较的是存在栈中的值**，因为int是基本数据类型，不能在堆中创建数据，所以无论咋比较，都是将堆中的Integer拆箱（xx.intValue）为int类型的数据，然后进行比较 
int和integer(无论new否)比，都为true，因为会把Integer自动拆箱为int再去比

## 4. 讲讲类加载机制？都有哪些类加载器,这些类加载器都加载哪些文件？手写一下类加载Demo

类加载机制主要采用的**双亲委托机制**。

**类加载器**：引导类加载器、拓展类加载器、应用类加载器、自定义类加载器

- **启动类加载器Bootstrap classLoader**:主要负责加载核心的类库(java.lang.*等)，构造ExtClassLoader和APPClassLoader。

- **拓展类加载器ExtClassLoader**：主要负责加载jre/lib/ext目录下的一些扩展的jar。

- **应用程序类加载器AppClassLoader**：主要负责加载应用程序的主函数类 

  

**手写一个类加载Demo**

  首先要继承ClassLoader类，自己实现一个类加载器不是去覆盖loadClass()方法，而是应该把自己的类加载逻辑写到findClass()方法中，在loadClass()方法的逻辑里如果父类加载失败，则会调用自己的findClass()方法来完成加载。

```java
import java.io.ByteArrayOutputStream;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStream;

/**
 * 自定义文件系统类加载器
 */
public class FileSystemClassLoader extends ClassLoader {
    //com.bjsxt.test.User   --> d:/myjava/  com/bjsxt/test/User.class
    private String rootDir;
    public FileSystemClassLoader(String rootDir){
        this.rootDir = rootDir;
    }

    @Override
    protected Class<?> findClass(String name) throws ClassNotFoundException {
        //应该要先查询有没有加载过这个类。如果已经加载，则直接返回加载好的类。如果没有，则加载新的类。
        Class<?> c = findLoadedClass(name);
        if(c!=null){
            return c;
        }else{
            ClassLoader parent = this.getParent();
            System.out.println(parent);
            try {
                c = parent.loadClass(name);	   //委派给父类加载
            } catch (Exception e) {
				e.printStackTrace();
            }
            if(c!=null){
                return c;
            }else{
                byte[] classData = getClassData(name);
                if(classData==null){
                    throw new ClassNotFoundException();
                }else{
                    c = defineClass(name, classData, 0,classData.length);
                }
            }
        }
        return c;
    }

    private byte[] getClassData(String classname){
        String path = rootDir +"/"+ classname.replace('.', '/')+".class";
		//IOUtils,可以使用它将流中的数据转成字节数组
        InputStream is = null;
        ByteArrayOutputStream baos = new ByteArrayOutputStream();
        try{
            is  = new FileInputStream(path);
            byte[] buffer = new byte[1024];
            int temp=0;
            while((temp=is.read(buffer))!=-1){
                baos.write(buffer, 0, temp);
            }
            return baos.toByteArray();
        }catch(Exception e){
            e.printStackTrace();
            return null;
        }finally{
            try {
                if(is!=null){
                    is.close();
                }
            } catch (IOException e) {
                e.printStackTrace();
            }
            try {
                if(baos!=null){
                    baos.close();
                }
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }
}
```



## 5. 知道osgi吗？他是如何实现的？

## 6. 请问你做过哪些JVM优化？使用什么方法？达到什么效果？

## 7. Class.forName("java. lang. String")和String.class. getClassLoader().loadClass ("java.lang.String")什么区别？

**类装载**的两种方式：

1. Class c1 = Class.forName ("java.lang.String");  // 反射

2. ClassLoader c1 = new  ClassLoader(); 

   Class c1.loadClass( String name, boolean resolve );

**区别一**：Class.forName是从指定的classloader中装载类,如果没有指定,也就是一个参数的时候,是从装载当前对象实例所在的classloader中装载类。而ClassLoader的实例调用loadclass方法,是指从当前ClassLoader实例中调用类,而这个实例与装载当前所在类实例的Classloader也许不是同一个。说白了就是他们**实现装载的时候，使用的类装载器的指定是不同的**。

**区别二**：Class.forName(className)实际上是调用Class.forName(className, true, this.getClass(). getClassLoader())。注意第二个参数，是指Class被loading后是不是必须被初始化。ClassLoader.loadClass (className)实际上调用的是ClassLoader.loadClass(name, false)，第二个参数指出Class是否被链接（不连接也不会初始化）。区别就出来了。**Class.forName(className)装载的class已经被实例化，而ClassLoader.loadClass(className)装载的class还没有被连接，所以就更谈不上实例化了**。

一般情况下，这两个方法效果一样，都能装载Class。但如果程序需要Class被实例化，就必须用Class.forName(name)了。

## 8. 锁优化

- **适应性自旋**
- **锁消除**：判断数据是否存在共享与竞争，判定来源于逃逸分析的数据支持，如果判断在一段代码中，堆上的所有数据都不会逃逸出去从而被其他线程访问到，则把它当做栈上的数据对待，认为它是线程私有的。
- **锁粗化**：如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有线程竞争，频繁的互斥操作也会导致不必要的性能损耗。
- **轻量级锁**：轻量级锁并不是用来代替重量级锁，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。
- **偏向锁**



## 9. 类加载过程

1. **加载:**查找并加载类的二进制数据
2. **连接**：
   - 验证:确保被加载的类的正确性

   - 准备:为类的静态变量分配内存，并将其初始化为默认值

   - 解析:把类中的符号引用转换为直接引用

4. **初始化:**为类的静态变量赋予正确的初始值
5. **使用**
6. **卸载**

## 10. 深入理解类加载器

- 类的加载是放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类。
- 对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。

## 11. gc的概念，如果A和B对象循环引用，是否可以被GC？

如果采用引用计数法，那么循环引用便不能被GC 

## 12. jvm gc如何判断对象是否需要回收，有哪几种方式？

引用计数法；

可达性分析算法：虚拟机栈（栈帧中的本地变量表）中引用的对象；方法区静态属性引用的对象；方法区中常量引用的对象；本地方法栈中JNI（即一般说的Native方法）引用的对象。

## 13. Java中能不能主动触发GC

不能

## 14. JVM的内存结构，堆和栈的区别

**栈区**：

栈分为**java虚拟机栈**和**本地方法栈**

重点是Java虚拟机栈，它是线程私有的，生命周期与线程相同。

每个方法执行都会创建一个栈帧，用于存放局部变量表，操作栈，动态链接，方法出口等。每个方法从被调用，直到被执行完。对应着一个栈帧在虚拟机中从入栈到出栈的过程。

通常说的栈就是指局部变量表部分，存放编译期间可知的8种基本数据类型，及对象引用和指令地址。局部变量表是在编译期间完成分配，当进入一个方法时，这个栈中的局部变量分配内存大小是确定的。

会有两种异常StackOverFlowError和 OutOfMemoneyError。当线程请求栈深度大于虚拟机所允许的深度就会抛出StackOverFlowError错误；虚拟机栈动态扩展，当扩展无法申请到足够的内存空间时候，抛出OutOfMemoneyError。

本地方法栈为虚拟机使用到本地方法服务（native）

**堆区**：

堆被所有线程共享区域，在虚拟机启动时创建，唯一目的存放对象实例。

堆区是GC的主要区域，通常情况下分为两个区块**新生代**和**老年代**。更细一点新生代又分为**Eden**区**放新创建对象、**From survivor** 和 **To survivor** 保存GC后幸存下的对象，默认情况下各自占比 8:1:1。

不过很多文章介绍分为3个区块，把**方法区算着为永久代**。这大概是基于Hotspot虚拟机划分，然后比如IBM j9就不存在永久代概论。不管怎么分区，都是存放对象实例。会有异常OutOfMemoneyError。

**方法区**：

被所有线程共享区域，用于存放已被虚拟机加载的**类信息**，**常量**，**静态变量**等数据。被Java虚拟机描述为堆的一个逻辑部分。习惯是也叫它**永久代**（permanment generation）

垃圾回收很少光顾这个区域，不过也是需要回收的，主要针对**常量池回收**，**类型卸载**。

常量池用于存放编译期生成的各种字节码和符号引用，常量池具有一定的动态性，里面可以存放编译期生成的常量；运行期间的常量也可以添加进入常量池中，比如string的intern()方法。

**程序计数器**：

当前线程所执行的行号指示器。通过改变计数器的值来确定下一条指令，比如循环，分支，跳转，异常处理，线程恢复等都是依赖计数器来完成。

Java虚拟机多线程是通过线程轮流切换并分配处理器执行时间的方式实现的。为了线程切换能恢复到正确的位置，每条线程都需要一个独立的程序计数器，所以它是线程私有的。

唯一一块Java虚拟机没有规定任何OutofMemoryError的区块。

## 15. JVM堆的分代

**新生代**：新生代又分为Eden区放新创建对象、From survivor 和 To survivor 保存GC后幸存下的对象，默认情况下各自占比 8:1:1。

**老年代**：

**永久代**：方法区

## 16. Minor GC、Major GC和Full GC之间的区别

**Minor GC**：从年轻代空间（包括 Eden 和 Survivor 区域）回收内存被称为 Minor GC,因为 Java 对象大多都具备朝生夕灭的特性，所以 Minor GC 非常频繁，一般回收速度也比较快。

**Major GC**：指发生在老年代的 GC，出现了 Major GC，经常会伴随至少一次的 Minor GC（但非绝对的，ParallelScavenge 收集器的收集策略里就有直接进行 Major GC 的策略选择过程） 。MajorGC 的速度一般会比 Minor GC 慢 10倍以上。

**Full GC**：是清理整个堆空间—包括年轻代和永久代。



**Minor GC触发机制**：

当年轻代满时就会触发Minor GC，这里的年轻代满指的是Eden代满，Survivor满不会引发GC。 

**Full GC触发机制**：

（1）调用System.gc时，系统建议执行Full GC，但是不必然执行

（2）老年代空间不足

（3）方法区空间不足

（4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存

（5）由Eden区、survivor space1（From Space）区向survivor space2（To Space）区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小

 

## 17. Java中的内存溢出是什么，和内存泄露有什么关系

**内存溢出 out of memory**，是指程序在申请内存时，没有足够的内存空间供其使用，出现out of memory；比如申请了一个integer,但给它存了long才能存下的数，那就是内存溢出。

**内存泄露 memory leak**，是指程序在申请内存后，无法释放已申请的内存空间，一次内存泄露危害可以忽略，但内存泄露堆积后果很严重，无论多少内存,迟早会被占光。

## 18. Java的类加载机制，什么是双亲委派机制？

双亲委派机制是为了保证java核心库的类型安全；这种机制就保证不会出现用户能定义java.lang.Object类的情况

# IO

## 1. BIO(Blocking I/O)、NIO(New I/O)和AIO(Asynchronous I/O)和之间的区别

 IO的方式通常分为几种，同步阻塞的BIO、同步非阻塞的NIO、异步非阻塞的AIO。

同步和异步关注的是**消息通信机制**。

阻塞和非阻塞关注的是**程序在等待调用结果（消息，返回值）时的状态。**

**1)** **BIO**

 在JDK1.4出来之前，我们建立网络连接的时候采用BIO模式，需要先在服务端启动一个ServerSocket，然后在客户端启动Socket来对服务端进行通信，默认情况下服务端需要对每个请求建立一堆线程等待请求，而客户端发送请求后，先咨询服务端是否有线程相应，如果没有则会一直等待或者遭到拒绝请求，如果有的话，客户端会线程会等待请求结束后才继续执行。

**2)** **NIO**

NIO本身是基于**事件驱动**思想来完成的，其主要想解决的是BIO的**大并发**问题：在使用同步I/O的网络应用中，如果要同时处理多个客户端请求，或是在客户端要同时和多个服务器进行通讯，就必须使用多线程来处理。也就是说，将每一个客户端请求分配给一个线程来单独处理。这样做虽然可以达到我们的要求，但同时又会带来另外一个问题。由于每创建一个线程，就要为这个线程分配一定的内存空间（也叫工作存储器），而且操作系统本身也对线程的总数有一定的限制。如果客户端的请求过多，服务端程序可能会因为不堪重负而拒绝客户端的请求，甚至服务器可能会因此而瘫痪。BIO模型中一般是采用每连接一个线程的模型，是因为BIO中读写操作是阻塞的，读写一个连接的时候没法处理其他连接。而NIO中，读写函数是非阻塞的，如果一个连接不能读写（socket.read()返回0或者socket.write()返回0），我们可以把其记录下来（在Selector上注册标记位），然后切换到其它就绪的连接（channel）继续进行读写。

NIO基于Reactor，当socket有流可读或可写入socket时，操作系统会相应的通知引用程序进行处理，应用再将流读取到缓冲区或写入操作系统。也就是说，这个时候，已经不是一个连接就要对应一个处理线程了，而是有效的请求，对应一个线程，当连接没有数据时，是没有工作线程来处理的。

BIO与NIO一个比较重要的不同，是我们使用BIO的时候往往会引入多线程，每个连接一个单独的线程；而NIO则是使用单线程或者只使用少量的多线程，每个连接共用一个线程。

NIO的最重要的地方是当一个连接创建后，不需要对应一个线程，这个连接会被注册到多路复用器上面，所以所有的连接只需要一个线程就可以搞定，当这个线程中的多路复用器进行轮询的时候，发现连接上有请求的话，才开启一个线程进行处理，也就是**一个请求一个线程模式**。

在NIO的处理方式中，当一个请求来的话，开启线程进行处理，可能会等待后端应用的资源(JDBC连接等)，其实这个线程就被阻塞了，当并发上来的话，还是会有BIO一样的问题。

HTTP/1.1出现后，有了Http长连接，这样除了超时和指明特定关闭的http header外，这个链接是一直打开的状态的，这样在NIO处理中可以进一步的进化，在后端资源中可以实现资源池或者队列，当请求来的话，开启的线程把请求和请求数据传送给后端资源池或者队列里面就返回，并且在全局的地方保持住这个现场(哪个连接的哪个请求等)，这样前面的线程还是可以去接受其他的请求，而后端的应用的处理只需要执行队列里面的就可以了，这样请求处理和后端应用是异步的.当后端处理完，到全局地方得到现场，产生响应，这个就实现了异步处理。

NIO主要是三部分**：Channel**，**Buffer**和**Selector**。工作原理：有一个专门的线程处理所有的IO事件并负责分发，事件到的时候触发，而非同步的去监视的事件。

总结一下到底NIO给我们带来了些什么：

Ø 事件驱动模型

Ø 避免多线程

Ø 单线程处理多任务

Ø 非阻塞I/O：I/O读写不再阻塞，而是返回0

Ø 基于block的传输，通常比基于流的传输更高效

Ø 更高级的IO函数，zero-copy

**3)** **AIO**

与NIO不同，当进行读写操作时，只须直接调用API的read或write方法即可。这两种方法均为异步的，对于读操作而言，当有流可读取时，操作系统会将可读的流传入read方法的缓冲区，并通知应用程序；对于写操作而言，当操作系统将write方法传递的流写入完毕时，操作系统主动通知应用程序。即可以理解为，read/write方法都是异步的，完成后会主动调用回调函数。在JDK1.7中，这部分内容被称作NIO.2，主要在java.nio.channels包下增加了下面四个异步通道：

· AsynchronousSocketChannel

· AsynchronousServerSocketChannel

· AsynchronousFileChannel

· AsynchronousDatagramChannel

其中的read/write方法，会返回一个带回调函数的对象，当执行完读取/写入操作后，直接调用回调函数。

**BIO**是一个连接一个线程。**

**NIO**是一个请求一个线程。**

**AIO**是一个有效请求一个线程**。

 

**Java**对BIO**、NIO**、AIO**的支持**：

Ø Java BIO：同步并阻塞，服务器实现模式为**一个连接一个线程**，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。

Ø Java NIO：同步非阻塞，服务器实现模式为**一个请求一个线程**，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。

Ø Java AIO(NIO.2)：异步非阻塞，服务器实现模式为**一个有效请求一个线程**，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理。

**BIO**、NIO**、AIO**适用场景分析:**

Ø BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。

Ø NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。

Ø AIO方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。

另外，I/O属于底层操作，需要操作系统支持，并发也需要操作系统的支持，所以性能方面不同操作系统差异会比较明显。

在高性能的I/O设计中，有两个比较著名的模式Reactor和Proactor模式，其中Reactor模式用于同步I/O，而Proactor运用于异步I/O操作。

在比较这两个模式之前，我们首先的搞明白几个概念，什么是阻塞和非阻塞，什么是同步和异步,同步和异步是针对应用程序和内核的交互而言的，同步指的是用户进程触发IO操作并等待或者轮询的去查看IO操作是否就绪，而异步是指用户进程触发IO操作以后便开始做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知。而阻塞和非阻塞是针对于进程在访问数据的时候，根据IO操作的就绪状态来采取的不同方式，说白了是一种读取或者写入操作函数的实现方式，阻塞方式下读取或者写入函数将一直等待，而非阻塞方式下，读取或者写入函数会立即返回一个状态值。

 一般来说I/O模型可以分为：同步阻塞，同步非阻塞，异步阻塞，异步非阻塞IO

同步阻塞IO：在此种方式下，用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行。JAVA传统的IO模型属于此种方式！

同步非阻塞IO:在此种方式下，用户进程发起一个IO操作以后边可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费。其中目前JAVA的NIO就属于同步非阻塞IO。

异步阻塞IO：此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问IO是否完成，那么为什么说是阻塞的呢？因为此时是通过select系统调用来完成的，而select函数本身的实现方式是阻塞的，而采用select函数有个好处就是它可以同时监听多个文件句柄，从而提高系统的并发性！

 异步非阻塞IO:在此种模式下，用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了。

## 2. IO和NIO常用用法

<https://blog.csdn.net/anxpp/article/details/51512200>

 

那么什么是阻塞IO、非阻塞IO、同步IO、异步IO呢？

一个IO操作其实分成了两个步骤**：发起**IO**请求**和**实际**IO**操作**

阻塞IO和非阻塞IO的区别在于第一步：发起IO请求是否会被阻塞，如果阻塞直到完成那么就是传统的阻塞IO;如果不阻塞，那么就是非阻塞IO

同步IO和异步IO的区别就在于第二个步骤是否阻塞，如果实际的IO读写阻塞请求进程，那么就是同步IO，因此阻塞IO、非阻塞IO、IO复用、信号驱动IO都是同步IO;如果不阻塞，而是操作系统帮你做完IO操作再将结果返回给你，那么就是异步IO。

 

# Netty

## 1. 讲讲Netty的特点？

Ø **高并发**：Netty是一款基于NIO（Nonblocking I/O，非阻塞IO）开发的网络通信框架，对比于BIO（Blocking I/O，阻塞IO），他的并发性能得到了很大提高 。

Ø **传输快**：Netty的传输快其实也是依赖了NIO的一个特性——零拷贝。

Ø **封装好**：Netty封装了NIO操作的很多细节，提供易于使用的API。

## 2. BIO、NIO和AIO的区别？

## 3. NIO的组成是什么？

## 4. 如何使用 Java NIO 搭建简单的客户端与服务端实现网络通讯？

## 5. 如何使用 Netty 搭建简单的客户端与服务端实现网络通讯？

## 6. 讲讲Netty 底层操作与 Java NIO 操作对应关系？

## 7. Channel 与 Socket是什么关系，Channel 与 EventLoop是什么关系，Channel 与 ChannelPipeline是什么关系？

在基于Java的网络编程中，其基本的构造是类Socket。Netty的 Channel 接口所提供的API，大大地降低了直接使用Socket类的复杂性。

一个EventLoop是一条单纯的线程，用于处理注册在其上面的所有I/O事件，也就是说，Channel是需要注册到EventLoop上面去的，而且一个EventLoop通常会有多个Channel注册，而EventLoopGroup则是EventLoop的集合。

在Netty中每个Channel都有仅有一个ChannelPipeline与之对应，它们的组成关系如下：

  

 

## 8. EventLoop与EventLoopGroup 是什么关系？

一个EventLoop是一条单纯的线程，用于处理注册在其上面的所有I/O事件，也就是说，Channel是需要注册到EventLoop上面去的，而且一个EventLoop通常会有多个Channel注册，而EventLoopGroup则是EventLoop的集合。

## 9. 说说Netty中几个重要的对象是什么，它们之间的关系是什么？

## 10. Netty的线程模型是什么？

## 11. 什么是粘包与半包问题?

**粘包**： 如果发送的包的大小比TCP发送缓存容量小，并且TCP缓存可以存放多个包，那么客户端和服务端的一次通信就可能传递了多个包，这时候服务端从接受缓存就可能一下读取了多个包，这时候就出现了粘包现象。

**半包**：如果发送的包的大小比TCP发送缓存的容量大，那么这个数据包就会被分成多个包，通过socket多次发送到服务端，服务端第一次从接受缓存里面获取的数据，实际是整个包的一部分，这时候就产生了半包现象，半包不是说只收到了全包的一半，是说收到了全包的一部分。

<https://blog.csdn.net/zhailuxu/article/details/80388000>

## 12. 粘包与半包为何会出现?

 

## 13. 如何避免粘包与半包问题？

**消息定长**，报文大小固定长度，不够空格补全，发送和接收方遵循相同的约定，这样即使粘包了通过接收方编程实现获取定长报文也能区分。

**包尾添加特殊分隔符**，例如每条报文结束都添加回车换行符（例如FTP协议）或者指定特殊字符作为报文分隔符，接收方通过特殊分隔符切分报文区分。

**将消息分为消息头和消息体**，消息头中包含表示信息的总长度（或者消息体长度）的字段。

 

## 14. 如何使用包定长FixedLengthFrameDecoder解决粘包与半包问题？原理是什么？

Netty中提供了FixedLengthFrameDecoder定长解码器可以帮助我们轻松实现第一种解决方案，**定长解码报文**。**如果原始数据的长度不够定长，需要增加空格来达到定长。**

 

## 15. 如何使用包分隔符DelimiterBasedFrameDecoder解决粘包与半包问题？原理是什么？

 

## 16. Dubbo在使用Netty作为网络通讯时候是如何避免粘包与半包问题？

自定义包，将消息分为消息头和消息体

 

## 17. 什么时候需要考虑粘包与半包问题？

## 18. 服务端如何进行初始化？

## 19. 何时接受客户端请求？

## 20. 何时注册接受Socket并注册到对应的 EventLoop 管理的 Selector ？

## 21. 客户端如何进行初始化？

## 22. 何时创建的 DefaultChannelPipeline？

## 23. 讲讲Netty的零拷贝？

Netty的零拷贝体现在三个方面：

\1. Netty的接收和发送ByteBuffer采用DIRECT BUFFERS，使用堆外直接内存进行Socket读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存（HEAP BUFFERS）进行Socket读写，JVM会将堆内存Buffer拷贝一份到直接内存中，然后才写入Socket中。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。

\2. Netty提供了组合Buffer对象，可以聚合多个ByteBuffer对象，用户可以像操作一个Buffer那样方便的对组合Buffer进行操作，避免了传统通过内存拷贝的方式将几个小Buffer合并成一个大的Buffer。

\3. Netty的文件传输采用了transferTo方法，它可以直接将文件缓冲区的数据发送到目标Channel，避免了传统通过循环write方式导致的内存拷贝问题。

# 其它

## 1. hashcode有哪些算法

目前流行的Hash算法包括 MD5、SHA-1 和 SHA-2。

MD4（RFC 1320）是 MIT 的 Ronald L. Rivest 在 1990 年设计的，MD 是 Message Digest 的缩写。其输出为 128 位。MD4 已证明不够安全。

MD5（RFC 1321）是 Rivest 于1991年对 MD4 的改进版本。它对输入仍以 512 位分组，其输出是 128 位。MD5 比 MD4 复杂，并且计算速度要慢一点，更安全一些。MD5 已被证明不具备"强抗碰撞性"。

SHA （Secure Hash Algorithm）是一个 Hash 函数族，由 NIST（National Institute of Standards and Technology）于 1993 年发布第一个算法。目前知名的 SHA-1 在 1995 年面世，它的输出为长度 160 位的 hash 值，因此抗穷举性更好。SHA-1 设计时基于和 MD4 相同原理，并且模仿了该算法。SHA-1已被证明不具"强抗碰撞性"。

为了提高安全性，NIST 还设计出了 SHA-224、SHA-256、SHA-384，和 SHA-512 算法（统称为 SHA-2），跟 SHA-1 算法原理类似。SHA-3 相关算法也已被提出。

## 2. 反射的基本概念，反射是否可以调用私有方法

在了解反射之前，应该先了解Java中的Class类。Class类在开发中最常见的用法就

# MVC框架

## 1. 介绍几个常用的MVC框架

## 2. 什么是MVC

## 3. Struts中请求的实现过程 

## 4. Spring mvc与Struts mvc的区别

## 5. Service嵌套事务处理，如何回滚

## 6. struts2中拦截器与过滤器的区别及执行顺序

## 7. struts2拦截器的实现原理

# http相关

## 1. session和cookie的区别

cookie是把用户的数据写给用户的浏览器

session技术把用户的数据写到用户独占的session中（服务端）

## 2. HTTP请求中session实现原理？ 

## 3. 如果客户端禁止Cookie能实现Session吗？ 

## 4. http中get和post区别 

## 5. redirect与forward的区别

## 6. 常见的web请求返回的状态码。404、302、301、500分别代表什么

# SSH相关

## 1. Hibernate/Ibatis/MyBatis之间的区别

## 2. 什么是OR Mapping

## 3. hibernate的缓存机制、一级和二级缓存

## 4. 使用Spring的好处是什么，Spring的核心理念

## 5. 什么是AOP和IOC，实现原理是什么

## 6. spring bean的初始化过程

## 7. Spring的事务管理，Spring bean注入的几种方式 

## 8. spring四种依赖注入方式

# 容器相关

## 1. 什么是web服务器、什么是应用服务器

**Web**服务器**可以解析(handles)HTTP协议。当Web服务器接收到一个HTTP请求(request)，会返回一个HTTP响应 (response)，例如送回一个HTML页面。为了处理一个请求(request)，Web服务器可以响应(response)一个静态页面或图片，进行页面跳转(redirect)，或者把动态响应(dynamic response)的产生委托(delegate)给一些其它的程序例如CGI脚本，JSP(JavaServer Pages)脚本，servlets，ASP(Active Server Pages)脚本，服务器端(server-side)JavaScript，或者一些其它的服务器端(server-side)技术。无论它们(译者 注：脚本)的目的如何，这些服务器端(server-side)的程序通常产生一个HTML的响应(response)来让浏览器可以浏览。 

要知道，Web服务器的代理模型(delegation model)非常简单。当一个请求(request)被送到Web服务器里来时，它只单纯的把请求(request)传递给可以很好的处理请求 (request)的程序(译者注：服务器端脚本)。Web服务器仅仅提供一个可以执行服务器端(server-side)程序和返回(程序所产生的)响 应(response)的环境，而不会超出职能范围。服务器端(server-side)程序通常具有事务处理(transaction processing)，数据库连接(database connectivity)和消息(messaging)等功能。 

虽然Web服务器不支持事务处理或数据库连接池，但它可以配置(employ)各种策略(strategies)来实现容错性(fault tolerance)和可扩展性(scalability)，例如负载平衡(load balancing)，缓冲(caching)。集群特征(clustering—features)经常被误认为仅仅是应用程序服务器专有的特征。

**应用程序服务器**，它通过各种协议，可以包括HTTP，把商业逻辑暴露给(expose)客户端应用程序。Web服务器主要是处理向浏览器发送HTML以供浏览，而应用程序服务器提供访问商业逻辑的途径以供客户端应用程序使用。应用程序使用此商业逻辑就象你调用对象的一个方法(或过程语言中的一个函数)一样。 

应用程序服务器的客户端(包含有图形用户界面(GUI)的)可能会运行在一台PC、一个Web服务器或者甚至是其它的应用程序服务器上。在应用程序服务器与其客户端之间来回穿梭(traveling)的信息不仅仅局限于简单的显示标记。相反，这种信息就是程序逻辑(program logic)。 正是由于这种逻辑取得了(takes)数据和方法调用(calls)的形式而不是静态HTML，所以客户端才可以随心所欲的使用这种被暴露的商业逻辑。

在大多数情形下，应用程序服务器是通过组件(component)的应用程序接口(API)把商业逻辑暴露(expose)(给客户端应用程序)的，例如 基于J2EE(Java 2 Platform, Enterprise Edition)应用程序服务器的EJB(Enterprise JavaBean)组件模型。此外，应用程序服务器可以管理自己的资源，例如看大门的工作(gate-keeping duties)包括安全(security)，事务处理(transaction processing)，资源池(resource pooling)， 和消息(messaging)。就象Web服务器一样，应用程序服务器配置了多种可扩展(scalability)和容错(fault tolerance)技术。

 

## 2. 常用的web服务器有哪些？

① **Apache**是世界使用排名的Web服务器软件。它几乎可以运行在所有的计算机平台上。由于Apache是开源免费的，因此有很多人参与到新功能的开发设计，不断对其进行完善。 Apache的特点是简单、速度快、性能稳定，并可做代理服务器来使用。

② **IIS**（Internet信息服务）英文Internet Information Server的缩写。它是微软公司主推的服务器。IIS的特点具有：安全性，强大，灵活。

③ **Nginx**不仅是一个小巧且高效的HTTP服务器，也可以做一个高效的负载均衡反向代理，通过它接受用户的请求并分发到多个Mongrel进程可以极大提高Rails应用的并发能力。

④ **Tomcat**是Apache 软件基金会（Apache Software Foundation）的Jakarta 项目中的一个核心项目，由Apache、Sun 和其他一些公司及个人共同开发而成。Tomcat 技术先进、性能稳定，而且免费，因而深受Java 爱好者的喜爱并得到了部分软件开发商的认可，成为目前比较流行的Web 应用服务器。

⑤ **Lighttpd**是由德国人 Jan Kneschke 领导开发的，基于BSD许可的开源WEB服务器软件，其根本的目的是提供一个专门针对高性能网站，安全、快速、兼容性好并且灵活的web server环境。具有非常低的内存开销，CPU占用率低，效能好，以及丰富的模块等特点。支持FastCGI, CGI, Auth, 输出压缩(output compress), URL重写, Alias等重要功能。

⑥ **Zeus**是一个运行于Unix下的非常的Web 服务器，据说性能超过Apache，是效率的Web 服务器之一。

 

## 3. Tomcat和weblogic的区别 

# web安全

## 1. 什么是SQL注入，如何避免。

所谓SQL注入式攻击，就是攻击者把SQL命令插入到Web表单的输入域或页面请求的查询字符串，欺骗服务器执行恶意的SQL命令。在某些表单中，用户输入的内容直接用来构造(或者影响)动态SQL命令，或作为存储过程的输入参数，这类表单特别容易受到SQL注入式攻击。常见的SQL注入式攻击过程类如：

1) 某个ASP.NET Web应用有一个登录页面，这个登录页面控制着用户是否有权访问应用，它要求用户输入一个名称和密码。

2) 登录页面中输入的内容将直接用来构造动态的SQL命令，或者直接用作存储过程的参数。下面是ASP.NET应用构造查询的一个例子：

System.Text.StringBuilder query = newSystem.Text.StringBuilder ("SELECT * from Users WHERE login =’")。Append(txtLogin.Text)。Append("’ ANDpassword=’")。Append(txtPassword.Text)。Append("’");

3) 攻击者在用户名字和密码输入框中输入"’或’1’=’1"之类的内容。

4) 用户输入的内容提交给服务器之后，服务器运行上面的ASP.NET代码构造出查询用户的SQL命令，但由于攻击者输入的内容非常特殊，所以最后得到的SQL命令变成：SELECT* from Users WHERE login = ’’ or ’1’=’1’ AND password = ’’ or’1’=’1’.

5) 服务器执行查询或存储过程，将用户输入的身份信息和服务器中保存的身份信息进行对比。

6) 由于SQL命令实际上已被注入式攻击修改，已经不能真正验证用户身份，所以系统会错误地授权给攻击者。

如果攻击者知道应用会将表单中输入的内容直接用于验证身份的查询，他就会尝试输入某些特殊的SQL字符串篡改查询改变其原来的功能，欺骗系统授予访问权限。

系统环境不同，攻击者可能造成的损害也不同，这主要由应用访问数据库的安全权限决定。如果用户的帐户具有管理员或其他比较高级的权限，攻击者就可能对数据库的表执行各种他想要做的操作，包括添加、删除或更新数据，甚至可能直接删除表。

**如何防范?**

好在要防止ASP.NET应用被SQL注入式攻击闯入并不是一件特别困难的事情，只要在利用表单输入的内容构造SQL命令之前，把所有输入内容过滤一番就可以了。过滤输入内容可以按多种方式进行。

1) 对于动态构造SQL查询的场合，可以使用下面的技术：

a) 替换单引号，即把所有单独出现的单引号改成两个单引号，防止攻击者修改SQL命令的含义。再来看前面的例子，“SELECT* from Users WHERE login = ’’’ or ’’1’’=’’1’ AND password = ’’’ or’’1’’=’’1’”显然会得到与“SELECT * from Users WHERE login = ’’ or ’1’=’1’AND password = ’’ or ’1’=’1’”不同的结果。

b) 删除用户输入内容中的所有连字符，防止攻击者构造出类如“SELECT * from Users WHERE login= ’mas’ —— AND password=’’”之类的查询，因为这类查询的后半部分已经被注释掉，不再有效，攻击者只要知道一个合法的用户登录名称，根本不需要知道用户的密码就可以顺利获得访问权限。

c) 对于用来执行查询的数据库帐户，限制其权限。用不同的用户帐户执行查询、插入、更新、删除操作。由于隔离了不同帐户可执行的操作，因而也就防止了原本用于执行SELECT命令的地方却被用于执行INSERT、UPDATE或DELETE命令。

2) 用存储过程来执行所有的查询。SQL参数的传递方式将防止攻击者利用单引号和连字符实施攻击。此外，它还使得数据库权限可以限制到只允许特定的存储过程执行，所有的用户输入必须遵从被调用的存储过程的安全上下文，这样就很难再发生注入式攻击了。

3) 限制表单或查询字符串输入的长度。如果用户的登录名字最多只有10个字符，那么不要认可表单中输入的10个以上的字符，这将大大增加攻击者在SQL命令中插入有害代码的难度。

4) 检查用户输入的合法性，确信输入的内容只包含合法的数据。数据检查应当在客户端和服务器端都执行——之所以要执行服务器端验证，是为了弥补客户端验证机制脆弱的安全性。在客户端，攻击者完全有可能获得网页的源代码，修改验证合法性的脚本(或者直接删除脚本)，然后将非法内容通过修改后的表单提交给服务器。因此，要保证验证操作确实已经执行，唯一的办法就是在服务器端也执行验证。你可以使用许多内建的验证对象，例如RegularExpressionValidator，它们能够自动生成验证用的客户端脚本，当然你也可以插入服务器端的方法调用。如果找不到现成的验证对象，你可以通过CustomValidator自己创建一个。

5) 将用户登录名称、密码等数据加密保存。加密用户输入的数据，然后再将它与数据库中保存的数据比较，这相当于对用户输入的数据进行了“消毒”处理，用户输入的数据不再对数据库有任何特殊的意义，从而也就防止了攻击者注入SQL命令。System.Web.Security.FormsAuthentication类有一个HashPasswordForStoringInConfigFile，非常适合于对输入数据进行消毒处理。

6) 检查提取数据的查询所返回的记录数量。如果程序只要求返回一个记录，但实际返回的记录却超过一行，那就当作出错处理。

## 2. 什么是XSS攻击，如何避免

## 3. 什么是CSRF攻击，如何避免

Cross-site request forgery 跨站请求伪造，也被称为“one click attack” 或者 session riding，通常缩写为 CSRF 或者 XSRF，是一种对网站的恶意利用；可以这么理解CSRF攻击：攻击者盗用你的身份，以你的名义向第三方网站发送恶意请求。CRSF能做的事情包括利用你的身份发邮件，发短信，进行交易转账，甚至盗取账号信息。

**防御方法**：

CSRF的防御可以从服务端和客户端两方面着手，防御效果是从服务端着手效果比较好，现在一般的CSRF防御也都在服务端进行。

服务端的预防CSRF攻击的方式方法有多种，但思想上都是差不多的，主要从以下2个方面入手：

Ø 正确使用GET,POST和Cookie；

Ø 在非GET请求中增加伪随机数；

由这两个方面我们可以想到很多方法：

a) token机制：SRF 主流防御方式是在后端生成表单的时候生成一串随机 token ，内置到表单里成为一个字段，同时，将此串 token 置入 session 中。每次表单提交到后端时都会检查这两个值是否一致，以此来判断此次表单提交是否是可信的。提交过一次之后，如果这个页面没有生成 CSRF token ，那么 token 将会被清空，如果有新的需求，那么 token 会被更新。攻击者可以伪造 POST 表单提交，但是他没有后端生成的内置于表单的 token，session 中有没有 token 都无济于事。(此方法用到了<input type = "hidden" />)

b) 验证码。通常情况下，验证码能够很好的遏制CSRF攻击，但是很多情况下，出于用户体验考虑，验证码只能作为一种辅助手段，而不是最主要的解决方案。

c) referer识别。在HTTP Header中有一个字段Referer，它记录了HTTP请求的来源地址。如果Referer是其他网站，就有可能是CSRF攻击，则拒绝该请求。但是，服务器并非都能取到Referer。很多用户出于隐私保护的考虑，限制了Referer的发送。在某些情况下，浏览器也不会发送Referer，例如HTTPS跳转到HTTP。

# 动态代理

## 1. Java的动态代理的概念

代理类在程序运行时创建的代理方式被成为动态代理。相比于静态代理， 动态代理的优势在于可以很方便的对代理类的函数进行统一的处理，而不用修改每个代理类的函数。

## 2. Java的动态代理的实现

1、建立代理对象和真实对象的关系。

2、实现代理逻辑方法。

## 3. JDK原生和cglib的区别

java动态代理是利用**反射机制**生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。通过 Proxy.newProxyInstance 创建的代理对象是在jvm运行时动态生成的一个对象，它并不是我们的InvocationHandler类型，也不是我们定义的那组接口的类型，而是在运行是动态生成的一个对象，并且命名方式都是这样的形式，以$开头，proxy为中，最后一个数字表示对象的标号。这也是静态代理和动态代理根本上的区别。

而cglib动态代理是利用asm开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。

# 编码问题

## 1. 常用的字符编码

## 2. 如何解决中文乱码问题

# C++相关

## 1. 构造

## 2. 函数和析构函数

## 3. 为什么不要在构造器中调用虚函数

## 4. 为什么不要在析构函数中抛出异常

## 5. 面向对象的三大基本特征，五大基本原则

**三大特性是：封装、继承、多态** 

**封装**就是把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。封装是面向对象的特征之一，是对象和类概念的主要特性。简单的说，一个类就是一个封装了数据以及操作这些数据的代码的逻辑实体。在一个对象内部，某些代码或某些数据可以是私有的，不能被外界访问。通过这种方式，对象对内部数据提供了不同级别的保护，以防止程序中无关的部分意外的改变或错误的使用了对象的私有部分。

**继承**是指可以让某个类型的对象获得另一个类型的对象的属性的方法。它支持按级分类的概念。继承是指这样一种能力：它可以使用现有类的所有功能，并在无需重新编写原来的类的情况下对这些功能进行扩展。通过继承创建的新类称为“子类”或“派生类”，被继承的类称为“基类”、“父类”或“超类”。继承的过程，就是从一般到特殊的过程。要实现继承，可以通过“继承”（Inheritance）和“组合”（Composition）来实现。继承概念的实现方式有二类：实现继承与接口继承。实现继承是指直接使用基类的属性和方法而无需额外编码的能力；接口继承是指仅使用属性和方法的名称、但是子类必须提供实现的能力；

**多态**就是指一个类实例的相同方法在不同情形有不同表现形式。多态机制使具有不同内部结构的对象可以共享相同的外部接口。这意味着，虽然针对不同对象的具体操作不同，但通过一个公共的类，它们（那些操作）可以通过相同的方式予以调用。

 

**五大基本原则** 

Ø **单一职责原则**SRP(Single Responsibility Principle)：是指一个类的功能要单一，不能包罗万象。如同一个人一样，分配的工作不能太多，否则一天到晚虽然忙忙碌碌的，但效率却高不起来。

Ø **开放封闭原则**OCP(Open－Close Principle) ：一个模块在扩展性方面应该是开放的而在更改性方面应该是封闭的。比如：一个网络模块，原来只服务端功能，而现在要加入客户端功能，那么应当在不用修改服务端功能代码的前提下，就能够增加客户端功能的实现代码，这要求在设计之初，就应当将服务端和客户端分开，公共部分抽象出来。

Ø **里氏替换原则**(the Liskov Substitution Principle LSP) ：子类应当可以替换父类并出现在父类能够出现的任何地方。比如：公司搞年度晚会，所有员工可以参加抽奖，那么不管是老员工还是新员工，也不管是总部员工还是外派员工，都应当可以参加抽奖，否则这公司就不和谐了。

Ø **依赖反转原则**(the Dependency Inversion Principle DIP) ：具体依赖抽象，上层依赖下层。假设B是较A低的模块，但B需要使用到A的功能，这个时候，B不应当直接使用A中的具体类： 而应当由B定义一抽象接口，并由A来实现这个抽象接口，B只使用这个抽象接口：这样就达到了依赖倒置的目的，B也解除了对A的依赖，反过来是A依赖于B定义的抽象接口。通过上层模块难以避免依赖下层模块，假如B也直接依赖A的实现，那么就可能造成循环依赖。一个常见的问题就是编译A模块时需要直接包含到B模块的cpp文件，而编译B时同样要直接包含到A的cpp文件。

Ø **接口分离原则**(the Interface Segregation Principle ISP) ：模块间要通过抽象接口隔离开，而不是通过具体的类强耦合起来

## 6. C++继承的内存布局 

## 7. C++多态的实现机制 

## 8. new/delete和malloc/free的区别

## 9. 

# 其它

## 1. XML的解析方式，以及优缺点。

## 2. 什么是ajax，Ajax如何解决跨域问题



# 知识的综合能力

## 1. 请介绍一下一个http请求的全过程，描述的越全面越好

# 工具使用

**！1**、知道git/svn**是干什么的吗？用过吗**

**！2**、知道maven/gradle**是干什么的吗？用过吗**

**！3**、平常使用什么IDE**，为什么**

**！4**、平常使用什么浏览器，为什么**

**！5**、平常开发机器是什么操作系统的**

**！6**、会在Linux**上开发吗。Linux**常用命令会吗**

# 项目相关

## 1. 请简单介绍一下你的这个项目

## 2. 你在这个项目中充当什么角色

## 3. 这个项目的技术选型有做过么。

## 4. 选择某项技术做过哪些调研和对比

## 5. 这个项目中遇到的最大的问题是什么？你是如何解决的。

## 6. 项目中是否考虑过性能、安全性等问题

# 技术热情

**！1**、当前Java**的最新版本**

**！2**、Java8**的lambda**表达式**

**% 3**、Java8**的stream API**

**% 4**、Java9**的模块化**

**% 5**、Java10**的局部变量类型推断**

**% 6**、Spring Boot2.0**

**% 7**、HTTP/2**

**% 8**、会翻墙么，知道翻墙的原理吗**

**！9**、你最近在读什么书**

# 表达能力

**！1**、能不能简单做一个自我介绍。**

**！2**、能不能描述一下杭州给你的印象。用三句话概括一下。**

# 思考方式

**！1**、如何估算杭州有多少软件工程师**

**！2**、你最近读过的印象最深的文章是什么**

**！3**、这篇文章中有几个观点，你最赞成哪一个，最不赞成哪一个**

# 其他

**！1**、你对加班怎么看**

**！2**、你还有什么问题要问我（面试官）的么**

# 推荐阅读

程序员面试笔试宝典 

程序员面试金典

Java编程思想 

Effective Java 

深入理解Java虚拟机 

大话数据结构 

剑指Offer

高性能MySQL

Java并发编程实战

Redis设计与实现

！Hollis技术博客（http://www.hollischuang.com）及个人公众号（Hollis）

 

 






# 面向对象专题

## 1. 什么是面向对象，什么是面向过程。面向对象的三大基本特征和五大基本原则是什么？

继承、封装、多态

单一职责、开放封闭、里氏替换、依赖倒转、接口分离

## 2. Java和C+ +同为面向对象语言，Java和C++主要区别有哪些？双方各有哪些优缺点？

## 3. 什么是平台无关性，Java是如何做到平台无关的？ 什么是值传递，什么是引用传递。为什么说Java中只有值传递。

平台无关(跨平台): 一种语言在计算机上的运行不受平台的约束，一次编译到处运行。

Java经过编译之后生成的.class 的字节码文件，运行平台上只要有JVM就能运行，不需要进行再次编译

## 4. 什么是编译，什么是反编译。Java的编译和反编译方法。

## 5. 什么是Java的语法糖，列举你个知道的语法糖。如何解语法糖？ 

语法糖（Syntactic sugar），也译为糖衣语法，是由英国计算机科学家彼得·兰丁发明的一个术语，指计算机语言中添加的某种语法，这种语法对语言的功能并没有影响，但是更方便程序员使用。语法糖让程序更加简洁，有更高的可读性。

常见语法糖：i++ ; switch中使用String ；泛型 ；自动装箱和拆箱；内部类

## 6. Java 8中的lambda表达式是不是语法糖，具体如何实现的。

Lambda表达式是Java SE 8中一个重要的新特性。lambda表达式允许你通过表达式来代替功能接口。 lambda表达式就和方法一样,它提供了一个正常的参数列表和一个使用这些参数的主体(body,可以是一个表达式或一个代码块)。 Lambda表达式还增强了集合库。Java SE 8添加了2个对集合数据进行批量操作的包: java.util.function 包以及 java.util.stream 包。 流(stream)就如同迭代器(iterator),但附加了许多额外的功能。总的来说,lambda表达式和 stream 是自Java语言添加泛型(Generics)和注解(annotation)以来最大的变化。 

## 7. 什么是多态，多态有什么好处，多态的必要条件是什么、Java中多态的实现方式。

## 8. 什么是方法重写，什么是方法重载，成员变量可以被重写吗？ 

## 9. 接口和抽象类的区别，如何选择？ 

## 10. Java能不能多继承，可不可以多实现？ 

## 11. 什么是构造函数，什么是默认构造函数？

## 12. 构造方法能不能被重载，构造方法能不能被重写？ 

## 13. 对于成员变量和方法的作用域，public、protected、private以及不写之间的区别。

## 14. 接口能否继承接口？抽象类能否实现接口？抽象类能否继承具体类？

1、接口是可以被接口继承的。即通过关键字extends声明一个接口是另一个接口的子接口。由于接口中的方法和常量都是public，子接口将继承父接口中的全部方法和常量。

2、抽象类可以实现接口，当一个类声明实现一个接口而没有实现接口中所有的方法，那么这个必须是抽象类，即abstract类。

3、抽象类是可以继承实体类。

# 基本数据类型与String专题

## 1. String类能不能被继承，为什么？这种设计有什么好处？

Ø 只有当字符串是不可变的，字符串池才有可能实现。字符串池的实现可以在运行时节约很多heap空间，因为不同的字符串变量都指向池中的同一个字符串。

Ø 如果字符串是可变的，那么会引起很严重的安全问题。譬如，数据库的用户名、密码都是以字符串的形式传入来获得数据库的连接。

Ø 因为字符串是不可变的，所以是多线程安全的，同一个字符串实例可以被多个线程共享。这样便不用因为线程安全问题而使用同步。

Ø 类加载器要用到字符串，不可变性提供了安全性，以便正确的类被加载。 

Ø 因为字符串是不可变的，所以在它创建的时候hashcode就被缓存了，不需要重新计算，HashMap中的键往往都使用字符串。

## 2. 什么是Static Nested Class、什么是InnerClass，二者有什么不同？  

## 3. Java中有几种基本数据类型，如何分类的？String是基本数据类型吗？

String不是基本数据类型，基本数据类型八种：byte、char、short、int、long、float、double、boolean

## 4. 整型的几种中，各个类型的取值范围是多少，如何计算的？超出范围会发生什么？什么是浮点型。什么是单精度和双精度。为什么代码中不要用浮点数表示金额。

## 5. Java中的char是否可以存储中文字符？

可以，char存储的是unicode编码，存储了常见的中文字符

## 6. int和Integer, boolean和Boolean等，之间有什么区别。

## 7. 什么是自动拆箱、什么是自动装箱。

## 8. 在接口定义的时候，要定义一个字段表示是否成功，你会选以下哪种方式？为什么？ 

## 9. String s = new String("abc")；定义了几个对象。

1.如果常量池中有字符串abc，那么只会在内存中创建一个对象；

2.如果常量池中没有字符串abc，那么在常量池中创建一个内容为abc的对象，但是遇到了new关键字，则还是会在内存（不是常量池）中创建一个对象，然后将对象返回给引用s，特别注意s不是一个对象。

## 10. 字面量

## 11. 如何比较两个字符串？

compareTo()

## 12. String有没有长度限制，为什么？如果有，超过限制会发生什么？String的“+”是如何实现的？ 

String内部使用一个char[]数组来存放字符串的内容，数组下标是整型（也可以参考String的构造方法String(char value[], int offset, int count) ，可以知道字符数量是用整型表示），整型（Java规定32位）表示范围是2G，也就是说，Java数组最大的长度是2G，即字符串不能超过2G个字符。

## 13. String、StringBuilder和StingBuffer之间的区别与联系。

## 14. substring()方法到底做了什么？不同版本的JDK中是否有区别？为什么？ 

## 15. 如何理解String的intern方法，不同版本JDK有何不同？为什么？ 

## 16. 什么是Java中整型的缓存机制？ 

## 17. 在Java的代码中以及数据库存储中，如何对金额进行表示和计算。

# 集合类专题

## 1. Java中的集合类有哪些？如何分类的？ 

## 2. Collection和Collections有什么区别？ 

## 3. Java中Set与List 有什么不同？

## 4. Set是如何保证元素不重复的？ 

## 5. 既然说了Set中的元素是不重复且无顺序的，那TreeSet中的元素是按照key的大小排序的又如何解释？ 

## 6. Java中的List有几种实现，各有什么不同？

## 7. 知道什么是synchronizedList吗？他和Vector有何区别？ 

## 8. 通过Array.asList获得的List有何特点，使用时应该注意什么？ 

## 9. Java中的Collection如何迭代？

## 10. Enumeration和Iterator接口的区别。

## 11. Iterator和Listiterator之间有什么区别？

## 12. 什么是fail-fast,什么是fail-safe,有什么区别吗？

## 13. 如何在遍历的同时删除ArrayList中的元素。

## 14. 如何对一组对象进行排序？ 

## 15. Comparable和Comparator接口有何区别？

## 16. Java中的集合使用泛型有哪些好处？ 

## 17. 当一个集合被作为参数传递给一个函数时，如何才可以确保函数不能修改它？ 

## 18. 如何通过给定集合得到一个synchronized的集合？ 

## 19. Java中的Map主要有哪几种？之间有什么区别。

## 20. Java中遍历Map的几种方式。

## 21. HashMap和HashTable有何不同？

## 22. HashMap和ConcrrentHashMap的区别？。

## 23. 同样是线程安全的Map、HashTable和ConcurrentHashMap之间有什么区别？ 






# Java基础

## 1. hashcode相等两个类一定相等吗 ？ equals呢？相反呢？

hashcode相等两个类不一定相等；equals为true两个类也不一定完全相等，其中hashcode和equals都是可以自己重写的。对象相等则hashCode一定相等；hashCode相等对象未必相等。如果两个类相等，那么其hashcode相等，equals返回为true。

## 2. 介绍一下集合框架？

## 3. HashMap、HasTable 底层实现什么区别？HashTable和Concurrenthashtable呢？

## 4. HashMap和TreeMap什么区别？低层数据结构是什么？

## 5. 线程池用过吗？都有什么参数？底层如何实现的？

核心线程数量，阻塞队列，最大容量，keeplivetime，时间单位，命名线程工厂，队满异常处理

## 6. sychnized和Lock什么区别？

## 7. sychnized什么情况情况是对象锁？什么时候是全局锁？为什么？

## 8. ThreadLocal是什么？底层如何实现？写一个例子呗？

## 9. volitile的工作原理？

## 10. cas知道吗？如何实现的？

## 11. 请用至少四种写法写一个单例模式呗？？

# 分布式缓存

## 1. redis和memcheched什么区别？为什么单线程的redis比多线程的memched效率要高？

## 2. redis有什么数据类型？都在哪些场景下使用？

## 3. reids的主从复制是怎么实现的？ redis的集群模式是如何实现的呢？ redis的key是如何寻址的？

## 4. 使用redis如何设计分布式锁使用zk可以吗 ？如何实现这两种哪个效率更高？

## 5. 知道 redis的持久化吗？都有什么缺点优点？具体底层实现呢？

## 6. redis过期策略都有哪些？LRU？写一下java版本的代码吧？

# 分布式服务框架

## 1. 说一下dubbo的实现过程？注册中心挂了可以继续通信吗？

## 2. zk原理知道吗？zk都可以干什么？Paxos算法知道吗？说下原理和实现？

## 3. dubbo支持哪些序列化协议？hessian？说一下hess ian的数据结构 ？PB知道吗？为啥PB效率是最高的？

## 4. 知道netty吗？ netty可以干嘛？NIO, BIO,AIO 都是什么？有什么区别？

## 5. dubbo复制均衡策略和高可用策略都有哪些？动态代理策略呢？

## 6. 为什么要进行系统拆分？拆分不用dubbo可以吗？ dubbo和thrift什么区别？ 

# 分布式消息队列

## 1. 为什么使用消息队列？消息队列有什么优点和缺点？

## 2. 如何保证消息队列的高可用？如何保证消息不被重复消费？

## 3. kafka , activemq, rabbitmq, rocketmq都有什么优点,缺点？？

## 4. 如果让你写一个消息队列，该如何进行架构设计？说一下你的思路

# 分布式搜索引擎

## 1. es的工作过程实现是如何的？如何实现分布式的

## 2. es在数据量很大的情况下(数十亿级别)如何提高查询效率？

## 3. es的查询是一个怎么的工作过程？底层的Lucence介绍下呗？倒排索引知道吗 ？es和mongdb什么区别都在什么场景下使用？

# 高并发高可用架构设计

## 1. 如何设计一个高并发高可用系统？

## 2. 如何限流？工程中怎么做的，说一下具体实现 ？

## 3. 缓存如何使用的？缓存使用不当会造成什么后果？

## 4. 如何熔断？熔断框架都有哪些？具体实现原理知道吗？

## 5. 如何降级？如何进行系统拆分,如何数据库拆分？

# 通信协议

## 1. 说一 下TCP/IP四层？

## 2. http的工作流程？http1.0 http1.1 http2.0具体哪些区别？

## 3. TCP三次握手四层分手的工作流程？画一下流程图？为什么不是四次五次或者二次？

## 4. 画一下https的工作流程？具体如何实现？如何防止被抓包？

# 算法

## 1. 比较简单,我一个文件 ,有45亿个阿拉伯数字,如何进行去重？如何找出最大的那个数？数据结构

## 2. 二叉树和红黑树等.

# ZooKeeper

## 1. ZooKeeper是什么？

ZooKeeper是一个**分布式**的，开放源码的分布式**应用程序协调服务**，是Google的Chubby一个开源的实现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。客户端的读请求可以被集群中的任意一台机器处理，如果读请求在节点上注册了监听器，这个监听器也是由所连接的zookeeper机器来处理。对于写请求，这些请求会同时发给其他zookeeper机器并且达成一致后，请求才会返回成功。因此，随着zookeeper的集群机器增多，读请求的吞吐会提高但是写请求的吞吐会下降。有序性是zookeeper中非常重要的一个特性，所有的更新都是全局有序的，每个更新都有一个唯一的时间戳，这个时间戳称为zxid（Zookeeper Transaction Id）。而读请求只会相对于更新有序，也就是读请求的返回结果中会带有这个zookeeper最新的zxid。

## 2. ZooKeeper提供了什么？

Ø 文件系统

Ø 通知机制

## 3. Zookeeper文件系统

Zookeeper提供一个多层级的节点命名空间（节点称为znode）。与文件系统不同的是，这些节点都可以设置关联的数据，而文件系统中只有文件节点可以存放数据而目录节点不行。Zookeeper为了保证高吞吐和低延迟，在内存中维护了这个树状的目录结构，这种特性使得Zookeeper不能用于存放大量的数据，每个节点的存放数据上限为1M。

## 4. 四种类型的znode

1、PERSISTENT-持久化目录节点 

客户端与zookeeper断开连接后，该节点依旧存在 

2、PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点

客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号 

3、EPHEMERAL-临时目录节点

客户端与zookeeper断开连接后，该节点被删除 

4、EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点

客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号

  

## 5. Zookeeper通知机制

client端会对某个znode建立一个watcher事件，当该znode发生变化时，这些client会收到zk的通知，然后client可以根据znode变化来做出业务上的改变等。

## 6. Zookeeper做了什么？

1) 数据发布/订阅

2) 负载均衡

3) 命名服务

4) 分布式协调/通知

5) 集群管理

6) Master选举

7) 分布式锁

8) 分布式队列

## 7. zk的命名服务（文件系统）

命名服务是指通过指定的名字来获取资源或者服务的地址，利用zk创建一个全局的路径，即是唯一的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等。

## 8. zk的配置管理（文件系统、通知机制）

程序分布式的部署在不同的机器上，将程序的配置信息放在zk的znode下，当有配置发生改变时，也就是znode发生变化时，可以通过改变zk中某个目录节点的内容，利用watcher通知给各个客户端，从而更改配置。

## 9. Zookeeper集群管理（文件系统、通知机制）

所谓集群管理无在乎两点：是否有**机器退出和加入**、**选举**master**。 

对于第一点，所有机器约定在父目录下创建**临时目录节点**，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它上船了。

新机器加入也是类似，所有机器收到通知：新兄弟目录加入，highcount又有了。对于第二点，我们稍微改变一下，所有机器创建**临时顺序编号目录节点**，每次选取编号最小的机器作为master就好。

## 10. Zookeeper分布式锁（文件系统、通知机制）

有了zookeeper的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是**保持独占**，另一个是**控制时序**。 

对于第一类，我们将zookeeper上的一个znode看作是一把锁，通过createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的distribute_lock 节点就释放出锁。 

对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除，依次方便。

## 11. 获取分布式锁的流程

  

在获取分布式锁的时候在locker节点下创建临时顺序节点，释放锁的时候删除该临时节点。客户端调用createNode方法在locker下创建临时顺序节点，然后调用getChildren(“locker”)来获取locker下面的所有子节点，注意此时不用设置任何Watcher。客户端获取到所有的子节点path之后，如果发现自己创建的节点在所有创建的子节点序号最小，那么就认为该客户端获取到了锁。如果发现自己创建的节点并非locker所有子节点中最小的，说明自己还没有获取到锁，此时客户端需要找到比自己小的那个节点，然后对其调用exist()方法，同时对其注册事件监听器。之后，让这个被关注的节点删除，则客户端的Watcher会收到相应通知，此时再次判断自己创建的节点是否是locker子节点中序号最小的，如果是则获取到了锁，如果不是则重复以上步骤继续获取到比自己小的一个节点并注册监听。当前这个过程中还需要许多的逻辑判断。

  

代码的实现主要是基于互斥锁，获取分布式锁的重点逻辑在于BaseDistributedLock，实现了基于Zookeeper实现分布式锁的细节。

## 12. Zookeeper队列管理（文件系统、通知机制）

两种类型的队列：

1、**同步队列**，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。 

2、队列按照**FIFO**方式进行入队和出队操作。 

第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。 

第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。在特定的目录下创建PERSISTENT_SEQUENTIAL节点，创建成功时Watcher通知等待的队列，队列删除序列号最小的节点用以消费。此场景下Zookeeper的znode用于消息存储，znode存储的数据就是消息队列中的消息内容，SEQUENTIAL序列号就是消息的编号，按序取出即可。由于创建的节点是持久化的，所以不必担心队列消息的丢失问题。

 

## 13. Zookeeper数据复制

Zookeeper作为一个集群提供一致的数据服务，所以它要在所有机器间做数据复制。数据复制的好处： 

1、容错：一个节点出错，不致于让整个系统停止工作，别的节点可以接管它的工作； 

2、提高系统的扩展能力 ：把负载分布到多个节点上，或者增加节点来提高系统的负载能力； 

3、提高性能：让客户端本地访问就近的节点，提高用户访问速度。

从客户端读写访问的透明度来看，数据复制集群系统分下面两种： 

1、写主(WriteMaster) ：对数据的修改提交给指定的节点。读无此限制，可以读取任何一个节点。这种情况下客户端需要对读与写进行区别，俗称读写分离； 

2、写任意(Write Any)：对数据的修改可提交给任意的节点，跟读一样。这种情况下，客户端对集群节点的角色与变化透明。

对zookeeper来说，它采用的方式是写任意。通过增加机器，它的读吞吐能力和响应能力扩展性非常好，而写，随着机器的增多吞吐能力肯定下降（这也是它建立observer的原因），而响应能力则取决于具体实现方式，是延迟复制保持最终一致性，还是立即复制快速响应。

## 14. Zookeeper工作原理

Zookeeper 的核心是**原子广播**，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分别是**恢复模式**（选主）和**广播模式**（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。

## 15. zookeeper是如何保证事务的顺序一致性的？

zookeeper采用了递增的事务Id来标识，所有的proposal（提议）都在被提出的时候加上了zxid，zxid实际上是一个64位的数字，高32位是epoch（时期; 纪元; 世; 新时代）用来标识leader是否发生改变，如果有新的leader产生出来，epoch会自增，低32位用来递增计数。当新产生proposal的时候，会依据数据库的两阶段过程，首先会向其他的server发出事务执行请求，如果超过半数的机器都能执行并且能够成功，那么就会开始执行。

## 16. Zookeeper 下 Server工作状态

每个Server在工作过程中有三种状态： 

LOOKING：当前Server不知道leader是谁，正在搜寻

LEADING：当前Server即为选举出来的leader

FOLLOWING：leader已经选举出来，当前Server与之同步

## 17. zookeeper是如何选取主leader的？

当leader崩溃或者leader失去大多数的follower，这时zk进入恢复模式，恢复模式需要重新选举出一个新的leader，让所有的Server都恢复到一个正确的状态。Zk的选举算法有两种：一种是基于basic paxos实现的，另外一种是基于fast paxos算法实现的。系统默认的选举算法为fast paxos。

**1**、Zookeeper**选主流程(basic paxos)**

（1）选举线程由当前Server发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的Server； 

（2）选举线程首先向所有Server发起一次询问(包括自己)； 

（3）选举线程收到回复后，验证是否是自己发起的询问(验证zxid是否一致)，然后获取对方的id(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息(id,zxid)，并将这些信息存储到当次选举的投票记录表中； 

（4）收到所有Server回复以后，就计算出zxid最大的那个Server，并将这个Server相关信息设置成下一次要投票的Server； 

（5）线程将当前zxid最大的Server设置为当前Server要推荐的Leader，如果此时获胜的Server获得n/2 + 1的Server票数，设置当前推荐的leader为获胜的Server，将根据获胜的Server相关信息设置自己的状态，否则，继续这个过程，直到leader被选举出来。 通过流程分析我们可以得出：要使Leader获得多数Server的支持，则Server总数必须是奇数2n+1，且存活的Server的数目不得少于n+1. 每个Server启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的server还会从磁盘快照中恢复数据和会话信息，zk会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。

  

**2**、Zookeeper**选主流程(fast paxos)**

fast paxos流程是在选举过程中，某Server首先向所有Server提议自己要成为leader，当其它Server收到提议以后，解决epoch和 zxid的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息，重复这个流程，最后一定能选举出Leader。

  

## 18. Zookeeper同步流程

选完Leader以后，zk就进入状态同步过程。 

1、Leader等待server连接； 

2、Follower连接leader，将最大的zxid发送给leader； 

3、Leader根据follower的zxid确定同步点； 

4、完成同步后通知follower 已经成为uptodate状态； 

5、Follower收到uptodate消息后，又可以重新接受client的请求进行服务了。

  

## 19. 分布式通知和协调

对于系统调度来说：操作人员发送通知实际是通过控制台改变某个节点的状态，然后zk将这些变化发送给注册了这个节点的watcher的所有客户端。

对于执行情况汇报：每个工作进程都在某个目录下创建一个临时节点。并携带工作的进度数据，这样汇总的进程可以监控目录子节点的变化获得工作进度的实时的全局情况。

## 20. 机器中为什么会有leader？

在分布式环境中，有些业务逻辑只需要集群中的某一台机器进行执行，其他的机器可以共享这个结果，这样可以大大减少重复计算，提高性能，于是就需要进行leader选举。

## 21. zk节点宕机如何处理？

Zookeeper本身也是集群，推荐配置不少于3个服务器。Zookeeper自身也要保证当一个节点宕机时，其他节点会继续提供服务。

如果是一个Follower宕机，还有2台服务器提供访问，因为Zookeeper上的数据是有多个副本的，数据并不会丢失；

如果是一个Leader宕机，Zookeeper会选举出新的Leader。

ZK集群的机制是只要超过半数的节点正常，集群就能正常提供服务。只有在ZK节点挂得太多，只剩一半或不到一半节点能工作，集群才失效。

所以

3个节点的cluster可以挂掉1个节点(leader可以得到2票>1.5)

2个节点的cluster就不能挂掉任何1个节点了(leader可以得到1票<=1)

## 22. zookeeper负载均衡和nginx负载均衡区别

zk的负载均衡是可以调控，nginx只是能调权重，其他需要可控的都需要自己写插件；但是nginx的吞吐量比zk大很多，应该说按业务选择用哪种方式。

## 23. zookeeper watch机制

Watch机制官方声明：一个Watch事件是一个一次性的触发器，当被设置了Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了Watch的客户端，以便通知它们。

Zookeeper机制的特点：

1、一次性触发数据发生改变时，一个watcher event会被发送到client，但是client只会收到一次这样的信息。

2、watcher event异步发送watcher的通知事件从server发送到client是异步的，这就存在一个问题，不同的客户端和服务器之间通过socket进行通信，由于网络延迟或其他因素导致客户端在不通的时刻监听到事件，由于Zookeeper本身提供了ordering guarantee，即客户端监听事件后，才会感知它所监视znode发生了变化。所以我们使用Zookeeper不能期望能够监控到节点每次的变化。Zookeeper只能保证最终的一致性，而无法保证强一致性。

3、数据监视Zookeeper有数据监视和子数据监视getdata() and exists()设置数据监视，getchildren()设置了子节点监视。

4、注册watcher getData、exists、getChildren

5、触发watcher create、delete、setData

6、setData()会触发znode上设置的data watch（如果set成功的话）。一个成功的create() 操作会触发被创建的znode上的数据watch，以及其父节点上的child watch。而一个成功的delete()操作将会同时触发一个znode的data watch和child watch（因为这样就没有子节点了），同时也会触发其父节点的child watch。

7、当一个客户端连接到一个新的服务器上时，watch将会被以任意会话事件触发。当与一个服务器失去连接的时候，是无法接收到watch的。而当client重新连接时，如果需要的话，所有先前注册过的watch，都会被重新注册。通常这是完全透明的。只有在一个特殊情况下，watch可能会丢失：对于一个未创建的znode的exist watch，如果在客户端断开连接期间被创建了，并且随后在客户端连接上之前又删除了，这种情况下，这个watch事件可能会被丢失。

8、Watch是轻量级的，其实就是本地JVM的Callback，服务器端只是存了是否有设置了Watcher的布尔类型

## 24. Zookeeper对节点的watch监听通知是永久的吗？

不是。官方声明：一个Watch事件是一个一次性的触发器，当被设置了Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了Watch的客户端，以便通知它们。

为什么不是永久的，举个例子，如果服务端变动频繁，而监听的客户端很多情况下，每次变动都要通知到所有的客户端，这太消耗性能了。

一般是客户端执行getData(“/节点A”,true)，如果节点A发生了变更或删除，客户端会得到它的watch事件，但是在之后节点A又发生了变更，而客户端又没有设置watch事件，就不再给客户端发送。

在实际应用中，很多情况下，我们的客户端不需要知道服务端的每一次变动，我只要最新的数据即可。

## 25. ZK为什么不提供一个永久性的Watcher注册机制

不支持用持久Watcher的原因很简单，ZK无法保证性能。使用watch需要注意的几点：

a) Watches通知是一次性的，必须重复注册。

b) 发生CONNECTIONLOSS之后，只要在session_timeout之内再次连接上（即不发生SESSIONEXPIRED），那么这个连接注册的watches依然在。

c) 节点数据的版本变化会触发NodeDataChanged，注意，这里特意说明了是版本变化。存在这样的情况，只要成功执行了setData()方法，无论内容是否和之前一致，都会触发NodeDataChanged。

d) 对某个节点注册了watch，但是节点被删除了，那么注册在这个节点上的watches都会被移除。

e) 同一个zk客户端对某一个节点注册相同的watch，只会收到一次通知。

f) Watcher对象只会保存在客户端，不会传递到服务端。

## 26. ZooKeeper集群中服务器之间是怎样通信的？

Leader服务器会和每一个Follower/Observer服务器都建立TCP连接，同时为每个F/O都创建一个叫做LearnerHandler的实体。LearnerHandler主要负责Leader和F/O之间的网络通讯，包括数据同步，请求转发和Proposal提议的投票等。Leader服务器保存了所有F/O的LearnerHandler。

## 27. zookeeper是否会自动进行日志清理？如何进行日志清理？

zk自己不会进行日志清理，需要运维人员进行日志清理

# hadoop相关试题

## 1. MapReduce的输入格式与流程

  

文件从上传到HDFS到输入到map函数中，大致可以分为4步。

文件上传到hdfs中，被划分为若干份block，输入时，将所有block读取，划分为若干个split，每个split对应与一个map task，然后每个split划分为多个record。

https://blog.csdn.net/scgaliguodong123_/article/details/46443739

## 2. MapTask并行机度是由什么决定的？ 

由切片数量决定的。

## 3. MR是干什么的？ 

MR将用户编写的业务逻辑代码和自带的默认组件结合起来组成一个完整的分布式应用程序放到hadoop集群上运行。

## 4. MR的实例进程： 

driver(mr的job提交客户端) 

MRAppMaster 

MapTask 

ReduceTask

## 5. combiner和partition的作用： 

combiner的意义就是对每一个maptask的输出进行局部汇总，以减小网络传输量。

partition的默认实现是hashpartition，是map端将数据按照reduce个数取余，进行分区，不同的reduce来copy自己的数据。 

partition的作用是将数据分到不同的reduce进行计算，加快计算效果。

## 6. 什么是shuffle 

map阶段处理的数据如何传递给reduce阶段，是mapreduce框架中最关键的一个流程，这个流程就叫shuffle； 

shuffle: 洗牌、发牌——（核心机制：数据分区，排序，缓存）； 

具体来说：就是将maptask输出的处理结果数据，分发给reducetask，并在分发的过程中，对数据按key进行了分区和排序；

## 7. MR原理(详细解释参照：MR运行原理剖析)： 

InputFormat来读取数据，按行读取，返回KV值传到map方法中， 

context.write方法将处理后数据输出到outputCollector中， 

当outputCollector中的数据累计到一定数量后再将数据传到内存的环形缓冲区做处理， 

当环形缓冲区中的数据累积到一定数量后再将数据通过Splier多次溢出到本地磁盘的多个文件中，期间会对各个溢出的数据进行分区、排序 

然后对多个文件进行merge（归并排序）形成一个输出结果大文件 

ruduceTask根据自己的分区号去各个mapTask机器上取输出结果文件 

将得到的各个结果文件进行merge，然后进入reduce阶段， 

context.write将最终结果输出到outPutformat上，进而输出到本地文件中。

## 8. 举一个简单的例子说明mapreduce是怎么来运行的 ? 

wd例子。详细解释参考：Wd详解

## 9. 什么是yarn？ 

Yarn是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台，而mapreduce等运算程序则相当于运行于操作系统之上的应用程序。

## 10. namenode的safemode是怎么回事？如何才能退出safemode？ 

namenode在刚启动的时候元数据只有文件块信息，没有文件所在datanode的信息，需要datanode自己向namenode汇报。如果namenode发现datanode汇报的文件块信息没有达到namenode内存中所有文件块的总阈值的一个百分比，namenode就会处于safemode。 

只有达到这个阈值，namenode才会推出safemode。也可手动强制退出。

## 11. secondarynamenode的主要职责是什么？简述其工作机制 

sn的主要职责是执行checkpoint操作 

每隔一段时间，会由secondary namenode将namenode上积累的所有edits和一个最新的fsimage下载到本地，并加载到内存进行merge（这个过程称为checkpoint）

## 12. 如果namenode宕机，datanode节点是否也会跟着挂掉？ 

否

## 13. 一个datanode 宕机,怎么一个流程恢复？ 

Datanode宕机了后，如果是短暂的宕机，可以实现写好脚本监控，将它启动起来。如果是长时间宕机了，那么datanode上的数据应该已经被备份到其他机器了， 那这台datanode就是一台新的datanode了，删除他的所有数据文件和状态文件，重新启动

## 14. hadoop 的 namenode 宕机,怎么解决？ 

先分析宕机后的损失，宕机后直接导致client无法访问，内存中的元数据丢失，但是硬盘中的元数据应该还存在，如果只是节点挂了， 

重启即可，如果是机器挂了，重启机器后看节点是否能重启，不能重启就要找到原因修复了。 

但是最终的解决方案应该是在设计集群的初期就考虑到这个问题，做namenode的HA。

## 15. 简述hadoop安装

改IP，修改Host文件； 

装JDK配置环境变量； 

装Hadoop配置环境变量； 

修改hadoop的配置文件如core-site、marp-site、yarn-site、dfs-site等； 

namenode进行格式化； 

start-all；

## 16. 请列出hadoop正常工作时要启动那些进程，并写出各自的作用。 

namenode:管理集群并记录datanode的元数据，相应客户端的请求。 

seconder namenode：对namenode一定范围内的数据做一份快照性备份。 

datanode：存储数据。 

jobTracker：管理客户端提交的任务，并将任务分配给TaskTracker。 

TaskTracker：执行各个Task。

## 17. JobTracker和TaskTracker的功能 

JobTracker是一个master服务，软件启动之后JobTracker接收Job，负责调度Job的每一个子任务task运行于TaskTracker上， 

并监控它们，如果发现有失败的task就重新运行它。一般情况应该把JobTracker部署在单独的机器上。 

TaskTracker是运行在多个节点上的slaver服务。TaskTracker主动与JobTracker通信，接收作业，并负责直接执行每一个任务。

## 18. 用mapreduce怎么处理数据倾斜问题？ 

数据倾斜：map /reduce程序执行时，reduce节点大部分执行完毕，但是有一个或者几个reduce节点运行很慢，导致整个程序的处理时间很长， 

这是因为某一个key的条数比其他key多很多（有时是百倍或者千倍之多），这条key所在的reduce节点所处理的数据量比其他节点就大很多， 

从而导致某几个节点迟迟运行不完，此称之为数据倾斜。 

解决：自己实现partition类，用key和value相加取hash值。

## 19. Mapreduce 的 map 数量 和 reduce 数量 怎么确定 ,怎么配置？ 

map的数量有数据块决定，reduce数量随便配置。

## 20. hdfs的体系结构 

hdfs有namenode、secondraynamenode、datanode组成。 

namenode负责管理datanode和记录元数据 

secondraynamenode负责合并日志 

datanode负责存储数据

## 21. 说下对hadoop的一些理解,包括哪些组件 

详谈hadoop的应用，包括的组件分为三类，分别说明hdfs，yarn，mapreduce。

## 22. 一些传统的hadoop 问题,mapreduce 他就问shuffle 阶段,你怎么理解的 

Shuffle意义在于将不同map处理后的数据进行合理分配，让reduce处理，从而产生了排序、分区。

## 23. NameNode 负责管理 metadata，client 端每次读写请求，它都会从磁盘中读取或则会写入 metadata信息并反馈client 端。（错误） 

修改后分析： 

NameNode 不需要从磁盘读取 metadata，所有数据都在内存中，硬盘上的只是序列化的结果，只有每次 

namenode 启动的时候才会读取。

 

## 24. Hadoop1.0的局限

**HDFS**层面**

1) 资源隔离

（1）静态资源配置。采用了静态资源设置策略，即每个节点实现配置好可用的slot总数，这些slot数目一旦启动后无法再动态修改。

（2）资源无法共享。Hadoop 1.0将slot分为Map slot和Reduce slot两种，且不允许共享。对于一个作业，刚开始运行时，Map slot资源紧缺而Reduce slot空闲，当Map Task全部运行完成后，Reduce slot紧缺而Map slot空闲。很明显，这种区分slot类别的资源管理方案在一定程度上降低了slot的利用率。

（3）资源划分粒度过大。这种基于无类别slot的资源划分方法的划分粒度仍过于粗糙，往往会造成节点资源利 用率过高或者过低 ，比如，管理员事先规划好一个slot代表2GB内存和1个CPU，如果一个应用程序的任务只需要1GB内存，则会产生“资源碎片”，从而降低集群资源的 利用率，同样，如果一个应用程序的任务需要3GB内存，则会隐式地抢占其他任务的资源，从而产生资源抢占现象，可能导致集群利用率过高。

（4） 没引入有效的资源隔离机制。Hadoop 1.0仅采用了基于jvm的资源隔离机制，这种方式仍过于粗糙，很多资源，比如CPU，无法进行隔离，这会造成同一个节点上的任务之间干扰严重。

2) 元数据拓展性

HDFS的底层存储是可以水平扩展的（解释：底层存储指的是datanode，当集群存储空间不够时，可简单的添加机器已进行水平扩展），但 namespace不可以。当前的namespace只能存放在单个namenode上，而namenode在内存中存储了整个分布式文件系统中的元数据信息，这限制了集群中数据块，文件和目录的数目。

3) 访问效率

文件操作的性能制约于单个namenode的吞吐量，单个namenode当前仅支持约60K的task，而下一代Apache MapReduce将支持多余100K的并发任务，这隐含着要支持多个namenode。

4) 单点失效

单个namenode一旦失效，整个HDFS不可用

**MapReduce**层面**

1) 扩展性

集群最大节点数–4000

最大并发任务数–40000

2) 可用性

JobTracker负载较重

存在单点故障, 一旦故障，

  所有执行的任务的全部失败

3) 批处理模式,时效性低

仅仅使用MapReduce一种计算方式

4) 低效的资源管理

把资源强制划分为 map task slot 和 reduce task slot, 当系统中只有 map task 或者只有 reduce task 的时候，会造成资源的浪费。

 

**Hadoop 2.0**新特性**：

由HDFS、MapReduce和YARN三个分支构成

Ø HDFS：支持NN Federation、HA

Ø MapReduce：运行在YARN上的MR，编程模型不变

Ø YARN：资源管理系统

 

# Hive相关试题

## 1. 你的数据库是不是很大么,有没有分表,分区,你是怎么实现的 

hive内部表和外部表的区别 

内部表：加载数据到hive所在的hdfs目录，删除时，元数据和数据文件都删除 

外部表：不加载数据到hive所在的hdfs目录，删除时，只删除表结构。

## 2. 分桶的作用 

最大的作用是提高join的效率。

（1）获得更高的查询处理效率。

（2） 使取样（sampling）更高效。

## 3. Hive 你们用的是外部表还是内部表,有没有写过UDF。 

UDF： 

1、写对应的java代码自定义函数的逻辑 

2、将代码打成jar包上传到hive 

3、在hive创建临时函数与对应的class类相关联 

4、在hive中调用临时函数。

# Hbase相关试题

## 1. hbase的rowkey怎么创建好？列族怎么创建比较好？（重点） 

hbase存储时，数据按照Row key的字典序(byte order)排序存储。设计key时，要充分利用排序存储这个特性，将经常一起读取的行存储放到一起。(位置相关性) 

一个列族在数据底层是一个文件，所以将经常一起查询的列放到一个列族中，列族尽量少，减少文件的寻址时间。

## 2. Redis,传统数据库,hbase,hive 每个之间的区别？(问的非常细) 

redis：分布式缓存，强调缓存，内存中数据 

传统数据库：注重关系 

hbase：列式数据库，无法做关系数据库的主外键，用于存储海量数据，底层基于hdfs 

hive：数据仓库工具，底层是mapreduce。不是数据库，不能用来做用户的交互存储

## 3. HBase中各个模块的作用

**client:** Client包含访问hbase 的接口，client 维护着一些cache 来加快对hbase 的访问，比如region的位置信息

**ZooKeeper:**

1:保证任何时候，集群中只有一个running master 

2:存贮所有Region 的寻址入口

3:实时监控Region Server 的状态，将Region server 的上线和下线信息，实时通知给Master

4:存储Hbase的schema,包括有哪些table，每个table有哪些column family

**Master :**

1:可以启动多个Master，通过Zookeeper的Master Election机制保证总有一个Master运行

2:为Region server分配region

3:负责region server的负载均衡

4:发现失效的region server并重新分配其上的region

**Region Server:**

1:维护Master分配给它的region

2:处理对这些region 的IO 请求

3:负责切分在运行过程中变得过大的region

 

client 访问hbase 上数据的过程并不需要master 参与，寻址访问zookeeper 和region server，数据读写访问regioneserver。RegionServer主要负责响应用户I/O请求，向HDFS文件系统中读写数据，是HBase中最核心的模块。

## 4. hdfs 和 hbase 各自使用场景。 

整理总结： 

首先一点需要明白：Hbase 是基于 HDFS 来存储的。 

**HDFS****： 

1、一次性写入，多次读取。 

2、保证数据的一致性。 

3、主要是可以部署在许多廉价机器中，通过多副本提高可靠性，提供了容错和恢复机制。 

**Hbase****： 

1、瞬间写入量很大，数据库不好支撑或需要很高成本支撑的场景。 

2、数据需要长久保存，且量会持久增长到比较大的场景 

3、hbase不适用与有 join，多级索引，表关系复杂的数据模型 

4、大数据量 （100s TB 级数据） 且有快速随机访问的需求。 

如：淘宝的交易历史记录。数据量巨大无容置疑，面向普通用户的请求必然要即时响应。 

5、容量的优雅扩展 

大数据的驱使，动态扩展系统容量的必须的。例如：webPage DB。 

6、业务场景简单，不需要关系数据库中很多特性（例如交叉列、交叉表，事务，连接等等） 

7、优化方面：合理设计 rowkey。因为 hbase 的查

## 5. 说说 hbase 的 API 都有哪些 filter?

## 6. 说说你用过的 storm

## 7. 自己熟悉大数据的部分说一下?

## 8. hadoop 与 storm、spark 的比较?

## 9. 对一个字符串进行全排列?

## 10. 事务都有哪些特点?

## 11. hadoop 集群中的某个 block 不能 copy 数据到其他节点，怎么办?如果并发量大了，有多个 block不能 copy 数据，怎么办?

## 12. flum是如何导入数据到 kafka?具体

# Storm相关试题

## 1. 公司技术选型可能利用storm 进行实时计算,讲解一下storm 

描述下storm的设计模式，是基于work、excutor、task的方式运行代码，由spout、bolt组成等等。

## 2. 实时流式计算框架,几个人,多长时间,细节问题,包括讲flume ,kafka ,storm 

的各个的组件组成,你负责那一块,如果需要你搭建你可以完成么?（多次提到）

# Spark相关试题

## 1. 你觉得spark 可以完全替代hadoop 么? 

spark会替代mr,不会代替yarn和hdfs.

## 2. SDD、DAG、Stage怎么理解？

## 3. 宽依赖、窄依赖怎么理解？

## 4. Stage是基于什么原理分割task的？

## 5. 血统的概念

## 6. 任务的概念

## 7. 容错方法

## 8. 粗粒度和细粒度

## 9. Spark优越性

## 10. Spark为什么快

## 11. Transformation和action是什么？区别？举几个常用方法

## 12. SDD怎么理解

## 13. spark作业提交流程是怎么样的，client和 cluster 有什么区别，各有什么作用

## 14. spark on yarn 作业执行流程，yarn-client 和 yarn cluster 有什么区别

## 15. spark streamning 工作流程是怎么样的，和 storm 比有什么区别

## 16. spark sql 你使用过没有，在哪个项目里面使用的

## 17. spark 机器学习和 spark 图计算接触过没，，能举例说明你用它做过什么吗？

## 18. spark sdd 是怎么容错的，基本原理是什么？




# Java并发编程

## 1.  在java中守护线程和本地线程区别？

java中的线程分为两种**：守护线程（**Daemon**）**和**用户线程（**User**）**。

任何线程都可以设置为守护线程和用户线程，通过方法Thread.setDaemon(bool on)；true则把该线程设置为守护线程，反之则为用户线程。Thread.setDaemon()必须在Thread.start()之前调用，否则运行时会抛出异常。

两者的区别： 

唯一的区别是判断虚拟机(JVM)何时离开，Daemon是为其他线程提供服务，如果全部的User Thread已经撤离，Daemon 没有可服务的线程，JVM撤离。也可以理解为守护线程是JVM自动创建的线程（但不一定），用户线程是程序创建的线程；比如JVM的垃圾回收线程是一个守护线程，当所有线程已经撤离，不再产生垃圾，守护线程自然就没事可干了，当垃圾回收线程是Java虚拟机上仅剩的线程时，Java虚拟机会自动离开。

扩展：Thread Dump打印出来的线程信息，含有daemon字样的线程即为守护进程，可能会有：服务守护进程、编译守护进程、windows下的监听Ctrl+break的守护进程、Finalizer守护进程、引用处理守护进程、GC守护进程。

## 2.  线程与进程的区别？

进程是操作系统分配资源的最小单元，线程是操作系统调度的最小单元。

一个程序至少有一个进程,一个进程至少有一个线程。

## 3.  什么是多线程中的上下文切换？

多线程会共同使用一组计算机上的CPU，而线程数大于给程序分配的CPU数量时，为了让各个线程都有执行的机会，就需要轮转使用CPU。不同的线程切换使用CPU发生的切换数据等就是上下文切换。

## 4.  死锁与活锁的区别，死锁与饥饿的区别？

**死锁**：是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。 

产生死锁的必要条件： 

\1. 互斥条件：所谓互斥就是进程在某一时间内独占资源。 

\2. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 

\3. 不剥夺条件:进程已获得资源，在末使用完之前，不能强行剥夺。 

\4. 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

**活锁**：任务或者执行者没有被阻塞，由于**某些条件没有满足**，导致一直重复尝试，失败，尝试，失败。

活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，所谓的“活”， 而处于死锁的实体表现为等待；活锁有可能自行解开，死锁则不能。

**饥饿**：一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行的状态。 

Java中导致饥饿的原因： 

\- 高优先级线程吞噬所有的低优先级线程的CPU时间。 

\- 线程被永久堵塞在一个等待进入同步块的状态，因为其他线程总是能在它之前持续地对该同步块进行访问。 

\- 线程在等待一个本身也处于永久等待完成的对象(比如调用这个对象的wait方法)，因为其他线程总是被持续地获得唤醒。

## 5.  Java中用到的线程调度算法是什么？

采用**时间片轮转**的方式。可以设置线程的优先级，会映射到下层的系统上面的优先级上，如非特别需要，尽量不要用，防止线程饥饿。

## 6.  什么是线程组，为什么在Java中不推荐使用？

ThreadGroup类，可以把线程归属到某一个线程组中，线程组中可以有线程对象，也可以有线程组，组中还可以有线程，这样的组织结构有点类似于树的形式。

为什么不推荐使用？因为使用有很多的安全隐患吧，没有具体追究，如果需要使用，推荐使用线程池。

## 7.  为什么使用Executor框架？

1) 每次执行任务创建线程 new Thread()比较消耗性能，创建一个线程是比较耗时、耗资源的。

2) 调用new Thread()创建的线程缺乏管理，被称为野线程，而且可以无限制的创建，线程之间的相互竞争会导致过多占用系统资源而导致系统瘫痪，还有线程之间的频繁交替也会消耗很多系统资源。

3) 接使用new Thread()启动的线程不利于扩展，比如定时执行、定期执行、定时定期执行、线程中断等都不便实现。

## 8.  在Java中Executor和Executors的区别？

Executors工具类的不同方法按照我们的需求创建了不同的线程池，来满足业务的需求。

Executor接口对象能执行我们的线程任务。

ExecutorService接口继承了Executor接口并进行了扩展，提供了更多的方法我们能获得任务执行的状态并且可以获取任务的返回值。 

使用ThreadPoolExecutor 可以创建自定义线程池。 

Future 表示异步计算的结果，他提供了检查计算是否完成的方法，以等待计算的完成，并可以使用get()方法获取计算的结果。

## 9.  如何在Windows和Linux上查找哪个线程使用的CPU时间最长？

 

## 10. 什么是原子操作？在Java Concurrency API中有哪些原子类(atomic classes)？

原子操作（atomic operation）意为”不可被中断的一个或一系列操作” 。 

处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。 

在Java中可以通过锁和循环CAS的方式来实现原子操作。 CAS操作——Compare & Set，或是 Compare & Swap，现在几乎所有的CPU指令都支持CAS的原子操作。

原子操作是指一个不受其他操作影响的操作任务单元。原子操作是在多线程环境下避免数据不一致必须的手段。 

int++并不是一个原子操作，所以当一个线程读取它的值并加1时，另外一个线程有可能会读到之前的值，这就会引发错误。 

为了解决这个问题，必须保证增加操作是原子的，在JDK1.5之前我们可以使用同步技术来做到这一点。到JDK1.5，java.util.concurrent.atomic包提供了int和long类型的原子包装类，它们可以自动的保证对于他们的操作是原子的并且不需要使用同步。

java.util.concurrent这个包里面提供了一组原子类。其基本的特性就是在多线程环境下，当有多个线程同时执行这些类的实例包含的方法时，具有排他性，即当某个线程进入方法，执行其中的指令时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等到该方法执行完成，才由JVM从等待队列中选择一个另一个线程进入，这只是一种逻辑上的理解。

原子类：AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference 

原子数组：AtomicIntegerArray，AtomicLongArray，AtomicReferenceArray 

原子属性更新器：AtomicLongFieldUpdater，AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater 

解决ABA问题的原子类：AtomicMarkableReference（通过引入一个boolean来反映中间有没有变过），AtomicStampedReference（通过引入一个int来累加来反映中间有没有变过）

## 11. Java Concurrency API中的Lock接口(Lock interface)是什么？对比同步它有什么优势？

Lock接口比同步方法和同步块提供了更具扩展性的锁操作。 

他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。

它的优势有：

· 可以使锁更公平

· 可以使线程在等待锁的时候响应中断

· 可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间

· 可以在不同的范围，以不同的顺序获取和释放锁

整体上来说Lock是synchronized的扩展版，Lock提供了无条件的、可轮询的(tryLock方法)、定时的(tryLock带参方法)、可中断的(lockInterruptibly)、可多条件队列的(newCondition方法)锁操作。另外Lock的实现类基本都支持非公平锁(默认)和公平锁，synchronized只支持非公平锁，当然，在大部分情况下，非公平锁是高效的选择。

## 12. 什么是Executors框架？

Executor框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架。

无限制的创建线程会引起应用程序内存溢出。所以创建一个线程池是个更好的的解决方案，因为可以限制线程的数量并且可以回收再利用这些线程。利用Executors框架可以非常方便的创建一个线程池。

## 13. 什么是阻塞队列？阻塞队列的实现原理是什么？如何使用阻塞队列来实现生产者-消费者模型？

阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。

这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。

阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。

JDK7提供了7个阻塞队列。分别是： 

ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。 

LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。 

PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。 

DelayQueue：一个使用优先级队列实现的无界阻塞队列。 

SynchronousQueue：一个不存储元素的阻塞队列。 

LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。 

LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。

Java 5之前实现同步存取时，可以使用普通的一个集合，然后在使用线程的协作和线程同步可以实现生产者，消费者模式，主要的技术就是用好，wait ,notify,notifyAll,sychronized这些关键字。而在java 5之后，可以使用阻塞队列来实现，此方式大大简少了代码量，使得多线程编程更加容易，安全方面也有保障。 

BlockingQueue接口是Queue的子接口，它的主要用途并不是作为容器，而是作为线程同步的的工具，因此他具有一个很明显的特性，当生产者线程试图向BlockingQueue放入元素时，如果队列已满，则线程被阻塞，当消费者线程试图从中取出一个元素时，如果队列为空，则该线程会被阻塞，正是因为它所具有这个特性，所以在程序中多个线程交替向BlockingQueue中放入元素，取出元素，它可以很好的控制线程之间的通信。

阻塞队列使用最经典的场景就是socket客户端数据的读取和解析，读取数据的线程不断将数据放入队列，然后解析线程不断从队列取数据解析。

## 14. 什么是Callable和Future?

Callable接口类似于Runnable，从名字就可以看出来了，但是Runnable不会返回结果，并且无法抛出返回结果的异常，而Callable功能更强大一些，被线程执行后，可以返回值，这个返回值可以被Future拿到，也就是说，Future可以拿到异步执行任务的返回值。 

可以认为是带有回调的Runnable。

Future接口表示异步任务，是还没有完成的任务给出的未来结果。所以说Callable用于产生结果，Future用于获取结果。

## 15. 什么是FutureTask?使用ExecutorService启动任务。

在Java并发程序中FutureTask表示一个可以取消的异步运算。它有启动和取消运算、查询运算是否完成和取回运算结果等方法。只有当运算完成的时候结果才能取回，如果运算尚未完成get方法将会阻塞。一个FutureTask对象可以对调用了Callable和Runnable的对象进行包装，由于FutureTask也是调用了Runnable接口所以它可以提交给Executor来执行。

## 16. 什么是并发容器的实现？

何为同步容器：可以简单地理解为通过synchronized来实现同步的容器，如果有多个线程调用同步容器的方法，它们将会串行执行。比如Vector，Hashtable，以及Collections.synchronizedSet，synchronizedList等方法返回的容器。 

可以通过查看Vector，Hashtable等这些同步容器的实现代码，可以看到这些容器实现线程安全的方式就是将它们的状态封装起来，并在需要同步的方法上加上关键字synchronized。

并发容器使用了与同步容器完全不同的加锁策略来提供更高的并发性和伸缩性，例如在ConcurrentHashMap中采用了一种粒度更细的加锁机制，可以称为分段锁，在这种锁机制下，允许任意数量的读线程并发地访问map，并且执行读操作的线程和写操作的线程也可以并发的访问map，同时允许一定数量的写操作线程并发地修改map，所以它可以在并发环境下实现更高的吞吐量。

## 17. 多线程同步和互斥有几种实现方法，都是什么？

线程同步是指线程之间所具有的一种制约关系，一个线程的执行依赖另一个线程的消息，当它没有得到另一个线程的消息时应等待，直到消息到达时才被唤醒。 

线程互斥是指对于共享的进程系统资源，在各单个线程访问时的排它性。当有若干个线程都要使用某一共享资源时，任何时刻最多只允许一个线程去使用，其它要使用该资源的线程必须等待，直到占用资源者释放该资源。线程互斥可以看成是一种特殊的线程同步。

线程间的同步方法大体可分为两类：用户模式和内核模式。顾名思义，内核模式就是指利用系统内核对象的单一性来进行同步，使用时需要切换内核态与用户态，而用户模式就是不需要切换到内核态，只在用户态完成操作。 

用户模式下的方法有：原子操作（例如一个单一的全局变量），临界区。内核模式下的方法有：事件，信号量，互斥量。

## 18. 什么是竞争条件？你怎样发现和解决竞争？

当多个进程都企图对共享数据进行某种处理，而最后的结果又取决于进程运行的顺序时，则我们认为这发生了竞争条件（race condition）。

## 19. 你将如何使用thread dump？你将如何分析Thread dump？

 

· **新建状态（New**）** 

用new语句创建的线程处于新建状态，此时它和其他Java对象一样，仅仅在堆区中被分配了内存。

· **就绪状态（Runnable**）** 

当一个线程对象创建后，其他线程调用它的start()方法，该线程就进入就绪状态，Java虚拟机会为它创建方法调用栈和程序计数器。处于这个状态的线程位于可运行池中，等待获得CPU的使用权。

· **运行状态（Running**）** 

处于这个状态的线程占用CPU，执行程序代码。只有处于就绪状态的线程才有机会转到运行状态。

· **阻塞状态（Blocked**）** 

阻塞状态是指线程因为某些原因放弃CPU，暂时停止运行。当线程处于阻塞状态时，Java虚拟机不会给线程分配CPU。直到线程重新进入就绪状态，它才有机会转到运行状态。 

**阻塞状态可分为以下3**种**：

位于对象等待池中的阻塞状态（Blocked in object’s wait pool）：当线程处于运行状态时，如果执行了某个对象的wait()方法，Java虚拟机就会把线程放到这个对象的等待池中，这涉及到“线程通信”的内容。

位于对象锁池中的阻塞状态（Blocked in object’s lock pool）：当线程处于运行状态时，试图获得某个对象的同步锁时，如果该对象的同步锁已经被其他线程占用，Java虚拟机就会把这个线程放到这个对象的锁池中，这涉及到“线程同步”的内容。

其他阻塞状态（Otherwise Blocked）：当前线程执行了sleep()方法，或者调用了其他线程的join()方法，或者发出了I/O请求时，就会进入这个状态。

· **死亡状态（Dead**）** 

当线程退出run()方法时，就进入死亡状态，该线程结束生命周期。

 

我们运行之前的那个死锁代码SimpleDeadLock.java，然后尝试输出信息(/*这是注释，作者自己加的*/)：

/* 时间，jvm信息 */

2017-11-01 17:36:28

Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.144-b01 mixed mode):

 

/* 线程名称：DestroyJavaVM

编号：#13

优先级：5

系统优先级：0

jvm内部线程id：0x0000000001c88800

对应系统线程id（NativeThread ID）：0x1c18

线程状态： waiting on condition [0x0000000000000000] （等待某个条件）

线程详细状态：java.lang.Thread.State: RUNNABLE 及之后所有*/

"DestroyJavaVM" #13 prio=5 os_prio=0 tid=0x0000000001c88800 nid=0x1c18 waiting on condition [0x0000000000000000]

  java.lang.Thread.State: RUNNABLE

 

"Thread-1" #12 prio=5 os_prio=0 tid=0x0000000018d49000 nid=0x17b8 waiting for monitor entry [0x0000000019d7f000]

/* 线程状态：阻塞（在对象同步上）

 代码位置：at com.leo.interview.SimpleDeadLock$B.run(SimpleDeadLock.java:56)

 等待锁：0x00000000d629b4d8 

 已经获得锁：0x00000000d629b4e8*/

  java.lang.Thread.State: BLOCKED (on object monitor)

 at com.leo.interview.SimpleDeadLock$B.run(SimpleDeadLock.java:56)

 \- waiting to lock <0x00000000d629b4d8> (a java.lang.Object)

 \- locked <0x00000000d629b4e8> (a java.lang.Object)

 

"Thread-0" #11 prio=5 os_prio=0 tid=0x0000000018d44000 nid=0x1ebc waiting for monitor entry [0x000000001907f000]

  java.lang.Thread.State: BLOCKED (on object monitor)

 at com.leo.interview.SimpleDeadLock$A.run(SimpleDeadLock.java:34)

 \- waiting to lock <0x00000000d629b4e8> (a java.lang.Object)

 \- locked <0x00000000d629b4d8> (a java.lang.Object)

 

"Service Thread" #10 daemon prio=9 os_prio=0 tid=0x0000000018ca5000 nid=0x1264 runnable [0x0000000000000000]

  java.lang.Thread.State: RUNNABLE

 

"C1 CompilerThread2" #9 daemon prio=9 os_prio=2 tid=0x0000000018c46000 nid=0xb8c waiting on condition [0x0000000000000000]

  java.lang.Thread.State: RUNNABLE

 

"C2 CompilerThread1" #8 daemon prio=9 os_prio=2 tid=0x0000000018be4800 nid=0x1db4 waiting on condition [0x0000000000000000]

  java.lang.Thread.State: RUNNABLE

 

"C2 CompilerThread0" #7 daemon prio=9 os_prio=2 tid=0x0000000018be3800 nid=0x810 waiting on condition [0x0000000000000000]

  java.lang.Thread.State: RUNNABLE

 

"Monitor Ctrl-Break" #6 daemon prio=5 os_prio=0 tid=0x0000000018bcc800 nid=0x1c24 runnable [0x00000000193ce000]

  java.lang.Thread.State: RUNNABLE

 at java.net.SocketInputStream.socketRead0(Native Method)

 at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)

 at java.net.SocketInputStream.read(SocketInputStream.java:171)

 at java.net.SocketInputStream.read(SocketInputStream.java:141)

 at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)

 at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)

 at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)

 \- locked <0x00000000d632b928> (a java.io.InputStreamReader)

 at java.io.InputStreamReader.read(InputStreamReader.java:184)

 at java.io.BufferedReader.fill(BufferedReader.java:161)

 at java.io.BufferedReader.readLine(BufferedReader.java:324)

 \- locked <0x00000000d632b928> (a java.io.InputStreamReader)

 at java.io.BufferedReader.readLine(BufferedReader.java:389)

 at com.intellij.rt.execution.application.AppMainV2$1.run(AppMainV2.java:64)

 

"Attach Listener" #5 daemon prio=5 os_prio=2 tid=0x0000000017781800 nid=0x524 runnable [0x0000000000000000]

  java.lang.Thread.State: RUNNABLE

 

"Signal Dispatcher" #4 daemon prio=9 os_prio=2 tid=0x000000001778f800 nid=0x1b08 waiting on condition [0x0000000000000000]

  java.lang.Thread.State: RUNNABLE

 

"Finalizer" #3 daemon prio=8 os_prio=1 tid=0x000000001776a800 nid=0xdac in Object.wait() [0x0000000018b6f000]

  java.lang.Thread.State: WAITING (on object monitor)

 at java.lang.Object.wait(Native Method)

 \- waiting on <0x00000000d6108ec8> (a java.lang.ref.ReferenceQueue$Lock)

 at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)

 \- locked <0x00000000d6108ec8> (a java.lang.ref.ReferenceQueue$Lock)

 at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164)

 at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)

 

"Reference Handler" #2 daemon prio=10 os_prio=2 tid=0x0000000017723800 nid=0x1670 in Object.wait() [0x00000000189ef000]

  java.lang.Thread.State: WAITING (on object monitor)

 at java.lang.Object.wait(Native Method)

 \- waiting on <0x00000000d6106b68> (a java.lang.ref.Reference$Lock)

 at java.lang.Object.wait(Object.java:502)

 at java.lang.ref.Reference.tryHandlePending(Reference.java:191)

 \- locked <0x00000000d6106b68> (a java.lang.ref.Reference$Lock)

 at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)

 

"VM Thread" os_prio=2 tid=0x000000001771b800 nid=0x604 runnable 

 

"GC task thread#0 (ParallelGC)" os_prio=0 tid=0x0000000001c9d800 nid=0x9f0 runnable 

 

"GC task thread#1 (ParallelGC)" os_prio=0 tid=0x0000000001c9f000 nid=0x154c runnable 

 

"GC task thread#2 (ParallelGC)" os_prio=0 tid=0x0000000001ca0800 nid=0xcd0 runnable 

 

"GC task thread#3 (ParallelGC)" os_prio=0 tid=0x0000000001ca2000 nid=0x1e58 runnable 

 

"VM Periodic Task Thread" os_prio=2 tid=0x0000000018c5a000 nid=0x1b58 waiting on condition 

 

JNI global references: 33

 

 

/* 此处可以看待死锁的相关信息！ */

Found one Java-level deadlock:

=============================

"Thread-1":

 waiting to lock monitor 0x0000000017729fc8 (object 0x00000000d629b4d8, a java.lang.Object),

 which is held by "Thread-0"

"Thread-0":

 waiting to lock monitor 0x0000000017727738 (object 0x00000000d629b4e8, a java.lang.Object),

 which is held by "Thread-1"

 

Java stack information for the threads listed above:

===================================================

"Thread-1":

 at com.leo.interview.SimpleDeadLock$B.run(SimpleDeadLock.java:56)

 \- waiting to lock <0x00000000d629b4d8> (a java.lang.Object)

 \- locked <0x00000000d629b4e8> (a java.lang.Object)

"Thread-0":

 at com.leo.interview.SimpleDeadLock$A.run(SimpleDeadLock.java:34)

 \- waiting to lock <0x00000000d629b4e8> (a java.lang.Object)

 \- locked <0x00000000d629b4d8> (a java.lang.Object)

 

Found 1 deadlock.

 

/* 内存使用状况，详情得看JVM方面的书 */

Heap

 PSYoungGen  total 37888K, used 4590K [0x00000000d6100000, 0x00000000d8b00000, 0x0000000100000000)

 eden space 32768K, 14% used [0x00000000d6100000,0x00000000d657b968,0x00000000d8100000)

 from space 5120K, 0% used [0x00000000d8600000,0x00000000d8600000,0x00000000d8b00000)

 to  space 5120K, 0% used [0x00000000d8100000,0x00000000d8100000,0x00000000d8600000)

 ParOldGen  total 86016K, used 0K [0x0000000082200000, 0x0000000087600000, 0x00000000d6100000)

 object space 86016K, 0% used [0x0000000082200000,0x0000000082200000,0x0000000087600000)

 Metaspace  used 3474K, capacity 4500K, committed 4864K, reserved 1056768K

 class space used 382K, capacity 388K, committed 512K, reserved 1048576K

## 20. 为什么我们调用start()方法时会执行run()方法，为什么我们不能直接调用run()方法？

当你调用start()方法时你将创建新的线程，并且执行在run()方法里的代码。 

但是如果你直接调run()方法，它不会创建新的线程也不会执行调用线程的代码，只会把run方法当作普通方法去执行。

## 21. Java中你怎样唤醒一个阻塞的线程？

在Java发展史上曾经使用suspend()、resume()方法对于线程进行阻塞唤醒，但随之出现很多问题，比较典型的还是死锁问题。 

解决方案可以使用以对象为目标的阻塞，即利用Object类的wait()和notify()方法实现线程阻塞。 

首先，wait、notify方法是针对对象的，调用任意对象的wait()方法都将导致线程阻塞，阻塞的同时也将释放该对象的锁，相应地，调用任意对象的notify()方法则将随机解除该对象阻塞的线程，但它需要重新获取改对象的锁，直到获取成功才能往下执行；其次，wait、notify方法必须在synchronized块或方法中被调用，并且要保证同步块或方法的锁对象与调用wait、notify方法的对象是同一个，如此一来在调用wait之前当前线程就已经成功获取某对象的锁，执行wait阻塞后当前线程就将之前获取的对象锁释放。

## 22. 在Java中CycliBarriar和CountdownLatch有什么区别？

CyclicBarrier可以重复使用，而CountdownLatch不能重复使用。 

Java的concurrent包里面的CountDownLatch其实可以把它看作一个计数器，只不过这个计数器的操作是原子操作，同时只能有一个线程去操作这个计数器，也就是同时只能有一个线程去减这个计数器里面的值。 

你可以向CountDownLatch对象设置一个初始的数字作为计数值，任何调用这个对象上的await()方法都会阻塞，直到这个计数器的计数值被其他的线程减为0为止。 

所以在当前计数到达零之前，await 方法会一直受阻塞。之后，会释放所有等待的线程，await的所有后续调用都将立即返回。这种现象只出现一次——计数无法被重置。如果需要重置计数，请考虑使用 CyclicBarrier。 

CountDownLatch的一个非常典型的应用场景是：有一个任务想要往下执行，但必须要等到其他的任务执行完毕后才可以继续往下执行。假如我们这个想要继续往下执行的任务调用一个CountDownLatch对象的await()方法，其他的任务执行完自己的任务后调用同一个CountDownLatch对象上的countDown()方法，这个调用await()方法的任务将一直阻塞等待，直到这个CountDownLatch对象的计数值减到0为止。

CyclicBarrier一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时 CyclicBarrier 很有用。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。

## 23. 什么是不可变对象，它对写并发应用有什么帮助？

不可变对象(Immutable Objects)即对象一旦被创建它的状态（对象的数据，也即对象属性值）就不能改变，反之即为可变对象(Mutable Objects)。 

不可变对象的类即为不可变类(Immutable Class)。Java平台类库中包含许多不可变类，如String、基本类型的包装类、BigInteger和BigDecimal等。 

不可变对象天生是线程安全的。它们的常量（域）是在构造函数中创建的。既然它们的状态无法修改，这些常量永远不会变。

不可变对象永远是线程安全的。 

只有满足如下状态，一个对象才是不可变的； 

它的状态不能在创建后再被修改； 

所有域都是final类型；并且， 

它被正确创建（创建期间没有发生this引用的逸出）。

## 24. 什么是多线程中的上下文切换？

在上下文切换过程中，CPU会停止处理当前运行的程序，并保存当前程序运行的具体位置以便之后继续运行。从这个角度来看，上下文切换有点像我们同时阅读几本书，在来回切换书本的同时我们需要记住每本书当前读到的页码。在程序中，上下文切换过程中的“页码”信息是保存在进程控制块（PCB）中的。PCB还经常被称作“切换桢”（switchframe）。“页码”信息会一直保存到CPU的内存中，直到他们被再次使用。 

上下文切换是存储和恢复CPU状态的过程，它使得线程执行能够从中断点恢复执行。上下文切换是多任务操作系统和多线程环境的基本特征。

## 25. Java中用到的线程调度算法是什么？

计算机通常只有一个CPU,在任意时刻只能执行一条机器指令,每个线程只有获得CPU的使用权才能执行指令.所谓多线程的并发运行,其实是指从宏观上看,各个线程轮流获得CPU的使用权,分别执行各自的任务.在运行池中,会有多个处于就绪状态的线程在等待CPU,JAVA虚拟机的一项任务就是负责线程的调度,线程调度是指按照特定机制为多个线程分配CPU的使用权.

有两种调度模型：分时调度模型和抢占式调度模型。 

分时调度模型是指让所有的线程轮流获得cpu的使用权,并且平均分配每个线程占用的CPU的时间片这个也比较好理解。

java虚拟机采用抢占式调度模型，是指优先让可运行池中优先级高的线程占用CPU，如果可运行池中的线程优先级相同，那么就随机选择一个线程，使其占用CPU。处于运行状态的线程会一直运行，直至它不得不放弃CPU。

## 26. 什么是线程组，为什么在Java中不推荐使用？

线程组和线程池是两个不同的概念，他们的作用完全不同，前者是为了方便线程的管理，后者是为了管理线程的生命周期，复用线程，减少创建销毁线程的开销。

## 27. 为什么使用Executor框架比使用应用创建和管理线程好？

为什么要使用Executor线程池框架 

1、每次执行任务创建线程 new Thread()比较消耗性能，创建一个线程是比较耗时、耗资源的。 

2、调用 new Thread()创建的线程缺乏管理，被称为野线程，而且可以无限制的创建，线程之间的相互竞争会导致过多占用系统资源而导致系统瘫痪，还有线程之间的频繁交替也会消耗很多系统资源。 

3、直接使用new Thread() 启动的线程不利于扩展，比如定时执行、定期执行、定时定期执行、线程中断等都不便实现。

使用Executor线程池框架的优点 

1、能复用已存在并空闲的线程从而减少线程对象的创建从而减少了消亡线程的开销。 

2、可有效控制最大并发线程数，提高系统资源使用率，同时避免过多资源竞争。 

3、框架中已经有定时、定期、单线程、并发数控制等功能。 

综上所述使用线程池框架Executor能更好的管理线程、提供系统资源使用率。

## 28. java中有几种方法可以实现一个线程？

Ø 继承 Thread 类

Ø 实现 Runnable 接口

Ø 实现 Callable 接口，需要实现的是 call() 方法

## 29. 如何停止一个正在运行的线程？

1)  使用共享变量的方式 

2)  在这种方式中，之所以引入共享变量，是因为该变量可以被多个执行相同任务的线程用来作为是否中断的信号，通知中断线程的执行。

3)  使用interrupt方法终止线程 

4)  如果一个线程由于等待某些事件的发生而被阻塞，又该怎样停止该线程呢？这种情况经常会发生，比如当一个线程由于需要等候键盘输入而被阻塞，或者调用Thread.join()方法，或者Thread.sleep()方法，在网络中调用ServerSocket.accept()方法，或者调用了DatagramSocket.receive()方法时，都有可能导致线程阻塞，使线程处于处于不可运行状态时，即使主程序中将该线程的共享变量设置为true，但该线程此时根本无法检查循环标志，当然也就无法立即中断。这里我们给出的建议是，不要使用stop()方法，而是使用Thread提供的interrupt()方法，因为该方法虽然不会中断一个正在运行的线程，但是它可以使一个被阻塞的线程抛出一个中断异常，从而使线程提前结束阻塞状态，退出堵塞代码。

## 30. notify()和notifyAll()有什么区别？

当一个线程进入wait之后，就必须等其他线程notify/notifyall,使用notifyall,可以唤醒所有处于wait状态的线程，使其重新进入锁的争夺队列中，而notify只能唤醒一个。

如果没把握，建议notifyAll，防止notigy因为信号丢失而造成程序异常。

## 31. 什么是Daemon线程？它有什么意义？

所谓后台(daemon)线程，是指在程序运行的时候在后台提供一种通用服务的线程，并且这个线程并不属于程序中不可或缺的部分。因此，当所有的非后台线程结束时，程序也就终止了，同时会杀死进程中的所有后台线程。反过来说， 

只要有任何非后台线程还在运行，程序就不会终止。必须在线程启动之前调用setDaemon()方法，才能把它设置为后台线程。注意：后台进程在不执行finally子句的情况下就会终止其run()方法。

比如：JVM的垃圾回收线程就是Daemon线程，Finalizer也是守护线程。

## 32. java如何实现多线程之间的通讯和协作？

中断 和 共享变量

## 33. 什么是可重入锁（ReentrantLock）？

举例来说明锁的可重入性

public class UnReentrant{

 Lock lock = new Lock();

 public void outer(){

 lock.lock();

 inner();

 lock.unlock();

 }

 public void inner(){

 lock.lock();

 //do something

 lock.unlock();

 }

}

outer中调用了inner，outer先锁住了lock，这样inner就不能再获取lock。其实调用outer的线程已经获取了lock锁，但是不能在inner中重复利用已经获取的锁资源，这种锁即称之为 不可重入可重入就意味着：线程可以进入任何一个它已经拥有的锁所同步着的代码块。

synchronized、ReentrantLock都是可重入的锁，可重入锁相对来说简化了并发编程的开发。

## 34. 当一个线程进入某个对象的一个synchronized的实例方法后，其它线程是否可进入此对象的其它方法？

如果其他方法没有synchronized的话，其他线程是可以进入的。

所以要开放一个线程安全的对象时，得保证每个方法都是线程安全的。

## 35. 乐观锁和悲观锁的理解及如何实现，有哪些实现方式？

悲观锁：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。再比如Java里面的同步原语synchronized关键字的实现也是悲观锁。

乐观锁：顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。

乐观锁的实现方式： 

1、使用版本标识来确定读到的数据与提交时的数据是否一致。提交后修改版本标识，不一致时可以采取丢弃和再次尝试的策略。 

2、java中的Compare and Swap即CAS ，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。　CAS 操作中包含三个操作数 —— 需要读写的内存位置（V）、进行比较的预期原值（A）和拟写入的新值(B)。如果内存位置V的值与预期原值A相匹配，那么处理器会自动将该位置值更新为新值B。否则处理器不做任何操作。

CAS缺点： 

\1. **ABA**问题**： 

比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但可能存在潜藏的问题。从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。 

2、**循环时间长开销大**： 

对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。 

3、**只能保证一个共享变量的原子操作**： 

当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。

## 36. SynchronizedMap和ConcurrentHashMap有什么区别？

SynchronizedMap一次锁住整张表来保证线程安全，所以每次只能有一个线程来访为map。

ConcurrentHashMap使用分段锁来保证在多线程下的性能。ConcurrentHashMap中则是一次锁住一个桶。ConcurrentHashMap默认将hash表分为16个桶，诸如get,put,remove等常用操作只锁当前需要用到的桶。这样，原来只能一个线程进入，现在却能同时有16个写线程执行，并发性能的提升是显而易见的。 

另外ConcurrentHashMap使用了一种不同的迭代方式。在这种迭代方式中，当iterator被创建后集合再发生改变就不再是抛出ConcurrentModificationException，取而代之的是在改变时new新的数据从而不影响原有的数据 ，iterator完成后再将头指针替换为新的数据 ，这样iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变。

## 37. CopyOnWriteArrayList可以用于什么应用场景？

CopyOnWriteArrayList(免锁容器)的好处之一是当多个迭代器同时遍历和修改这个列表时，不会抛出ConcurrentModificationException。在CopyOnWriteArrayList中，写入将导致创建整个底层数组的副本，而源数组将保留在原地，使得复制的数组在被修改时，读取操作可以安全地执行。

1、由于写操作的时候，需要拷贝数组，会消耗内存，如果原数组的内容比较多的情况下，可能导致young gc或者full gc； 

2、不能用于实时读的场景，像拷贝数组、新增元素都需要时间，所以调用一个set操作后，读取到数据可能还是旧的,虽然CopyOnWriteArrayList 能做到最终一致性,但是还是没法满足实时性要求；

CopyOnWriteArrayList透露的思想 

1、读写分离，读和写分开 

2、最终一致性 

3、使用另外开辟空间的思路，来解决并发冲突

## 38. 什么叫线程安全？servlet是线程安全吗?

线程安全是编程中的术语，指某个函数、函数库在多线程环境中被调用时，能够正确地处理多个线程之间的共享变量，使程序功能正确完成。

Servlet不是线程安全的，servlet是单实例多线程的，当多个线程同时访问同一个方法，是不能保证共享变量的线程安全性的。 

Struts2的action是多实例多线程的，是线程安全的，每个请求过来都会new一个新的action分配给这个请求，请求完成后销毁。 

SpringMVC的Controller是线程安全的吗？不是的，和Servlet类似的处理流程。

Struts2好处是不用考虑线程安全问题；Servlet和SpringMVC需要考虑线程安全问题，但是性能可以提升不用处理太多的gc，可以使用ThreadLocal来处理多线程的问题。

## 39. volatile有什么用？能否用一句话说明下volatile的应用场景？

volatile保证内存可见性和禁止指令重排。

volatile用于多线程环境下的单次操作(单次读或者单次写)。

## 40. 为什么代码会重排序？

在执行程序时，为了提供性能，处理器和编译器常常会对指令进行重排序，但是不能随意重排序，不是你想怎么排序就怎么排序，它需要满足以下两个条件：

l 在单线程环境下不能改变程序运行的结果；

l 存在数据依赖关系的不允许重排序

需要注意的是：重排序不会影响单线程环境的执行结果，但是会破坏多线程的执行语义。

## 41. 在java中wait和sleep方法的不同？

最大的不同是在等待时wait会释放锁，而sleep一直持有锁。Wait通常被用于线程间交互，sleep通常被用于暂停执行。

直接了解的深入一点吧： 

 

在Java中线程的状态一共被分成6种：

**初始态：NEW**

创建一个Thread对象，但还未调用start()启动线程时，线程处于初始态。

**运行态：RUNNABLE** 

在Java中，运行态包括就绪态 和 运行态。 

就绪态 该状态下的线程已经获得执行所需的所有资源，只要CPU分配执行权就能运行。所有就绪态的线程存放在就绪队列中。 

运行态 获得CPU执行权，正在执行的线程。由于一个CPU同一时刻只能执行一条线程，因此每个CPU每个时刻只有一条运行态的线程。

**阻塞态**

当一条正在执行的线程请求某一资源失败时，就会进入阻塞态。而在Java中，阻塞态专指请求锁失败时进入的状态。由一个阻塞队列存放所有阻塞态的线程。处于阻塞态的线程会不断请求资源，一旦请求成功，就会进入就绪队列，等待执行。PS：锁、IO、Socket等都资源。

**等待态**

当前线程中调用wait、join、park函数时，当前线程就会进入等待态。也有一个等待队列存放所有等待态的线程。线程处于等待态表示它需要等待其他线程的指示才能继续运行。进入等待态的线程会释放CPU执行权，并释放资源（如：锁）

**超时等待态**

当运行中的线程调用sleep(time)、wait、join、parkNanos、parkUntil时，就会进入该状态；它和等待态一样，并不是因为请求不到资源，而是主动进入，并且进入后需要其他线程唤醒；进入该状态后释放CPU执行权 和 占有的资源。与等待态的区别：到了超时时间后自动进入阻塞队列，开始竞争锁。

**终止态**

线程执行结束后的状态。

**注意**：

l wait()方法会释放CPU执行权 和 占有的锁。

l sleep(long)方法仅释放CPU使用权，锁仍然占用；线程被放入超时等待队列，与yield相比，它会使线程较长时间得不到运行。

l yield()方法仅释放CPU执行权，锁仍然占用，线程会被放入就绪队列，会在短时间内再次执行。

l wait和notify必须配套使用，即必须使用同一把锁调用；

l wait和notify必须放在一个同步块中调用wait和notify的对象必须是他们所处同步块的锁对象。

## 42. 用Java实现阻塞队列

参考java中的阻塞队列的内容吧，直接实现有点烦： 

<http://www.infoq.com/cn/articles/java-blocking-queue>

## 43. 一个线程运行时发生异常会怎样？

如果异常没有被捕获该线程将会停止执行。Thread.UncaughtExceptionHandler是用于处理未捕获异常造成线程突然中断情况的一个内嵌接口。当一个未捕获异常将造成线程中断的时候JVM会使用Thread.getUncaughtExceptionHandler()来查询线程的UncaughtExceptionHandler并将线程和异常作为参数传递给handler的uncaughtException()方法进行处理。

## 44. 如何在两个线程间共享数据？

在两个线程间共享变量即可实现共享。 

一般来说，共享变量要求变量本身是线程安全的，然后在线程内使用的时候，如果有对共享变量的复合操作，那么也得保证复合操作的线程安全性。

## 45. Java中notify 和 notifyAll有什么区别？

notify() 方法不能唤醒某个具体的线程，所以只有一个线程在等待的时候它才有用武之地。而notifyAll()唤醒所有线程并允许他们争夺锁确保了至少有一个线程能继续运行。

## 46. 为什么wait, notify 和 notifyAll这些方法不在thread类里面？

一个很明显的原因是JAVA提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中因为锁属于对象。

## 47. 什么是ThreadLocal变量？

ThreadLocal是Java里一种特殊的变量。每个线程都有一个ThreadLocal就是每个线程都拥有了自己独立的一个变量，竞争条件被彻底消除了。它是为创建代价高昂的对象获取线程安全的好方法，比如你可以用ThreadLocal让SimpleDateFormat变成线程安全的，因为那个类创建代价高昂且每次调用都需要创建不同的实例所以不值得在局部范围使用它，如果为每个线程提供一个自己独有的变量拷贝，将大大提高效率。首先，通过复用减少了代价高昂的对象的创建个数。其次，你在没有使用高代价的同步或者不变性的情况下获得了线程安全。

## 48. Java中interrupt、interrupted 和 isInterrupted方法的区别？

**interrupt** ****：方法用于中断线程。调用该方法的线程的状态为将被置为”中断”状态。 **注意**：线程中断仅仅是置线程的中断状态位，不会停止线程。需要用户自己去监视线程的状态为并做处理。支持线程中断的方法（也就是线程中断后会抛出interruptedException的方法）就是在监视线程的中断状态，一旦线程的中断状态被置为“中断状态”，就会抛出中断异常。

**interrupted** ：查询当前线程的中断状态，并且清除原状态。如果一个线程被中断了，第一次调用interrupted则返回true，第二次和后面的就返回false了。

**isInterrupted** ：仅仅是查询当前线程的中断状态

## 49. 为什么wait和notify方法要在同步块中调用？

Java API强制要求这样做，如果你不这么做，你的代码会抛出IllegalMonitorStateException异常。还有一个原因是为了避免wait和notify之间产生竞态条件。

## 50. 为什么你应该在循环中检查等待条件?

处于等待状态的线程可能会收到错误警报和伪唤醒，如果不在循环中检查等待条件，程序就会在没有满足结束条件的情况下退出。

## 51. Java中的同步集合与并发集合有什么区别？

同步集合与并发集合都为多线程和并发提供了合适的线程安全的集合，不过并发集合的可扩展性更高。在Java1.5之前程序员们只有同步集合来用且在多线程并发的时候会导致争用，阻碍了系统的扩展性。Java5介绍了并发集合像ConcurrentHashMap，不仅提供线程安全还用锁分离和内部分区等现代技术提高了可扩展性。

## 52. 什么是线程池？ 为什么要使用它？

创建线程要花费昂贵的资源和时间，如果任务来了才创建线程那么响应时间会变长，而且一个进程能创建的线程数有限。为了避免这些问题，在程序启动的时候就创建若干线程来响应处理，它们被称为线程池，里面的线程叫工作线程。从JDK1.5开始，Java API提供了Executor框架让你可以创建不同的线程池。

## 53. 怎么检测一个线程是否拥有锁？

在java.lang.Thread中有一个方法叫holdsLock()，它返回true如果当且仅当当前线程拥有某个具体对象的锁。

## 54. 你如何在Java中获取线程堆栈？

· kill -3 [java pid] 

· 不会在当前终端输出，它会输出到代码执行的或指定的地方去。比如，kill -3 tomcat pid, 输出堆栈到log目录下。

· Jstack [java pid] 

· 这个比较简单，在当前终端显示，也可以重定向到指定文件中。 

· -JvisualVM：Thread Dump 

· 不做说明，打开JvisualVM后，都是界面操作，过程还是很简单的。

## 55. JVM中哪个参数是用来控制线程的栈堆栈小的?

-Xss 每个线程的栈大小

## 56. Thread类中的yield方法有什么作用？

使当前线程从执行状态（运行状态）变为可执行态（就绪状态）。

当前线程到了就绪状态，那么接下来哪个线程会从就绪状态变成执行状态呢？可能是当前线程，也可能是其他线程，看系统的分配了。

## 57. Java中ConcurrentHashMap的并发度是什么？

ConcurrentHashMap把实际map划分成若干部分来实现它的可扩展性和线程安全。这种划分是使用并发度获得的，它是ConcurrentHashMap类构造函数的一个可选参数，默认值为16，这样在多线程情况下就能避免争用。

在JDK8后，它摒弃了Segment（锁段）的概念，而是启用了一种全新的方式实现,利用CAS算法。同时加入了更多的辅助变量来提高并发度，具体内容还是查看源码吧。

## 58. Java中Semaphore是什么？

Java中的Semaphore是一种新的同步类，它是一个计数信号。从概念上讲，从概念上讲，信号量维护了一个许可集合。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release()添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore只对可用许可的号码进行计数，并采取相应的行动。信号量常常用于多线程的代码中，比如数据库连接池。

## 59. Java线程池中submit() 和 execute()方法有什么区别？

两个方法都可以向线程池提交任务，execute()方法的返回类型是void，它定义在Executor接口中。

而submit()方法可以返回持有计算结果的Future对象，它定义在ExecutorService接口中，它扩展了Executor接口，其它线程池类像ThreadPoolExecutor和ScheduledThreadPoolExecutor都有这些方法。

## 60. 什么是阻塞式方法？

阻塞式方法是指程序会一直等待该方法完成期间不做其他事情，ServerSocket的accept()方法就是一直等待客户端连接。这里的阻塞是指调用结果返回之前，当前线程会被挂起，直到得到结果之后才会返回。此外，还有异步和非阻塞式方法在任务完成前就返回。

## 61. Java中的ReadWriteLock是什么？

读写锁是用来提升并发程序性能的锁分离技术的成果。

## 62. volatile 变量和 atomic 变量有什么不同？

Volatile变量可以确保先行关系，即写操作会发生在后续的读操作之前, 但它并不能保证原子性。例如用volatile修饰count变量那么 count++ 操作就不是原子性的。

而AtomicInteger类提供的atomic方法可以让这种操作具有原子性如getAndIncrement()方法会原子性的进行增量操作把当前值加一，其它数据类型和引用变量也可以进行相似操作。

## 63. 可以直接调用Thread类的run ()方法么？

当然可以。但是如果我们调用了Thread的run()方法，它的行为就会和普通的方法一样，会在当前线程中执行。为了在新的线程中执行我们的代码，必须使用Thread.start()方法。

## 64. 如何让正在运行的线程暂停一段时间？

我们可以使用Thread类的Sleep()方法让线程暂停一段时间。需要注意的是，这并不会让线程终止，一旦从休眠中唤醒线程，线程的状态将会被改变为Runnable，并且根据线程调度，它将得到执行。

## 65. 你对线程优先级的理解是什么？

每一个线程都是有优先级的，一般来说，高优先级的线程在运行时会具有优先权，但这依赖于线程调度的实现，这个实现是和操作系统相关的(OS dependent)。我们可以定义线程的优先级，但是这并不能保证高优先级的线程会在低优先级的线程前执行。线程优先级是一个int变量(从1-10)，1代表最低优先级，10代表最高优先级。

java的线程优先级调度会委托给操作系统去处理，所以与具体的操作系统优先级有关，如非特别需要，一般无需设置线程优先级。

## 66. 什么是线程调度器(Thread Scheduler)和时间分片(Time Slicing )？

线程调度器是一个操作系统服务，它负责为Runnable状态的线程分配CPU时间。一旦我们创建一个线程并启动它，它的执行便依赖于线程调度器的实现。 

同上一个问题，线程调度并不受到Java虚拟机控制，所以由应用程序来控制它是更好的选择（也就是说不要让你的程序依赖于线程的优先级）。

时间分片是指将可用的CPU时间分配给可用的Runnable线程的过程。分配CPU时间可以基于线程优先级或者线程等待的时间。

## 67. 你如何确保main()方法所在的线程是Java 程序最后结束的线程？

我们可以使用Thread类的join()方法来确保所有程序创建的线程在main()方法退出前结束。

## 68. 线程之间是如何通信的？

当线程间是可以共享资源时，线程间通信是协调它们的重要的手段。Object类中wait()\notify()\notifyAll()方法可以用于线程间通信关于资源的锁的状态。

## 69. 为什么线程通信的方法wait(), notify()和notifyAll()被定义在Object 类里？

Java的每个对象中都有一个锁(monitor，也可以成为监视器) 并且wait()，notify()等方法用于等待对象的锁或者通知其他线程对象的监视器可用。在Java的线程中并没有可供任何对象使用的锁和同步器。这就是为什么这些方法是Object类的一部分，这样Java的每一个类都有用于线程间通信的基本方法。

## 70. 为什么wait(), notify()和notifyAll ()必须在同步方法或者同步块中被调用？

当一个线程需要调用对象的wait()方法的时候，这个线程必须拥有该对象的锁，接着它就会释放这个对象锁并进入等待状态直到其他线程调用这个对象上的notify()方法。同样的，当一个线程需要调用对象的notify()方法时，它会释放这个对象的锁，以便其他在等待的线程就可以得到这个对象锁。由于所有的这些方法都需要线程持有对象的锁，这样就只能通过同步来实现，所以他们只能在同步方法或者同步块中被调用。

## 71. 为什么Thread类的sleep()和yield ()方法是静态的？

Thread类的sleep()和yield()方法将在当前正在执行的线程上运行。所以在其他处于等待状态的线程上调用这些方法是没有意义的。这就是为什么这些方法是静态的。它们可以在当前正在执行的线程中工作，并避免程序员错误的认为可以在其他非运行线程调用这些方法。

## 72. 如何确保线程安全？

在Java中可以有很多方法来保证线程安全——同步，使用原子类(atomic concurrent classes)，实现并发锁，使用volatile关键字，使用不变类和线程安全类。

## 73. 同步方法和同步块，哪个是更好的选择？

同步块是更好的选择，因为它不会锁住整个对象（当然你也可以让它锁住整个对象）。同步方法会锁住整个对象，哪怕这个类中有多个不相关联的同步块，这通常会导致他们停止执行并需要等待获得这个对象上的锁。

同步块更要符合开放调用的原则，只在需要锁住的代码块锁住相应的对象，这样从侧面来说也可以避免死锁。

## 74. 如何创建守护线程？

使用Thread类的setDaemon(true)方法可以将线程设置为守护线程，需要注意的是，需要在调用start()方法前调用这个方法，否则会抛出IllegalThreadStateException异常。

## 75. 什么是Java Timer 类？如何创建一个有特定时间间隔的任务？

java.util.Timer是一个工具类，可以用于安排一个线程在未来的某个特定时间执行。Timer类可以用安排一次性任务或者周期任务。 

java.util.TimerTask是一个实现了Runnable接口的抽象类，我们需要去继承这个类来创建我们自己的定时任务并使用Timer去安排它的执行。 

目前有开源的Qurtz可以用来创建定时任务。
